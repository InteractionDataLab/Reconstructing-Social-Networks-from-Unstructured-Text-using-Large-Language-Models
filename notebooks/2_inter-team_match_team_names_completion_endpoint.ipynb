{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b94909cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import tiktoken\n",
    "import cleantext\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import ast\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing import Pool\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#Load the api key from being an environment variable\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "stats = pd.DataFrame()\n",
    "\n",
    "stp_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e970a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_batch_request(arguments, model = \"gpt-3.5-turbo-instruct\", temperature = 0.3, output_format = \"lol\", columns = [\"team\", \"context\", \"target\"]):\n",
    "    \n",
    "    \n",
    "    chunks = arguments\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    flag = []\n",
    "\n",
    "    try:\n",
    "    \n",
    "        response = openai.Completion.create(                                \n",
    "                    prompt = chunks ,\n",
    "                    engine = model,\n",
    "                    temperature = temperature,\n",
    "                    max_tokens = 2000,  \n",
    "                    top_p = 1,\n",
    "                    frequency_penalty = 0,\n",
    "                    presence_penalty = 0,\n",
    "                    timeout = 200\n",
    "                    )\n",
    "        \n",
    "    except:\n",
    "        return(df, 0)\n",
    "        \n",
    "    var = response.choices[0].text.strip()\n",
    "        \n",
    "    t = pd.DataFrame([[var]], columns=[\"text\"]) \n",
    "                    \n",
    "    df = df.append(t)\n",
    "    \n",
    "    return(df, 1)\n",
    "\n",
    "\n",
    "def string_process_no_stp_words(name):\n",
    "    \n",
    "    processed_name = name.strip()\n",
    "    \n",
    "    #processed_name = processed_name.replace(\"_\", \" \")\n",
    "    #processed_name = processed_name.replace(\"-\", \" \")\n",
    "    processed_name = processed_name.replace(\",\", \" \")\n",
    "    \n",
    "    processed_name_lower = processed_name.lower()\n",
    "    \n",
    "    processed_sans_sw = word_tokenize(processed_name)\n",
    "    processed_sans_sw = [word for word in processed_sans_sw if not word in stp_words]\n",
    "    abbr = [word[0] for word in processed_sans_sw if not word in stp_words]\n",
    "    abbr = \"\".join(abbr)\n",
    "    processed_sans_sw = \" \".join(processed_sans_sw)\n",
    "\n",
    "    return(processed_name, processed_name_lower, processed_sans_sw, abbr)\n",
    "\n",
    "\n",
    "def process_team_names(name):\n",
    "    \n",
    "    if (len(name) > 0):\n",
    "    \n",
    "        #Remove _,- and keep string in uppercase (to preserve some contextual information about proper nouns)\n",
    "        \n",
    "        name = string_process_no_stp_words(name)[0]\n",
    "        #name = name.replace(\"igem\", \" \")\n",
    "        #name = name.replace(\"team\", \" \")\n",
    "\n",
    "        if len(name) > 0:\n",
    "            return(name.strip())\n",
    "        \n",
    "\n",
    "def process_request_regex(text, output_format = \"lol\", columns = [\"team\", \"matching\"]):\n",
    "    \n",
    "    if (output_format == \"lol\"):\n",
    "        \n",
    "        var = text\n",
    "        \n",
    "#        try:\n",
    "            \n",
    "#            var = var[var.find(\"[[\"):var.find(\"]]\")+2]\n",
    "#            var = ast.literal_eval(var)\n",
    "            \n",
    "#            processed_df = pd.DataFrame(data = var, columns = columns)\n",
    "        \n",
    "#        except:\n",
    "            \n",
    "        try:\n",
    "\n",
    "            var = text\n",
    "\n",
    "            var = re.findall(r'\\[[\"].*?[\"],[ ]?[\"].*?[\"]\\]', var)\n",
    "            var = [ast.literal_eval(x) for x in var]\n",
    "\n",
    "            var = [x if len(x) == 2 else None for x in var]\n",
    "            var = [x for x in var if x is not None]\n",
    "\n",
    "            if len(var) == 0:\n",
    "                return(pd.DataFrame(), 2)\n",
    "\n",
    "            processed_df = pd.DataFrame(var, columns = columns)   \n",
    "                \n",
    "        except:\n",
    "                \n",
    "            return(pd.DataFrame(), 0)\n",
    "            \n",
    "    return(processed_df, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e62a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"two-step\"\n",
    "output_format = \"lol\"\n",
    "temperature_curation = 0.3\n",
    "\n",
    "#batches = os.listdir(\"../data/processed/batches_inter-team_collab/\")\n",
    "#batches = os.listdir(\"../data/processed/all_batches_inter-team_fuzzy_select_freq/\")\n",
    "#batches = [batch.replace(\".csv\", \"\") for batch in batches]\n",
    "\n",
    "batches = [\"1\", \"2\"]\n",
    "\n",
    "model = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "temperature = 0.3\n",
    "\n",
    "breaks = 10\n",
    "\n",
    "meta = pd.read_csv(\"../data/raw/team_meta.csv\")\n",
    "\n",
    "f = open(\"prompts/prompt_inter-team_matching_\" + output_format, \"r\")\n",
    "prompt = f.read().rstrip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1947e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_names = pd.DataFrame()\n",
    "\n",
    "for batch_no in batches:\n",
    "    \n",
    "    df = pd.read_csv(\"../data/processed/gpt_curated/inter-team/processed_\" + batch_no + \"_\" + version + \"_\" + model + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\")\n",
    "    \n",
    "    df_names = df_names.append(df[[\"team\", \"year\"]])\n",
    "    \n",
    "    temp = pd.DataFrame({\"team\":df['target'], \"year\":df['year']})\n",
    "    \n",
    "    df_names = df_names.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e68068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b55294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started year 2009\n",
      "finished year 2009 in 3.125364303588867 seconds\n",
      "Started year 2011\n",
      "finished year 2011 in 20.414579153060913 seconds\n",
      "Started year 2012\n",
      "finished year 2012 in 2.444157123565674 seconds\n",
      "Started year 2013\n",
      "finished year 2013 in 3.0469248294830322 seconds\n",
      "Started year 2014\n",
      "finished year 2014 in 1.4547080993652344 seconds\n",
      "Started year 2015\n",
      "finished year 2015 in 31.438679933547974 seconds\n",
      "Started year 2016\n",
      "finished year 2016 in 38.56688833236694 seconds\n",
      "Started year 2017\n",
      "finished year 2017 in 61.172534465789795 seconds\n",
      "Started year 2018\n",
      "finished year 2018 in 53.55965065956116 seconds\n"
     ]
    }
   ],
   "source": [
    "df_matching = pd.DataFrame()\n",
    "\n",
    "for year in sorted(df_names['year'].unique()):\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Started year \" + str(year))\n",
    "    \n",
    "    missed_entries = []\n",
    "    \n",
    "    temp = df_names[df_names['year'] == year] \n",
    "    \n",
    "    list_of_names = list(meta[meta['Year'] == year]['Team'])\n",
    "    list_of_names_edited = [process_team_names(str(name)) for name in list_of_names]\n",
    "    \n",
    "    l = list(temp['team'].unique())\n",
    "    \n",
    "    #l = [str(x).split(\",\") for x in l]\n",
    "    #l = sum(l, [])\n",
    "    \n",
    "    #l = [str(element) for element in l if element not in list_of_names]\n",
    "    \n",
    "    l = [str(element) for element in l if not any(element == name for name in list_of_names)]\n",
    "    \n",
    "    l_edited = [process_team_names(str(element)) for element in l]\n",
    "    l_edited = [i for i in l_edited if i is not None]\n",
    "    \n",
    "    all_messages = []\n",
    "    var = 0\n",
    "    \n",
    "    #batch['processed_text'] =  prompt + \"We are team \" + batch['team'] + \"\\n.\" + \"The following text describes our activities in a scientific competition called iGEM including our relationships with other teams:\" +  batch['text']\n",
    "    \n",
    "    for j in range(0,len(l),breaks):        \n",
    "        \n",
    "        text = \"The following list contains the names of teams: \" + \", \".join(list_of_names_edited) + prompt + ', '.join(l_edited[j:min(j+breaks,len(l_edited))])\n",
    "        \n",
    "        all_messages.extend([text])\n",
    "        var = var + 1\n",
    "    \n",
    "    for message in all_messages:\n",
    "        \n",
    "        output, miss = send_batch_request(message)\n",
    "        output['year'] = year\n",
    "        \n",
    "        df_matching = df_matching.append(output)\n",
    "        \n",
    "        if miss == 0:\n",
    "            missed_entries.extend(all_messages[miss][0])\n",
    "            \n",
    "   #After support for the old endpoint ended early 2024, parallel processing seems to fail much more than before. \n",
    "    \n",
    "    #with Pool(processes = 8) as pool:\n",
    "        \n",
    "    #    zipped_output = pool.map(send_request_chat_competion, all_messages)\n",
    "        \n",
    "    #    for output, miss in list(zipped_output):\n",
    "            \n",
    "    #        df_matching = df_matching.append(output)\n",
    "            \n",
    "    #        if not miss == None:\n",
    "                \n",
    "    #            missed_entries.extend(all_messages[miss][0])\n",
    "            \n",
    "        time.sleep(0.01)\n",
    "            \n",
    "            \n",
    "    end = time.time()\n",
    "    time_elapsed = (end-start)\n",
    "    print(\"finished year \" + str(year) + \" in \" + str(time_elapsed) + \" seconds\")\n",
    "    \n",
    "    stats = stats.append(pd.DataFrame([[year, time_elapsed, str(missed_entries)]], columns=[\"year\", \"time_elapsed\", \"failed_chunks\"]))\n",
    "    time.sleep(1)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea644ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc766027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29002cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching.to_csv(\"../data/processed/gpt_curated/inter-team/team_name_matchings_\" + str(breaks) + \"_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\")+ \".csv\", index = False)\n",
    "stats.to_csv(\"../data/processed/gpt_curated/inter-team/stats_team_name_matchings_\" + str(breaks) + \"_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4527e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_processing = pd.DataFrame()\n",
    "\n",
    "df_interactions = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_csv(\"../data/processed/gpt_curated/inter-team/team_name_matchings_\" + str(breaks) + \"_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\")+ \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\")\n",
    "    \n",
    "for loop_var in range(len(df)):\n",
    "    \n",
    "    t, flag = process_request_regex(str(df['text'][loop_var]))\n",
    "        \n",
    "    if (len(t) > 0):\n",
    "        \n",
    "        t['year'] = df['year'][loop_var]\n",
    "            \n",
    "        df_interactions = df_interactions.append(t)                \n",
    "        \n",
    "    stats_processing = stats_processing.append(pd.DataFrame([[loop_var, flag]], columns=[\"row_no\", \"status\"]))\n",
    "    \n",
    "df_interactions.to_csv(\"../data/processed/gpt_curated/inter-team/processed_team_name_matchings_\" + str(breaks) + \"_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\")+ \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18915c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc17e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4ecdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c4949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1600b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
