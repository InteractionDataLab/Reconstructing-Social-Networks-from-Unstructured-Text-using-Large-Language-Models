{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db2e87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import tiktoken\n",
    "import cleantext\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing import Pool\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#from ipynb.fs.full.gpt_curation_custom_functions import string_process_no_stp_words, process_team_names\n",
    "#from ipynb.fs.full.gpt_curation_custom_functions import fuzzy_match, fuzzy_search\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#Load the api key from being an environment variable\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "stats = pd.DataFrame()\n",
    "\n",
    "stp_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f169c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request_chat_competion(arguments, model = \"gpt-4-0125-preview\", temperature = 0.3, output_format = \"lol\", columns = [\"relationship\", \"matching\"]):\n",
    "    \n",
    "    message = arguments[0]\n",
    "    variables = arguments[1]\n",
    "    chunk = arguments[2]\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(model = model, messages = message, temperature = temperature, request_timeout = 60)\n",
    "        final_response = response.choices[0].message[\"content\"].strip()\n",
    "    \n",
    "    except:\n",
    "        return(pd.DataFrame(), chunk)\n",
    "    \n",
    "    if (output_format == \"lol\"):\n",
    "        \n",
    "        var = final_response\n",
    "        #var = var[var.find(\"[[\"):var.find(\"]]\")+2]\n",
    "        processed_df = pd.DataFrame([[var]], columns=[\"text\"])\n",
    "        \n",
    "        #try:\n",
    "        #    var = ast.literal_eval(var)\n",
    "        #    processed_df = pd.DataFrame(data = var, columns = columns)\n",
    "            \n",
    "        for key, value  in variables.items():\n",
    "            processed_df[key] = value\n",
    "\n",
    "    return(processed_df, None)\n",
    "\n",
    "def process_request_regex(text, output_format = \"lol\", columns = [\"member\", \"matching\"]):\n",
    "    \n",
    "    if (output_format == \"lol\"):\n",
    "        \n",
    "        var = text\n",
    "        \n",
    "            \n",
    "        try:\n",
    "\n",
    "            var = text\n",
    "\n",
    "            var = re.findall(r'\\[[\"].*?[\"],[ ]?[\"].*?[\"]\\]', var)\n",
    "            var = [ast.literal_eval(x) for x in var]\n",
    "\n",
    "            var = [x if len(x) == 2 else None for x in var]\n",
    "            var = [x for x in var if x is not None]\n",
    "\n",
    "            if len(var) == 0:\n",
    "                return(pd.DataFrame(), 2)\n",
    "\n",
    "            processed_df = pd.DataFrame(var, columns = columns)   \n",
    "                \n",
    "        except:\n",
    "                \n",
    "            return(pd.DataFrame(), 0)\n",
    "            \n",
    "    return(processed_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb9deb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"specific\"\n",
    "output_format = \"lol\"\n",
    "temperature_curation = 0.3\n",
    "\n",
    "#batches = os.listdir(\"../data/processed/batches_inter-team_collab/\")\n",
    "#batches = [batch.replace(\".csv\", \"\") for batch in batches]\n",
    "\n",
    "#model = \"gpt-3.5-turbo-16k\"\n",
    "model = \"gpt-4-0125-preview\"\n",
    "#model = \"gpt-4-turbo\"\n",
    "\n",
    "temperature = 0.3\n",
    "\n",
    "breaks = 10\n",
    "\n",
    "meta = pd.read_csv(\"../data/raw/team_meta.csv\")\n",
    "\n",
    "#f = open(\"prompts/prompt_inter-team_matching_\" + output_format, \"r\")\n",
    "#prompt = f.read().rstrip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e3ab46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2015, 2016, 2017, 2018]\n",
    "df_names = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    df = pd.read_csv(\"../data/processed/gpt_curated/intra-team/processed_\" + str(year) + \"_\" + version + \"_\" + model + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\")\n",
    "    \n",
    "    df_names = df_names.append(df[[\"activity\", \"year\"]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "462f22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual = pd.read_csv(\"../data/processed/manually curated/random_per_year_intra_team/intra-team_manual_annotated.csv\")\n",
    "#df_names = manual.filter(items=['activities', 'Year'])\n",
    "#df_names = df_names.rename(columns={\"activities\": \"activity\", \"Year\": \"year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6688d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537ec8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "152bda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_interactions.to_csv(\"../data/processed/test_matching_activities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fadaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "Each phrase describes activities performed as a part of a team participating in the synthetic biology iGEM competition. \n",
    "\n",
    "Given a list of phrases, match each phrase with the categories listed below. Some phrases can be matched to multiple categories.\n",
    "\n",
    "Provide the output as a list of lists - [[\"PHRASE\", \"MATCHING CATEGORY\"]].\n",
    "\n",
    "The possible categories, along with their description are:\n",
    "Design: Conceptualising, doing background research and/or designing the teams' project idea.\n",
    "Experiments: Performed synthetic biology experiments in the wet laboratory as a part of the teams' project.\n",
    "Documentation: Creating, managing and editing the teams' wiki website, report writing and scientific documentation\n",
    "Interlab: Performed the interlab study.\n",
    "Modelling: Performed mathematical models, computer simulations and/or used engineering principles to model their project.\n",
    "Analysis: Performed dry lab work, data curation, data analysis and/or bioinformatics as a part of the teams' project\n",
    "Parts: Was responsible for creating, characterising and documenting basic or composite synthetic biology parts, also called biobricks.\n",
    "Safety: Was responsible for addressing safety considerations of the teams' project.\n",
    "Entrepreneurship: Was involved with building a business case and/or commercializing the teams' project.\n",
    "Hardware: Worked with or built hardware components for their teams' project.\n",
    "Software: Created computational tools and/or software as a part of their teams' project.\n",
    "Human Practices: Was responsible to understand the ethical, legal, economic and social considerations of the teams' project. Sometimes abbreviated as 'HP'.\n",
    "Public Engagement: Established a public dialogue through outreach, educational tools and/or social media to discuss their project, science and synthetic biology with people outside the lab.\n",
    "Collaboration: Was responsible for collaborating with other teams participating in the iGEM competition.\n",
    "Fundraising: Was responsible in fundraising and/or finding sponsors for the teams' project.\n",
    "Creative Contributions: Making presentations, designing team logos and suits, creating art pieces, and producing promotional materials.\n",
    "Administration: Was responsible for management, organisation and coordinating the laboratory and/or activities of the teams' project.\n",
    "Material Supply: Providing laboratory space, equipment, supplies and providing technical materials or reagents\n",
    "Supervision: Provided advice, feedback, support, guidance, assistance or help in various aspects of a teams' project by being a Principal Investigator (PI), advisor or instructor.\n",
    "Training: Conducting educational workshops, courses and/or teaching lab techniques.\n",
    "Other: For descriptions that are not matched to any of the categories above.\n",
    "\n",
    "example: '\"project conceptualization and working in the wetlab\", \"outreach\"'\n",
    "Matching: [[\"project conceptualization and working in the wetlab\", \"Design\"], [\"project conceptualization and working in the wetlab\", \"Experiments\"], [\"outreach\",\"Public Outreach\"]]\n",
    "\n",
    "example: '\"flux balance analysis\", \"Advisor for modelling tasks\"'\n",
    "Matching: [[\"flux balance analysis\",\"Experiments\"],[\"Advisor for modelling tasks\",\"Supervision\"], [\"Advisor for modelling tasks\",\"Modelling\"]]\n",
    "\n",
    "example: '\"assisted the team on many technical concepts\", \"made drawn images on the wiki\", \"absolutely love food and sleep\"'\n",
    "Matching: [[\"assisted the team on many technical concepts\", \"Supervision\"],[\"made drawn images on the wiki\", \"Documentation\"], [\"made drawn images on the wiki\", \"Creative Contributions\"],[\"absolutely love food and sleep\", \"other\"]]\n",
    "\n",
    "The following are the list of phrases:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Include more context for GPT to understand the iGEM specific background\n",
    "#Ask gpt to refine the prompt\n",
    "#Groupings in confusion matrix - dendogram\n",
    "#Examples for each categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf18c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f51d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f624247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61c7a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started year 2015\n",
      "finished year 2015 in 42.650538206100464 seconds\n",
      "Started year 2016\n",
      "finished year 2016 in 63.40220403671265 seconds\n",
      "Started year 2017\n",
      "finished year 2017 in 40.27959966659546 seconds\n",
      "Started year 2018\n",
      "finished year 2018 in 57.97981309890747 seconds\n"
     ]
    }
   ],
   "source": [
    "breaks = 10\n",
    "\n",
    "df_matching = pd.DataFrame()\n",
    "\n",
    "for year in sorted(df_names['year'].unique()):\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Started year \" + str(year))\n",
    "    \n",
    "    missed_entries = []\n",
    "    \n",
    "    temp = df_names[df_names['year'] == year] \n",
    "    \n",
    "    \n",
    "    l = list(temp['activity'].unique())\n",
    "    l = [x.lower() for x in l if x == x] # To remove np.nan. Regular method seems to not work\n",
    "    \n",
    "    all_messages = []\n",
    "    var = 0\n",
    "    \n",
    "    for j in range(0,len(l),breaks):\n",
    "    \n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "        messages.append({\"role\": \"user\", \"content\": ', '.join((\"\\\"\" + x + \"\\\"\") for x in l[j:min(j+breaks,len(l))])})\n",
    "        \n",
    "        all_messages.extend([[messages, {\"year\": year}, var]])\n",
    "        var = var + 1\n",
    "    \n",
    "    with Pool(processes = 8) as pool:\n",
    "        \n",
    "        zipped_output = pool.map(send_request_chat_competion, all_messages)\n",
    "        \n",
    "        for output, miss in list(zipped_output):\n",
    "            \n",
    "            df_matching = df_matching.append(output)\n",
    "            \n",
    "            if not miss == None:\n",
    "                \n",
    "                missed_entries.extend(all_messages[miss][0])\n",
    "            \n",
    "        time.sleep(0.01)\n",
    "            \n",
    "            \n",
    "    end = time.time()\n",
    "    time_elapsed = (end-start)\n",
    "    print(\"finished year \" + str(year) + \" in \" + str(time_elapsed) + \" seconds\")\n",
    "    \n",
    "    stats = stats.append(pd.DataFrame([[year, time_elapsed, str(missed_entries)]], columns=[\"year\", \"time_elapsed\", \"failed_chunks\"]))\n",
    "    time.sleep(1)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5370427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8addf926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "columns = [\"Activity\", \"Matching\"]\n",
    "\n",
    "for i in range(len(df_matching)):\n",
    "    \n",
    "    var = df_matching['text'].iloc[i]\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        #var = text\n",
    "\n",
    "        var = re.findall(r'\\[[\"].*?[\"],[ ]?[\"].*?[\"]\\]', var)\n",
    "        var = [ast.literal_eval(x) for x in var]\n",
    "\n",
    "        var = [x if len(x) == 2 else None for x in var]\n",
    "        var = [x for x in var if x is not None]\n",
    "\n",
    "        #if len(var) == 0:\n",
    "        #    t = pd.DataFrame()\n",
    "\n",
    "        t = pd.DataFrame(var, columns = columns)   \n",
    "        t['year'] = df_matching['year'].iloc[i]\n",
    "                \n",
    "    except:\n",
    "                \n",
    "        t = pd.DataFrame()\n",
    "            \n",
    "    if len(t) > 0:\n",
    "        df = df.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ed71794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../data/processed/curated/intra-team_verify/relationship_matching_manual.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9de2b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_matching.to_csv(\"../data/processed/curated/intra-team_verify/raw_relationship_matching_manual.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b088dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/gpt_curated/intra-team/processed_relationship_matching_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\")+ \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index=False)\n",
    "df_matching.to_csv(\"../data/processed/gpt_curated/intra-team/raw_relationship_matching_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\")+ \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb805959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bc2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
