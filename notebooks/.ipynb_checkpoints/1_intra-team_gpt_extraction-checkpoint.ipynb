{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b844ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the necessary libraries\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import tiktoken\n",
    "import cleantext\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import ast\n",
    "from fuzzywuzzy import fuzz\n",
    "from multiprocessing import Pool\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#from ipynb.fs.full.gpt_curation_custom_functions import send_batch_request\n",
    "#from ipynb.fs.full.gpt_curation_custom_functions import string_process_no_stp_words, process_team_names\n",
    "#from ipynb.fs.full.gpt_curation_custom_functions import fuzzy_match, fuzzy_search\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#Load the api key from being an environment variable\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "stats = pd.DataFrame()\n",
    "\n",
    "stp_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a7ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc18b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Version is custom - based on my prompt styles. Specific is one-shot with particular explanation on the task\n",
    "version = \"specific\"\n",
    "\n",
    "#Setting the output format as a list of list\n",
    "output_format = \"lol\"\n",
    "\n",
    "\n",
    "#The text file to the prompt\n",
    "f = open(\"prompts/prompt_intra-team_version_\" + version + \"_\" + output_format , \"r\")\n",
    "prompt = f.read().rstrip()\n",
    "\n",
    "meta = pd.read_csv(\"../data/raw/team_meta.csv\")\n",
    "\n",
    "model = \"gpt-4-turbo\"\n",
    "#model = \"gpt-4-0125-preview\"\n",
    "#model = \"gpt-3.5-turbo-16k\"\n",
    "\n",
    "\n",
    "#The level of creativity in the gpt response - for the extraction task set at 0.3\n",
    "temperature = 0.3\n",
    "\n",
    "\n",
    "#years = list(range(2015, 2019))\n",
    "years = [\"2015\", \"2016\", \"2017\", \"2018\"]\n",
    "\n",
    "manual = pd.read_csv(\"../data/processed/manually_curated/random_per_year_intra_team/new_intra_team_annotation_partial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ed3effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Extrapolate all relationships between people and activities they were involved in from the text provided. \n",
    "\n",
    "Provide the output as a list of lists - [[\"PERSON\", \"ACTIVITY\"]]. \n",
    "\n",
    "\"PERSON\" is the name of the person.\n",
    "\"ACTIVITY\" is the activity they performed as described in the text.\n",
    "\n",
    "If a person is involved in multiple activities, report each activity as a separate relationship.\n",
    "\n",
    "example: \"Project colycyclin: Marcus North, Andrea Belotti\"\n",
    "relationships: [[\"Marcus North\", \"Project colycyclin\"],[\"Andrea Belotti\", \"Project colycyclin\"]]\n",
    "\n",
    "example: \"We are team Mideastern. Our team members Brad Hogg and Sophie Devine performed wet lab experiments. Andrew Symonds was responsible for collaborating with other iGEM teams and maintaining our wiki.\"\n",
    "relationships: [[\"Brad Hogg\",\"performed wet lab experiments\"],[\"Sophie Devine\",\"performed wet lab experiments\"],[\"Andrew Symonds\",\"responsible for collaborating with other teams\"],[\"Andrew Symonds\", \"maintaining our wiki\"]]\n",
    "\n",
    "Please make sure there is no additional text in the response other than the relationships in the prescribed format.\n",
    "\n",
    "The text: \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed3fd010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_n_tokens(text, tokenizer = tokenizer):\n",
    "    \n",
    "    t = tokenizer.encode(text)\n",
    "    \n",
    "    return(len(t))\n",
    "\n",
    "\n",
    "def send_request_chat_competion(arguments, model = \"gpt-4-turbo\", temperature = 0.3, output_format = \"lol\"):\n",
    "    \n",
    "    message = arguments[0]\n",
    "    variables = arguments[1]\n",
    "    chunk = arguments[2]\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(model = model, messages = message, temperature = temperature, request_timeout = 60)\n",
    "        final_response = response.choices[0].message[\"content\"].strip()\n",
    "    \n",
    "    except:\n",
    "        return(pd.DataFrame(), chunk)\n",
    "    \n",
    "    if (output_format == \"lol\"):\n",
    "        \n",
    "        var = final_response\n",
    "        processed_df = pd.DataFrame([[var]], columns=[\"text\"])\n",
    "            \n",
    "        for key, value  in variables.items():\n",
    "            processed_df[key] = value\n",
    "\n",
    "    return(processed_df, None)\n",
    "\n",
    "def process_request_regex(text, output_format = \"lol\", columns = [\"member\", \"activity\"]):\n",
    "    \n",
    "    if (output_format == \"lol\"):\n",
    "        \n",
    "        var = text\n",
    "            \n",
    "        try:\n",
    "\n",
    "            var = text\n",
    "\n",
    "            var = re.findall(r'\\[[\"].*?[\"],[ ]?[\"].*?[\"]\\]', var)\n",
    "            var = [ast.literal_eval(x) for x in var]\n",
    "\n",
    "            var = [x if len(x) == 2 else None for x in var]\n",
    "            var = [x for x in var if x is not None]\n",
    "\n",
    "            if len(var) == 0:\n",
    "                return(pd.DataFrame(), 2)\n",
    "\n",
    "            processed_df = pd.DataFrame(var, columns = columns)   \n",
    "                \n",
    "        except:\n",
    "                \n",
    "            return(pd.DataFrame(), 0)\n",
    "            \n",
    "    return(processed_df, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0507b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed year 2015 in 81.67648911476135 seconds\n",
      "Completed year 2016 in 103.7580053806305 seconds\n",
      "Completed year 2017 in 75.94142413139343 seconds\n",
      "Completed year 2018 in 75.35301470756531 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for year in years:\n",
    "    \n",
    "    start = time.time()\n",
    "    year = str(year)\n",
    "\n",
    "    teams = manual['Team'][manual['Year'] == int(year)].unique()\n",
    "    \n",
    "    all_messages = []\n",
    "    missed_entries = []\n",
    "    var = 0\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    text = pd.read_csv(\"../data/processed/text_batches_intra-team/\" + year + \".csv\")\n",
    "    \n",
    "    for team in teams:\n",
    "    \n",
    "        if (not os.path.isfile(\"\")):\n",
    "                   \n",
    "            t = text[text['team'] == team]\n",
    "            \n",
    "            for i in range(len(t)):\n",
    "                \n",
    "                processed_text = t['chunk'].iloc[i]\n",
    "                \n",
    "                messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "                messages.append({\"role\": \"user\", \"content\": processed_text})              \n",
    "                all_messages.extend([[messages, {\"year\": year, \"team\": team, 'page': t['page'].iloc[i]}, var]])\n",
    "                var = var + 1\n",
    "    \n",
    "    \n",
    "    with Pool(processes = 8) as pool:\n",
    "\n",
    "        zipped_output = pool.map(send_request_chat_competion, all_messages)\n",
    "\n",
    "        for output, miss in list(zipped_output):    \n",
    "            \n",
    "            df = df.append(output)\n",
    "        \n",
    "            if not miss == None:\n",
    "                missed_entries.extend(all_messages[miss][0])\n",
    "\n",
    "    end = time.time()\n",
    "    time_elapsed = (end-start)\n",
    "\n",
    "    stats = stats.append(pd.DataFrame([[year, time_elapsed, missed_entries]], columns=[\"year\", \"time_secs\", \"misses\"]))\n",
    "\n",
    "    print(\"Completed year \" + year + \" in \" + str(time_elapsed) + \" seconds\")\n",
    "\n",
    "    \n",
    "    df.to_csv(\"../data/processed/gpt_curated/intra-team/raw_\" + year + \"_\"+ version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \".csv\", index=False)\n",
    "    time.sleep(1)\n",
    "    \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e9d3aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed year 2015\n",
      "Completed year 2016\n",
      "Completed year 2017\n",
      "Completed year 2018\n"
     ]
    }
   ],
   "source": [
    "stats_processing = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    df_interactions = pd.DataFrame()\n",
    "    \n",
    "    df = pd.read_csv(\"../data/processed/gpt_curated/intra-team/raw_\" + str(year) + \"_\"+ version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \".csv\")\n",
    "    \n",
    "    if (len(df) > 0):\n",
    "\n",
    "        for loop_var in range(len(df)):\n",
    "\n",
    "            t, flag = process_request_regex(str(df['text'].iloc[loop_var]))\n",
    "\n",
    "            if (len(t) > 0):\n",
    "\n",
    "                t['team'] = df['team'].iloc[loop_var]\n",
    "                t['year'] = year\n",
    "                t['page'] = df['page'].iloc[loop_var]\n",
    "                #t['batch_id'] = batch_no\n",
    "                t['chunk_id'] = loop_var #df['chunk'][loop_var]\n",
    "\n",
    "                df_interactions = df_interactions.append(t)                \n",
    "\n",
    "            stats_processing = stats_processing.append(pd.DataFrame([[year, loop_var, flag]], columns=[\"year\", \"chunk_no\", \"status\"]))\n",
    "\n",
    "        df_interactions.to_csv(\"../data/processed/gpt_curated/intra-team/processed_\" + str(year) + \"_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \".csv\", index=False)\n",
    "        \n",
    "    print(\"Completed year \" + str(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e132f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f185125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0a7b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "years = [\"2015\", \"2016\", \"2017\", \"2018\"]\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    t = pd.read_csv(\"../data/processed/gpt_curated/intra-team/processed_\" + year + \"_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \".csv\")\n",
    "    df = df.append(t)\n",
    "    \n",
    "df.to_csv(\"../data/processed/gpt_curated/intra-team/processed_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be003aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>time_secs</th>\n",
       "      <th>misses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>81.676489</td>\n",
       "      <td>[{'role': 'user', 'content': '\n",
       "\n",
       "Extrapolate al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>103.758005</td>\n",
       "      <td>[{'role': 'user', 'content': '\n",
       "\n",
       "Extrapolate al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>75.941424</td>\n",
       "      <td>[{'role': 'user', 'content': '\n",
       "\n",
       "Extrapolate al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>75.353015</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   time_secs                                             misses\n",
       "0  2015   81.676489  [{'role': 'user', 'content': '\n",
       "\n",
       "Extrapolate al...\n",
       "0  2016  103.758005  [{'role': 'user', 'content': '\n",
       "\n",
       "Extrapolate al...\n",
       "0  2017   75.941424  [{'role': 'user', 'content': '\n",
       "\n",
       "Extrapolate al...\n",
       "0  2018   75.353015                                                 []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08df97a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stats['misses'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fc310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e490b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43dc064d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f505a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
