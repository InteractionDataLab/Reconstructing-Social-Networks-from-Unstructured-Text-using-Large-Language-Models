{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b94909cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import tiktoken\n",
    "import cleantext\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import ast\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode\n",
    "from multiprocessing import Pool\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#Load the api key from being an environment variable\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "stats = pd.DataFrame()\n",
    "\n",
    "stp_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e970a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request_chat_competion(arguments, model = \"gpt-4-turbo\", temperature = 0.3, output_format = \"lol\", columns = [\"team\", \"matching\"]):\n",
    "    \n",
    "    message = arguments[0]\n",
    "    variables = arguments[1]\n",
    "    chunk = arguments[2]\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(model = model, messages = message, temperature = temperature, request_timeout = 60)\n",
    "        final_response = response.choices[0].message[\"content\"].strip()\n",
    "    \n",
    "    except:\n",
    "        return(pd.DataFrame(), chunk)\n",
    "    \n",
    "    if (output_format == \"lol\"):\n",
    "        \n",
    "        var = final_response\n",
    "        #var = var[var.find(\"[[\"):var.find(\"]]\")+2]\n",
    "        processed_df = pd.DataFrame([[var]], columns=[\"text\"])\n",
    "        \n",
    "        #try:\n",
    "        #    var = ast.literal_eval(var)\n",
    "        #    processed_df = pd.DataFrame(data = var, columns = columns)\n",
    "            \n",
    "        for key, value  in variables.items():\n",
    "            processed_df[key] = value\n",
    "\n",
    "    return(processed_df, None)\n",
    "\n",
    "\n",
    "def string_process_no_stp_words(name):\n",
    "    \n",
    "    processed_name = name.strip()\n",
    "    \n",
    "    #processed_name = processed_name.replace(\"_\", \" \")\n",
    "    #processed_name = processed_name.replace(\"-\", \" \")\n",
    "    processed_name = processed_name.replace(\",\", \" \")\n",
    "    processed_name = processed_name.replace(\"/\", \" \")\n",
    "    \n",
    "    processed_name_lower = processed_name.lower()\n",
    "    \n",
    "    processed_sans_sw = word_tokenize(processed_name)\n",
    "    processed_sans_sw = [word for word in processed_sans_sw if not word in stp_words]\n",
    "    abbr = [word[0] for word in processed_sans_sw if not word in stp_words]\n",
    "    abbr = \"\".join(abbr)\n",
    "    processed_sans_sw = \" \".join(processed_sans_sw)\n",
    "\n",
    "    return(processed_name, processed_name_lower, processed_sans_sw, abbr)\n",
    "\n",
    "\n",
    "def process_team_names(name):\n",
    "    \n",
    "    if (len(name) > 0):\n",
    "    \n",
    "        #Remove _,- and keep string in uppercase (to preserve some contextual information about proper nouns)\n",
    "        \n",
    "        name = string_process_no_stp_words(name)[0]\n",
    "        #name = name.replace(\"igem\", \" \")\n",
    "        #name = name.replace(\"team\", \" \")\n",
    "\n",
    "        if len(name) > 0:\n",
    "            return(name.strip())\n",
    "        \n",
    "        \n",
    "def process_request_regex(text, output_format = \"lol\", columns = [\"member\", \"matching\"]):\n",
    "    \n",
    "    if (output_format == \"lol\"):\n",
    "        \n",
    "        var = text\n",
    "        \n",
    "#        try:\n",
    "            \n",
    "#            var = var[var.find(\"[[\"):var.find(\"]]\")+2]\n",
    "#            var = ast.literal_eval(var)\n",
    "            \n",
    "#            processed_df = pd.DataFrame(data = var, columns = columns)\n",
    "        \n",
    "#        except:\n",
    "            \n",
    "        try:\n",
    "\n",
    "            var = text\n",
    "\n",
    "            var = re.findall(r'\\[[\"].*?[\"],[ ]?[\"].*?[\"]\\]', var)\n",
    "            var = [ast.literal_eval(x) for x in var]\n",
    "\n",
    "            var = [x if len(x) == 2 else None for x in var]\n",
    "            var = [x for x in var if x is not None]\n",
    "\n",
    "            if len(var) == 0:\n",
    "                return(pd.DataFrame(), 2)\n",
    "\n",
    "            processed_df = pd.DataFrame(var, columns = columns)   \n",
    "                \n",
    "        except:\n",
    "                \n",
    "            return(pd.DataFrame(), 0)\n",
    "            \n",
    "    return(processed_df, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e62a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"specific\"\n",
    "output_format = \"lol\"\n",
    "temperature_curation = 0.3\n",
    "\n",
    "#batches = os.listdir(\"../data/processed/batches_inter-team_collab//\")\n",
    "#batches = [batch.replace(\".csv\", \"\") for batch in batches]\n",
    "\n",
    "model = \"gpt-4-turbo\"\n",
    "#model = \"gpt-4-0125-preview\"\n",
    "#model = \"gpt-3.5-turbo-16k\"\n",
    "\n",
    "temperature = 0.3\n",
    "\n",
    "breaks = 10\n",
    "\n",
    "meta = pd.read_csv(\"../data/raw/team_meta.csv\")\n",
    "roster = pd.read_csv(\"../data/raw/teams_info_members_db.tsv\", sep=\"\\t\")\n",
    "\n",
    "years = [\"2015\", \"2016\", \"2017\", \"2018\"]\n",
    "#years = meta['Year'].unique()\n",
    "#years = sorted(years)\n",
    "\n",
    "#f = open(\"prompts/prompt_intra-team_matching_\" + output_format, \"r\")\n",
    "#prompt = f.read().rstrip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1947e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2015, 2016, 2017, 2018]\n",
    "df_names = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    df = pd.read_csv(\"../data/processed/gpt_curated/intra-team/processed_\" + str(year) + \"_\" + version + \"_\" + model + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\")\n",
    "    \n",
    "    df_names = df_names.append(df[[\"member\", \"team\", \"year\"]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0e13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28108e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3f258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65af8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"List 1 contains the names of members of a team. List 2 contains a list of names which may or may not be a member of the team.\n",
    "Find the closest match of each name in list 2 with list 1. If there is no possible good match - please mention 'other'.\n",
    "         \n",
    "Provide the output as a list of lists: [[\"name from the list 2\", \"closest match from list 1\"]]         \n",
    "            \n",
    "example: \n",
    "List 1: \"'Andrew Scott', 'Thomas Alves', 'Min Jang'\"\n",
    "List 2: \"'Andrew', 'Tommy Alves', 'Charles Jang', 'Sue Perkins'\"\n",
    "matches: [[\"Andrew\", \"Andrew Scott\"],[\"Tommy Alves\", Thomas Alves\"],[\"Charles Jang\", \"Min Jang\"], [\"Sue Perkins\",\"other\"]]\n",
    "\n",
    "Please make sure there is no extra text or explanation before or after the formatted output.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b55294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started year 2015\n",
      "finished year 2015 in 23.031932830810547 seconds\n",
      "Started year 2016\n",
      "finished year 2016 in 25.827670097351074 seconds\n",
      "Started year 2017\n",
      "finished year 2017 in 14.734761714935303 seconds\n",
      "Started year 2018\n",
      "finished year 2018 in 16.4371919631958 seconds\n"
     ]
    }
   ],
   "source": [
    "df_matching = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Started year \" + str(year))\n",
    "    \n",
    "    missed_entries = []\n",
    "    \n",
    "    temp = df_names[(df_names['year'] == year)]  \n",
    "    \n",
    "    teams = temp['team'].unique()\n",
    "    \n",
    "    all_messages = []\n",
    "    var = 0\n",
    "    \n",
    "    for team in teams:\n",
    "    \n",
    "        members = list(roster['UserName'][(roster['Year'] == year) & (roster['Team'] == team)].unique())\n",
    "        members = [unidecode(x) for x in members]\n",
    "        \n",
    "        names = list(temp['member'][temp['team'] == team].unique())\n",
    "        names = [unidecode(x) for x in names]\n",
    "        names = [process_team_names(x) for x in names if not x in members]\n",
    "    \n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        messages.append({\"role\": \"user\", \"content\": \"List 1:\"})\n",
    "\n",
    "        \n",
    "        messages.append({\"role\": \"user\", \"content\": \", \".join((\"\\\"\" + x + \"\\\"\") for x in members)})\n",
    "        messages.append({\"role\": \"user\", \"content\": \"List 2:\"})\n",
    "        messages.append({\"role\": \"user\", \"content\": \", \".join((\"\\\"\" + x + \"\\\"\") for x in names)})\n",
    "        \n",
    "        all_messages.extend([[messages, {\"year\": year, \"team\": team}, var]])\n",
    "        var = var + 1\n",
    "    \n",
    "    with Pool(processes = 8) as pool:\n",
    "        \n",
    "        zipped_output = pool.map(send_request_chat_competion, all_messages)\n",
    "        \n",
    "        for output, miss in list(zipped_output):\n",
    "            \n",
    "            df_matching = df_matching.append(output)\n",
    "            \n",
    "            if not miss == None:\n",
    "                \n",
    "                missed_entries.extend(all_messages[miss][0])\n",
    "            \n",
    "        time.sleep(0.01)\n",
    "            \n",
    "            \n",
    "    end = time.time()\n",
    "    time_elapsed = (end-start)\n",
    "    print(\"finished year \" + str(year) + \" in \" + str(time_elapsed) + \" seconds\")\n",
    "    \n",
    "    stats = stats.append(pd.DataFrame([[year, time_elapsed, str(missed_entries)]], columns=[\"year\", \"time_elapsed\", \"failed_chunks\"]))\n",
    "    time.sleep(1)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067ab96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba76a6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2fce92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29002cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching.to_csv(\"../data/processed/gpt_curated/intra-team/raw_member_matching_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)\n",
    "#stats.to_csv(\"../data/processed/curated/fuzzy_select_inter_team_raw/stats_team_name_matchings_new_\" + str(breaks) + \"_\" + version + \"_\" + output_format + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c7275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_processing = pd.DataFrame()\n",
    "\n",
    "df_interactions = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_csv(\"../data/processed/gpt_curated/intra-team/raw_member_matching_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\")+ \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\")\n",
    "    \n",
    "for loop_var in range(len(df)):\n",
    "    \n",
    "    t, flag = process_request_regex(str(df['text'][loop_var]))\n",
    "        \n",
    "    if (len(t) > 0):\n",
    "        \n",
    "        t['year'] = df['year'][loop_var]\n",
    "        t['team'] = df['team'][loop_var]\n",
    "            \n",
    "        df_interactions = df_interactions.append(t)                \n",
    "        \n",
    "    stats_processing = stats_processing.append(pd.DataFrame([[loop_var, flag]], columns=[\"row_no\", \"status\"]))\n",
    "    \n",
    "df_interactions.to_csv(\"../data/processed/gpt_curated/intra-team/processed_member_matching_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\")+ \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c9d1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b920afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
