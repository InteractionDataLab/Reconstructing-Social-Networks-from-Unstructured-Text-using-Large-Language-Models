{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2e87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import tiktoken\n",
    "import cleantext\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing import Pool\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#from ipynb.fs.full.gpt_curation_custom_functions import string_process_no_stp_words, process_team_names\n",
    "#from ipynb.fs.full.gpt_curation_custom_functions import fuzzy_match, fuzzy_search\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#Load the api key from being an environment variable\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "stats = pd.DataFrame()\n",
    "\n",
    "stp_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f169c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request_chat_competion(arguments, model = \"gpt-3.5-turbo-16k\", temperature = 0.3, output_format = \"lol\", columns = [\"team\", \"matching\"]):\n",
    "    \n",
    "    message = arguments[0]\n",
    "    variables = arguments[1]\n",
    "    chunk = arguments[2]\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(model = model, messages = message, temperature = temperature, request_timeout = 60)\n",
    "        final_response = response.choices[0].message[\"content\"].strip()\n",
    "    \n",
    "    except:\n",
    "        return(pd.DataFrame(), chunk)\n",
    "    \n",
    "    if (output_format == \"lol\"):\n",
    "        \n",
    "        var = final_response\n",
    "        processed_df = pd.DataFrame([[var]], columns=[\"text\"])\n",
    "            \n",
    "        for key, value  in variables.items():\n",
    "            processed_df[key] = value\n",
    "\n",
    "    return(processed_df, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb9deb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"two-step\"\n",
    "output_format = \"lol\"\n",
    "temperature_curation = 0.9\n",
    "\n",
    "#batches = os.listdir(\"../data/processed/text_batches_inter-team_filtered/\")\n",
    "#batches = [batch.replace(\".csv\", \"\") for batch in batches]\n",
    "\n",
    "batches = [\"1\", \"2\"]\n",
    "\n",
    "model = \"gpt-3.5-turbo-16k\"\n",
    "#model = \"gpt-4-0125-preview\"\n",
    "\n",
    "temperature = 0.3\n",
    "\n",
    "breaks = 10\n",
    "\n",
    "meta = pd.read_csv(\"../data/raw/team_meta.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e3ab46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_names = pd.DataFrame()\n",
    "\n",
    "for batch_no in batches:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        df = pd.read_csv(\"../data/processed/gpt_curated/inter-team/processed_\" + str(batch_no) + \"_\" + version + \"_\" + model + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\")\n",
    "    \n",
    "        df_names = df_names.append(df[[\"context\", \"year\"]])\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6688d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fadaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "Match each relationship name to the closest possible category listed below:\n",
    "\n",
    "Provide each matching as [[RELATIONSHIP, MATCHING CATEGORY]]\n",
    "\n",
    "The possible categories are:\n",
    "\n",
    "\"work\": Teams worked together or collaborated on aspects of their projects\n",
    "\"material transfer\": One team shared information, data, synthetic biology parts or laboratory materials with the other. \n",
    "\"advice\": One team gave advice or support to the other team concerning their project or about the competition.\n",
    "\"meetup\": Teams met each other at a meetup or in a social setting and discussed their project.\n",
    "\"other\": Contexts not fitting to the categories listed above.\n",
    "\n",
    "example: \"provided substrates to, participated in synthetic biology day with, did pct amplification for\"\n",
    "Matching: [[\"provided substrates to\", \"material transfer\"], [\"participated in synthetic biology day with\",\"meetup\"], [\"did pcr amplification for\",\"work\"]]\n",
    "\n",
    "example: \"provided thoughts and suggestions to\"\n",
    "Matching: [[\"provided thoughts and suggestions to\",\"advice\"]]\n",
    "\n",
    "The following are the list of relationships to match:\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61c7a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started year 2009\n",
      "finished year 2009 in 1.991706132888794 seconds\n",
      "Started year 2011\n",
      "finished year 2011 in 1.1019747257232666 seconds\n",
      "Started year 2012\n",
      "finished year 2012 in 0.9438886642456055 seconds\n",
      "Started year 2014\n",
      "finished year 2014 in 1.3459153175354004 seconds\n",
      "Started year 2015\n",
      "finished year 2015 in 6.0601646900177 seconds\n",
      "Started year 2016\n",
      "finished year 2016 in 4.832598924636841 seconds\n",
      "Started year 2017\n",
      "finished year 2017 in 6.0291595458984375 seconds\n",
      "Started year 2018\n",
      "finished year 2018 in 5.185008764266968 seconds\n"
     ]
    }
   ],
   "source": [
    "df_matching = pd.DataFrame()\n",
    "\n",
    "for year in sorted(df_names['year'].unique()):\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Started year \" + str(year))\n",
    "    \n",
    "    missed_entries = []\n",
    "    \n",
    "    temp = df_names[df_names['year'] == year] \n",
    "    \n",
    "    \n",
    "    l = list(temp['context'].unique())\n",
    "    l = [x for x in l if x == x] # To remove np.nan. Regular method seems to not work\n",
    "    \n",
    "    all_messages = []\n",
    "    var = 0\n",
    "    \n",
    "    for j in range(0,len(l),breaks):\n",
    "    \n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        messages.append({\"role\": \"user\", \"content\": ', '.join(l[j:min(j+breaks,len(l))])})\n",
    "        \n",
    "        all_messages.extend([[messages, {\"year\": year}, var]])\n",
    "        var = var + 1\n",
    "    \n",
    "    with Pool(processes = 8) as pool:\n",
    "        \n",
    "        zipped_output = pool.map(send_request_chat_competion, all_messages)\n",
    "        \n",
    "        for output, miss in list(zipped_output):\n",
    "            \n",
    "            output['year'] = year\n",
    "            df_matching = df_matching.append(output)\n",
    "            \n",
    "            if not miss == None:\n",
    "                \n",
    "                missed_entries.extend(all_messages[miss][0])\n",
    "            \n",
    "        time.sleep(0.01)\n",
    "            \n",
    "            \n",
    "    end = time.time()\n",
    "    time_elapsed = (end-start)\n",
    "    print(\"finished year \" + str(year) + \" in \" + str(time_elapsed) + \" seconds\")\n",
    "    \n",
    "    stats = stats.append(pd.DataFrame([[year, time_elapsed, str(missed_entries)]], columns=[\"year\", \"time_elapsed\", \"failed_chunks\"]))\n",
    "    time.sleep(1)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8addf926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "columns = [\"context\", \"category\"]\n",
    "stats_processing = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df_matching)):\n",
    "    \n",
    "    var = df_matching['text'].iloc[i]\n",
    "            \n",
    "    try:\n",
    "\n",
    "        var = df_matching['text'].iloc[i]\n",
    "\n",
    "        var = re.findall(r'\\[[\"].*?[\"],[ ]?[\"].*?[\"]\\]', var)\n",
    "        var = [ast.literal_eval(x) for x in var]\n",
    "\n",
    "        var = [x if len(x) == 2 else None for x in var]\n",
    "        var = [x for x in var if x is not None]\n",
    "\n",
    "        if len(var) == 0:\n",
    "            processed_df = pd.DataFrame()\n",
    "            stats_processing = stats_processing.append(pd.DataFrame([[i, 2]], columns = [\"row_no\", \"status\"]))\n",
    "\n",
    "        processed_df = pd.DataFrame(var, columns = columns)   \n",
    "                \n",
    "    except:\n",
    "                \n",
    "        processed_df = pd.DataFrame()\n",
    "        stats_processing = stats_processing.append(pd.DataFrame([[i, 0]], columns = [\"row_no\", \"status\"]))\n",
    "            \n",
    "    if len(processed_df) > 0:\n",
    "        df = df.append(processed_df)\n",
    "        stats_processing = stats_processing.append(pd.DataFrame([[i, 1]], columns = [\"row_no\", \"status\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ed71794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching.to_csv(\"../data/processed/gpt_curated/inter-team/context_matching_\" + version + \"_\" + breaks + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)\n",
    "stats.to_csv(\"../data/processed/gpt_curated/inter-team/stats_context_matching_\" + version + \"_\" + breaks + \"_\" +model + \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)\n",
    "stats_processing.to_csv(\"../data/processed/gpt_curated/inter-team/stats_context_matching_processing_\" + version + \"_\" + breaks + \"_\" + model+ \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)\n",
    "df.to_csv(\"../data/processed/gpt_curated/inter-team/processed_context_matching_\" + version + \"_\" + breaks + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2b731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088dc22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc34cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e26dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33348004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
