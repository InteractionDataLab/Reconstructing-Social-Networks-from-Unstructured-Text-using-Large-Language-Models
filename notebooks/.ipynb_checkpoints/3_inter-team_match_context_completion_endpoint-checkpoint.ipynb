{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94909cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import tiktoken\n",
    "import cleantext\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import ast\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing import Pool\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#Load the api key from being an environment variable\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "stats = pd.DataFrame()\n",
    "\n",
    "stp_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e970a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_batch_request(arguments, model = \"gpt-3.5-turbo-instruct\", temperature = 0.3, output_format = \"lol\", columns = [\"team\", \"context\", \"target\"]):\n",
    "    \n",
    "    \n",
    "    chunks = arguments\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    flag = []\n",
    "\n",
    "    try:\n",
    "    \n",
    "        response = openai.Completion.create(                                \n",
    "                    prompt = chunks ,\n",
    "                    engine = model,\n",
    "                    temperature = temperature,\n",
    "                    max_tokens = 2000,  \n",
    "                    top_p = 1,\n",
    "                    frequency_penalty = 0,\n",
    "                    presence_penalty = 0,\n",
    "                    timeout = 200\n",
    "                    )\n",
    "        \n",
    "    except:\n",
    "        return(df, 0)\n",
    "        \n",
    "    var = response.choices[0].text.strip()\n",
    "        \n",
    "    t = pd.DataFrame([[var]], columns=[\"text\"]) \n",
    "                    \n",
    "    df = df.append(t)\n",
    "    \n",
    "    return(df, 1)\n",
    "\n",
    "\n",
    "def string_process_no_stp_words(name):\n",
    "    \n",
    "    processed_name = name.strip()\n",
    "    \n",
    "    #processed_name = processed_name.replace(\"_\", \" \")\n",
    "    #processed_name = processed_name.replace(\"-\", \" \")\n",
    "    processed_name = processed_name.replace(\",\", \" \")\n",
    "    \n",
    "    processed_name_lower = processed_name.lower()\n",
    "    \n",
    "    processed_sans_sw = word_tokenize(processed_name)\n",
    "    processed_sans_sw = [word for word in processed_sans_sw if not word in stp_words]\n",
    "    abbr = [word[0] for word in processed_sans_sw if not word in stp_words]\n",
    "    abbr = \"\".join(abbr)\n",
    "    processed_sans_sw = \" \".join(processed_sans_sw)\n",
    "\n",
    "    return(processed_name, processed_name_lower, processed_sans_sw, abbr)\n",
    "\n",
    "\n",
    "def process_team_names(name):\n",
    "    \n",
    "    if (len(name) > 0):\n",
    "    \n",
    "        #Remove _,- and keep string in uppercase (to preserve some contextual information about proper nouns)\n",
    "        \n",
    "        name = string_process_no_stp_words(name)[0]\n",
    "        #name = name.replace(\"igem\", \" \")\n",
    "        #name = name.replace(\"team\", \" \")\n",
    "\n",
    "        if len(name) > 0:\n",
    "            return(name.strip())\n",
    "        \n",
    "\n",
    "def process_request_regex(text, output_format = \"lol\", columns = [\"team\", \"matching\"]):\n",
    "    \n",
    "    if (output_format == \"lol\"):\n",
    "        \n",
    "        var = text\n",
    "        \n",
    "#        try:\n",
    "            \n",
    "#            var = var[var.find(\"[[\"):var.find(\"]]\")+2]\n",
    "#            var = ast.literal_eval(var)\n",
    "            \n",
    "#            processed_df = pd.DataFrame(data = var, columns = columns)\n",
    "        \n",
    "#        except:\n",
    "            \n",
    "        try:\n",
    "\n",
    "            var = text\n",
    "\n",
    "            var = re.findall(r'\\[[\"].*?[\"],[ ]?[\"].*?[\"]\\]', var)\n",
    "            var = [ast.literal_eval(x) for x in var]\n",
    "\n",
    "            var = [x if len(x) == 2 else None for x in var]\n",
    "            var = [x for x in var if x is not None]\n",
    "\n",
    "            if len(var) == 0:\n",
    "                return(pd.DataFrame(), 2)\n",
    "\n",
    "            processed_df = pd.DataFrame(var, columns = columns)   \n",
    "                \n",
    "        except:\n",
    "                \n",
    "            return(pd.DataFrame(), 0)\n",
    "            \n",
    "    return(processed_df, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e62a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"two-step\"\n",
    "output_format = \"lol\"\n",
    "temperature_curation = 0.3\n",
    "\n",
    "#batches = os.listdir(\"../data/processed/batches_inter-team_collab/\")\n",
    "#batches = os.listdir(\"../data/processed/all_batches_inter-team_fuzzy_select_freq/\")\n",
    "#batches = [batch.replace(\".csv\", \"\") for batch in batches]\n",
    "\n",
    "batches = [\"1\", \"2\"]\n",
    "\n",
    "model = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "temperature = 0.3\n",
    "\n",
    "breaks = 10\n",
    "\n",
    "meta = pd.read_csv(\"../data/raw/team_meta.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1947e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "Match each relationship name to the closest possible category listed below:\n",
    "\n",
    "Provide each matching as [[RELATIONSHIP, MATCHING CATEGORY]]\n",
    "\n",
    "The possible categories are:\n",
    "\n",
    "\"work\": Teams worked together or collaborated on aspects of their projects\n",
    "\"material transfer\": One team shared information, data, synthetic biology parts or laboratory materials with the other. \n",
    "\"advice\": One team gave advice or support to the other team concerning their project or about the competition.\n",
    "\"meetup\": Teams met each other at a meetup or in a social setting and discussed their project.\n",
    "\"other\": Contexts not fitting to the categories listed above.\n",
    "\n",
    "example: \"provided substrates to, participated in synthetic biology day with, did pct amplification for\"\n",
    "Matching: [[\"provided substrates to\", \"material transfer\"], [\"participated in synthetic biology day with\",\"meetup\"], [\"did pcr amplification for\",\"work\"]]\n",
    "\n",
    "example: \"provided thoughts and suggestions to\"\n",
    "Matching: [[\"provided thoughts and suggestions to\",\"advice\"]]\n",
    "\n",
    "The following are the list of relationships to match:\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e68068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.DataFrame()\n",
    "\n",
    "for batch_no in batches:\n",
    "    \n",
    "    df = pd.read_csv(\"../data/processed/gpt_curated/inter-team/processed_\" + str(batch_no) + \"_\" + version + \"_\" + model + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\")\n",
    "    \n",
    "    df_names = df_names.append(df[[\"context\", \"year\"]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b55294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started year 2009\n",
      "finished year 2009 in 1.4602768421173096 seconds\n",
      "Started year 2011\n",
      "finished year 2011 in 0.9632911682128906 seconds\n",
      "Started year 2012\n",
      "finished year 2012 in 0.7175722122192383 seconds\n",
      "Started year 2013\n",
      "finished year 2013 in 1.4542913436889648 seconds\n",
      "Started year 2014\n",
      "finished year 2014 in 1.2094769477844238 seconds\n",
      "Started year 2015\n",
      "finished year 2015 in 14.971787452697754 seconds\n",
      "Started year 2016\n",
      "finished year 2016 in 26.7225284576416 seconds\n",
      "Started year 2017\n"
     ]
    }
   ],
   "source": [
    "df_matching = pd.DataFrame()\n",
    "\n",
    "for year in sorted(df_names['year'].unique()):\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Started year \" + str(year))\n",
    "    \n",
    "    missed_entries = []\n",
    "    \n",
    "    temp = df_names[df_names['year'] == year] \n",
    "    \n",
    "    l = list(temp['context'].unique())\n",
    "    l = [x for x in l if x == x]\n",
    "    \n",
    "    all_messages = []\n",
    "    var = 0\n",
    "    \n",
    "    #batch['processed_text'] =  prompt + \"We are team \" + batch['team'] + \"\\n.\" + \"The following text describes our activities in a scientific competition called iGEM including our relationships with other teams:\" +  batch['text']\n",
    "    \n",
    "    for j in range(0,len(l),breaks):        \n",
    "        \n",
    "        text = prompt +  ', '.join(l[j:min(j+breaks,len(l))])\n",
    "        \n",
    "        all_messages.extend([text])\n",
    "        var = var + 1\n",
    "    \n",
    "    for message in all_messages:\n",
    "        \n",
    "        output, miss = send_batch_request(message)\n",
    "        output['year'] = year\n",
    "        \n",
    "        df_matching = df_matching.append(output)\n",
    "        \n",
    "        if miss == 0:\n",
    "            missed_entries.extend(all_messages[miss][0])\n",
    "    \n",
    "    #After support for the old endpoint ended early 2024, parallel processing seems to fail much more than before.\n",
    "        \n",
    "    #with Pool(processes = 8) as pool:\n",
    "        \n",
    "    #    zipped_output = pool.map(send_request_chat_competion, all_messages)\n",
    "        \n",
    "    #    for output, miss in list(zipped_output):\n",
    "            \n",
    "    #        df_matching = df_matching.append(output)\n",
    "            \n",
    "    #        if not miss == None:\n",
    "                \n",
    "    #            missed_entries.extend(all_messages[miss][0])\n",
    "            \n",
    "        time.sleep(0.01)\n",
    "            \n",
    "            \n",
    "    end = time.time()\n",
    "    time_elapsed = (end-start)\n",
    "    print(\"finished year \" + str(year) + \" in \" + str(time_elapsed) + \" seconds\")\n",
    "    \n",
    "    stats = stats.append(pd.DataFrame([[year, time_elapsed, str(missed_entries)]], columns=[\"year\", \"time_elapsed\", \"failed_chunks\"]))\n",
    "    time.sleep(1)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4527e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "columns = [\"context\", \"category\"]\n",
    "stats_processing = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df_matching)):\n",
    "    \n",
    "    var = df_matching['text'].iloc[i]\n",
    "    \n",
    "            \n",
    "    try:\n",
    "\n",
    "        var = df_matching['text'].iloc[i]\n",
    "\n",
    "        var = re.findall(r'\\[[\"].*?[\"],[ ]?[\"].*?[\"]\\]', var)\n",
    "        \n",
    "        var = [ast.literal_eval(x) for x in var]\n",
    "\n",
    "        var = [x if len(x) == 2 else None for x in var]\n",
    "        var = [x for x in var if x is not None]\n",
    "\n",
    "        if len(var) == 0:\n",
    "            processed_df = pd.DataFrame()\n",
    "            stats_processing = stats_processing.append(pd.DataFrame([[i, 2]], columns = [\"row_no\", \"status\"]))\n",
    "\n",
    "        processed_df = pd.DataFrame(var, columns = columns)   \n",
    "                \n",
    "    except:\n",
    "                \n",
    "        processed_df = pd.DataFrame()\n",
    "        stats_processing = stats_processing.append(pd.DataFrame([[i, 0]], columns = [\"row_no\", \"status\"]))\n",
    "            \n",
    "    if len(processed_df) > 0:\n",
    "        df = df.append(processed_df)\n",
    "        stats_processing = stats_processing.append(pd.DataFrame([[i, 1]], columns = [\"row_no\", \"status\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de18915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching.to_csv(\"../data/processed/curated/collab_inter-team_versions/context_matching_\" + version + \"_\" + model + \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)\n",
    "stats.to_csv(\"../data/processed/curated/collab_inter-team_versions/stats_context_matching_\" + version + \"_\" + model+ \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)\n",
    "stats_processing.to_csv(\"../data/processed/curated/collab_inter-team_versions/stats_context_matching_processing_\" + version + \"_\" + model+ \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)\n",
    "df.to_csv(\"../data/processed/curated/collab_inter-team_versions/processed_context_matching_\" + version + \"_\" + model+ \"_\" + str(temperature).replace(\".\",\"-\") + \"_\" + str(temperature_curation).replace(\".\",\"-\") + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc17e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4ecdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c4949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1600b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
