<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_Kent_Algorithm skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:Kent/Algorithm</SPAN></H1></DIV><DIV id="HQ_page"><DIV id="bodyContent"><DIV id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><DIV class="menu_wrapper"><DIV class="nav"><LABEL for="show-menu" class="show-menu">Show Menu</LABEL><DIV class="nav_hide"><DIV class="nav_menu_item hvr-fade"><DIV class="nav_link"><A href="https://2016.igem.org/Team:Kent">Home</A></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="toggleTeam" class="toggle_nav nav_link hvr-fade">Team</LABEL><DIV class="nav_submenu" id="toggleTeam_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Team">Meet the team</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Attributions">Attributions</A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="toggleProject" class="toggle_nav nav_link hvr-fade">Project</LABEL><DIV class="nav_submenu" id="toggleProject_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Description">Description</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Experiments">Experiments</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Results">Results</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Safety"> Safety </A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Achievements">Achievements</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://igem.org/2016_Judging_Form?id=1985">Judging</A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="toggleParts" class="toggle_nav nav_link hvr-fade">Parts</LABEL><DIV class="nav_submenu" id="toggleParts_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Parts">Overview</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Basic">Basic</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Composite_Part">Composite</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Part_Collection"> Collection</A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="togglePractices" class="toggle_nav nav_link hvr-fade"><A href="https://2016.igem.org/Team:Kent/Human_Practices">Practices</A></LABEL><DIV class="nav_submenu" id="togglePractices_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Human_Practices">HP</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Collaborations">  Collaborations </A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="toggleModelling" class="toggle_nav nav_link hvr-fade">Modelling</LABEL><DIV class="nav_submenu" id="toggleModelling_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Model">Introduction</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Algorithm">Algorithm</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Methodology">Methodology</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/ModelResults">Results</A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><DIV class="nav_link"><A href="https://2016.igem.org/Team:Kent/Notebook">Notebook</A></DIV></DIV></DIV></DIV><DIV class="nav_replace">
    Navigation
  </DIV><UL id="accordion" class="top_menu"><LI class="menu_item"><A href="https://2016.igem.org/Team:Kent">HOME </A></LI><LI class="menu_item"> TEAM
			</LI><LI><A href=" https://2016.igem.org/Team:Kent/Team"> Team   </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Collaborations">★  Collaborations </A></LI></UL><LI class="menu_item"> PROJECT  
			</LI><LI><A href="https://2016.igem.org/Team:Kent/Description"> ★  Description </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Design"> ★ Design </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Experiments"> Experiments </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Proof"> ★ Proof of Concept </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Demonstrate"> ★ Demonstrate </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Results"> Results </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Notebook"> Notebook </A></LI><LI class="menu_item"> PARTS  
			</LI><LI><A href="https://2016.igem.org/Team:Kent/Parts">Parts </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Basic_Part"> ★ Basic Parts </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Composite_Part"> ★ Composite Parts </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Part_Collection"> ★ Part Collection </A></LI><LI class="menu_item"><A href="https://2016.igem.org/Team:Kent/Safety"> SAFETY </A></LI><LI class="menu_item"><A href="https://2016.igem.org/Team:Kent/Attributions"> ATTRIBUTIONS </A></LI><LI class="menu_item"> PRACTICES 
			</LI><LI><A href="https://2016.igem.org/Team:Kent/Human_Practices"> Human Practices </A></LI><LI><A href="https://2016.igem.org/Team:Kent/HP/Silver">★ Silver </A></LI><LI><A href="https://2016.igem.org/Team:Kent/HP/Gold">★ Gold </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Integrated_Practices"> ★ Integrated Practices </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Engagement">★ Engagement </A></LI><LI class="menu_item"> AWARDS 
			</LI><LI><A href="https://2016.igem.org/Team:Kent/Entrepreneurship"> ★ Entrepreneurship </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Hardware"> ★ Hardware </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Software">★ Software </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Measurement">★  Measurement </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Model">★ Model </A></LI></DIV><DIV class="content_wrapper"><DIV class="top"><H1 class="first_title">Algorithm – Gibbs Sampling</H1><P>We used Gibbs sampling which is one of the algorithms that is used by LDA models [6].
To explain exactly how this algorithm works, let us split the process of the algorithm into steps for better
explanation and understanding.</P></DIV><DIV class="subs"><H2 class="sub_titles">Initialise Parameters</H2><P>It is also important to tell the algorithm how many topics to find and this is a draw back because you are
required to know the notion of the number of topics you want to find. Testing is, therefore, required
to confirm whether the results are satisfying.
Number of iteration is also needs to be tested and optimal number of iteration is found when the model is
converging. In other words, until the model produces same/very similar results.
The hyperparameters, alpha and beta, are parameters of a prior distribution. Prior distribution is the
probability distribution that expresses the uncertainty of the variable before the data is taken into account [7].
Hyperparameter is determined by statistical models such as the L-Tangent Norm [8].</P><H2 class="sub_titles">Initialise Topic Assignments Randomly</H2><P>After initializing the parameters, the algorithm will initiate random assignment of topics to each word in a
document.</P><H2 class="sub_titles">Iterate</H2><P>Based on initial parameters, such as number of topics (K), and assignments (W and Z) the algorithm will compute frequency of words in each topics and distribution of topics in documents.
Therefore, it will create these temporary variables named as and , where is the word distribution for topic
and is the topic distribution for document.

Therefore, it will create these temporary variables named as ϕ(k) and θ(i), where ϕ(k) is the word distribution for topic k and θ(i) is the topic distribution for document i.</P><H2 class="sub_titles">Resampling</H2><P>Topic of each word in each document is resampled, given all the other words and their current topic assignments. This is ultimately answering the following questions:</P><UL><LI>Which topics occur in this document?
  </LI><LI>Which topics like the word Y?
 </LI></UL>

After the resampling is carried out until conversion (optimal number of iterations), ϕ(k) and θ(i)  will have definitive distribution.

<H2 class="sub_titles">Gibbs Sampling: Mathematical Description</H2><P>The collection of documents is represented by a set of word indices w<SUB>i</SUB> and document indices d<SUB>i</SUB> for each token i. Gibbs sampling then considers each word in token in the text collection in turn then estimates the probability of assigning the current word token to each topic. From this conditional distribution, a topic is sampled and stored as the new topics assignment for this word token.  This conditional distribution can be written as:</P>

Where z<SUB>i</SUB>=j represents the topic assignment of topic i to topic j,  z<SUB>-i</SUB> refers to the topic assignments of all the other word tokens and “.” refers to all the other known or observed information such as all the other word tokens w<SUB>-i</SUB> and document indices d<SUB>-i</SUB> and hyperparameters α and β.
This is calculated by:


Thus, 


Where C<SUP>WT</SUP> and C<SUP>DT</SUP> are matrices of counts with dimensions W×T and D×T respectively; C<SUP>DT</SUP><SUB>dj</SUB> contains the number of times topic j is assigned to some word token in document d, not including the current instance i. [9]





</DIV></DIV></DIV></DIV></DIV></DIV></DIV></BODY></HTML>