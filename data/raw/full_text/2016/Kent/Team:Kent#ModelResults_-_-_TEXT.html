Team:Kent/ModelResults
Show Menu
Home
Team
Meet the team
Attributions
Project
Description
Experiments
Results
Safety
Achievements
Judging
Parts
Overview
Basic
Composite
Collection
Practices
HP
Collaborations
Modelling
Introduction
Algorithm
Methodology
Results
Notebook
Navigation
HOME
TEAM
Team
★  Collaborations
PROJECT
★  Description
★ Design
Experiments
★ Proof of Concept
★ Demonstrate
Results
Notebook
PARTS
Parts
★ Basic Parts
★ Composite Parts
★ Part Collection
SAFETY
ATTRIBUTIONS
PRACTICES
Human Practices
★ Silver
★ Gold
★ Integrated Practices
★ Engagement
AWARDS
★ Entrepreneurship
★ Hardware
★ Software
★  Measurement
★ Model
Results
In our topic model there was no cleaning of the words, meaning words without meaning such as “is”, “and”, “a” etc. were included in the data. Therefore, these meaningless words were considered as topic by the model as they do appear very frequently. Therefore, we manually removed them from the final result as it has no meaning. As our aim was to use topic model as a quantitative tool, maps created to visualise the topic distribution of each subject are presented in the Human Practice section here .
References
"David M. Blei", Cs.princeton.edu, 2016. [Online]. Available: https://www.cs.princeton.edu/~blei/topicmodeling.html. [Accessed: 17- Oct- 2016].
"What is machine learning? - Definition from WhatIs.com", WhatIs.com, 2016. [Online]. Available: http://whatis.techtarget.com/definition/machine-learning. [Accessed: 17- Oct- 2016].
Additive Models, Trees, and Related Methods, 2nd ed. Springer Science+Business Media, 2011.
T. Hofmann, Machine Learning, vol. 42, no. 12, pp. 177-196, 2001.
L. Kaufman and P. Rousseeuw, Finding groups in data. New York: Wiley, 1990.
X. Wei and W. Croft, LDA_Based Document Models for Ad-hoc Retrieval, 1st ed. Amherst: University of Massachusetts Amherst.
"IGI Global", Igi-global.com, 2016. [Online]. Available: http://www.igi global.com/dictionary/hyperparameter/13541]. [Accessed: 17- Oct- 2016].
"Hyperparameters", Brnt.eu, 2016. [Online]. Available: http://www.brnt.eu/phd/node14.html#sec:hyperp. [Accessed: 17- Oct- 2016].
M. Steyvers and T. Griffiths, Probabilistic Topic Models, 1st ed. p. 8.
"Topic Modeling Toolbox", Psiexp.ss.uci.edu, 2016. [Online]. Available: http://psiexp.ss.uci.edu/research/programs_data/toolbox.htm#. [Accessed: 17- Oct- 2016].
"MIT CSAIL Research Abstracts", Publications.csail.mit.edu, 2016. [Online]. Available: http://publications.csail.mit.edu/abstracts/abstracts06/bohsu/bohsu.html. [Accessed: 18- Oct- 2016].
"Example 1 of running HMM-LDA topic model", Psiexp.ss.uci.edu, 2016. [Online]. Available: http://psiexp.ss.uci.edu/research/programs_data/exampleLDAHMM1.html. [Accessed: 17- Oct- 2016].
H. Chang, J. Boyd-graber, C. Wang, S. Gerrish and D. M. Blei, Reading Tea Leaves: How Humans Interpret Topic Models, 1st ed. Vancouver, BC: Neural Information Processing Systems, 2009, p. 3.
"Notebook", Radimrehurek.com, 2016. [Online]. Available: http://radimrehurek.com/topic_modeling_tutorial/2%20-%20Topic%20Modeling.html. [Accessed: 17- Oct- 2016].
D. Mimno, The details: training and validating big models on big data, 1st ed. Princeton University, Computer Science, 2012, p. 48.
