<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_Kent_Model skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:Kent/Model</SPAN></H1></DIV><DIV id="HQ_page"><DIV id="bodyContent"><DIV id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><DIV class="menu_wrapper"><DIV class="nav"><LABEL for="show-menu" class="show-menu">Show Menu</LABEL><DIV class="nav_hide"><DIV class="nav_menu_item hvr-fade"><DIV class="nav_link"><A href="https://2016.igem.org/Team:Kent">Home</A></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="toggleTeam" class="toggle_nav nav_link hvr-fade">Team</LABEL><DIV class="nav_submenu" id="toggleTeam_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Team">Meet the team</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Attributions">Attributions</A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="toggleProject" class="toggle_nav nav_link hvr-fade">Project</LABEL><DIV class="nav_submenu" id="toggleProject_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Description">Description</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Experiments">Experiments</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Results">Results</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Safety"> Safety </A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Achievements">Achievements</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://igem.org/2016_Judging_Form?id=1985">Judging</A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="toggleParts" class="toggle_nav nav_link hvr-fade">Parts</LABEL><DIV class="nav_submenu" id="toggleParts_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Parts">Overview</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Basic">Basic</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Composite_Part">Composite</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Part_Collection"> Collection</A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="togglePractices" class="toggle_nav nav_link hvr-fade"><A href="https://2016.igem.org/Team:Kent/Human_Practices">Practices</A></LABEL><DIV class="nav_submenu" id="togglePractices_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Human_Practices">HP</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Collaborations">  Collaborations </A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><LABEL for="toggleModelling" class="toggle_nav nav_link hvr-fade">Modelling</LABEL><DIV class="nav_submenu" id="toggleModelling_submenu"><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Model">Introduction</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Algorithm">Algorithm</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/Methodology">Methodology</A></DIV><DIV class="nav_menu_subitem hvr-fade"><A href="https://2016.igem.org/Team:Kent/ModelResults">Results</A></DIV></DIV></DIV><DIV class="nav_menu_item hvr-fade"><DIV class="nav_link"><A href="https://2016.igem.org/Team:Kent/Notebook">Notebook</A></DIV></DIV></DIV></DIV><DIV class="nav_replace">
    Navigation
  </DIV><UL id="accordion" class="top_menu"><LI class="menu_item"><A href="https://2016.igem.org/Team:Kent">HOME </A></LI><LI class="menu_item"> TEAM
			</LI><LI><A href=" https://2016.igem.org/Team:Kent/Team"> Team   </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Collaborations">★  Collaborations </A></LI></UL><LI class="menu_item"> PROJECT  
			</LI><LI><A href="https://2016.igem.org/Team:Kent/Description"> ★  Description </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Design"> ★ Design </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Experiments"> Experiments </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Proof"> ★ Proof of Concept </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Demonstrate"> ★ Demonstrate </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Results"> Results </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Notebook"> Notebook </A></LI><LI class="menu_item"> PARTS  
			</LI><LI><A href="https://2016.igem.org/Team:Kent/Parts">Parts </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Basic_Part"> ★ Basic Parts </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Composite_Part"> ★ Composite Parts </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Part_Collection"> ★ Part Collection </A></LI><LI class="menu_item"><A href="https://2016.igem.org/Team:Kent/Safety"> SAFETY </A></LI><LI class="menu_item"><A href="https://2016.igem.org/Team:Kent/Attributions"> ATTRIBUTIONS </A></LI><LI class="menu_item"> PRACTICES 
			</LI><LI><A href="https://2016.igem.org/Team:Kent/Human_Practices"> Human Practices </A></LI><LI><A href="https://2016.igem.org/Team:Kent/HP/Silver">★ Silver </A></LI><LI><A href="https://2016.igem.org/Team:Kent/HP/Gold">★ Gold </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Integrated_Practices"> ★ Integrated Practices </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Engagement">★ Engagement </A></LI><LI class="menu_item"> AWARDS 
			</LI><LI><A href="https://2016.igem.org/Team:Kent/Entrepreneurship"> ★ Entrepreneurship </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Hardware"> ★ Hardware </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Software">★ Software </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Measurement">★  Measurement </A></LI><LI><A href="https://2016.igem.org/Team:Kent/Model">★ Model </A></LI></DIV><DIV class="content_wrapper"><DIV class="top"><H1 class="first_title">Model</H1><P>We live in an age where information is abundant and easily accessible, an information age. Not only they are
available but they are crucial part of our modern day society. An easy example would be Google which uses
topic model algorithm (a branch of machine learning) to cluster the terms entered into their search engine.
This allows them to do market segmentation, learning people’s preferences, predict search terms and build a
content recommendation system. An example would be the annoying Google ads that we deal with everyday. By knowing this it is clear
that Google isn’t the only one who is implementing this tool, big companies like Facebook, amazon, Yahoo etc.
are all taking advantage and constantly improving their model.

Knowing the capabilities of topic models, we decided to practice and apply it to analyse our project aims
quantitatively as a part of our integrated human practices. Big Data approach such as topic modelling could
prove itself to be a powerful and useful quantitative tool for iGEM projects. From this our main aim was to
analyse our hypothesis and its impact in society and in synthetic biology communities.</P></DIV><DIV class="subs"><H2 class="sub_titles">Topic Model</H2><P>Topic model allows us to identify boardbroad and subtitle patterns in a particular subject that we would
otherwise unable to detect due to our inability to process such a huge collection of texts [1]. This is very useful as it provides a simple way to analyse large volumes of unlabelled text. In
other words, identifying the topic on which the specific content is talking about. One of the applications is text
summarisation which basically summarises the data presented to the user, and an example of the technology
that utilises this would be search engines such as Google.</P><H2 class="sub_titles">Background – What is Topic Modelling?</H2><P>Topic modelling is one of many applications of machine learning which is a type of artificial intelligence (AI)
that grants computers with the ability to learn without being explicitly programmed [2]. It looks for patterns in
data but also uses the extracted data to detect patterns in data and adjust its program actions accordingly.
There are two main groups of machine learning applications: Supervised learning and unsupervised learning.</P><P>As seen in figure 1, if the datasets contain labels it is classed as supervised learning. Under supervised
learning if the label is categorical it is talking about classification and if the label is quantitative it is talking
about regression [3]. In unsupervised learning there are no such labels therefore clustering of the datasets or
finding latent variables/structure in the datasets is performed [4].</P><P>Clustering or cluster analysis groups a set of similar objects closer together, in comparison to other objects in
the same set of data [5].
To get more general understanding here are the characteristics of topic models:</P><UL><LI>Exploratory: to discover, browse or search large collections of unlabelled text data
  </LI><LI>Latent variables: extracting hidden thematic structure (not labelled). It could be abstract topics, which
could be a cluster of words and together they have some kind of meaning
  </LI><LI>Clustering: cluster of words and collection of documents
 </LI></UL><H2 class="sub_titles">Types of Clustering and Topic Model Clustering</H2><P>In machine learning there are actually different kinds of clustering:</P><P>Hard clustering is where each instance of your dataset can only belong to one cluster as there are hard division
on lines.
Hierarchical clustering includes sub clusters in the cluster itself where the sub clusters have ‘child and parent’
like relationships.
Soft/Fuzzy clustering is used by topic modelling. Each instance can belong to each cluster with certain
degree. Certain degree can be thought of as a percentage or a probability.</P><H2 class="sub_titles">Understanding the Machine Learning Algorithm</H2><P>It is important to know what a program does before asking how it works. The black box in figure 3 represents
the algorithm of a topic model. As illustrated above, input is going to be a collection of text documents and
there will be three outputs:</P><UL><LI>Cluster of words where each cluster will define a topic
  </LI><LI>Frequency of the words appearing in the topics
  </LI><LI>Distribution of topics in documents. For an example, politic and cultures might appear in the same
document and such.
 </LI></UL>


 Furthermore, we know that one word can belong to several clusters meaning words have different meaning in
different contexts. This is also represented in this type of modelling.
<H2 class="sub_titles">Latent Dirichlet Allocation</H2><P>One of the popular algorithm in topic modelling is called Latent Dirichlet Allocation, commonly known as LDA.
However, there is another model (not topic) called LDA but it stands for Linear Discriminant analysis which is
used for supervised learning. Hence, these two LDAs have no relation to each other therefore it is important to
be clear about which LDA model is being referred to early. And of course we are only concerned with Latent
Dirichlet Allocation.</P></DIV></DIV></DIV></DIV></DIV></DIV></DIV></BODY></HTML>