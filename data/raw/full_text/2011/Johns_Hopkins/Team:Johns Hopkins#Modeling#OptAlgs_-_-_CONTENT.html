<HTML xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki  ltr ns-0 ns-subject page-Team_Johns_Hopkins_Modeling_OptAlgs"><DIV id="globalWrapper"><DIV id="top-section"><DIV id="p-logo"><A href="/Main_Page" title="Main Page">&quot;
	    </A></DIV><DIV id="menubar" class="left-menu noprint"><UL><LI class="selected"><A href="/Team:Johns_Hopkins/Modeling/OptAlgs">Page               </A></LI><LI class="new"><A href="/wiki/index.php?title=Talk:Team:Johns_Hopkins/Modeling/OptAlgs&amp;action=edit&amp;redlink=1">Discussion               </A></LI><LI><A href="/wiki/index.php?title=Team:Johns_Hopkins/Modeling/OptAlgs&amp;action=edit">View source               </A></LI><LI><A href="/wiki/index.php?title=Team:Johns_Hopkins/Modeling/OptAlgs&amp;action=history">History               </A></LI><LI style="color:#808080;cursor:default">teams</LI></UL></DIV><DIV class="right-menu noprint" id="menubar"><UL><LI id="pt-login"><A href="/wiki/index.php?title=Special:UserLogin&amp;returnto=Team:Johns_Hopkins/Modeling/OptAlgs" title="You are encouraged to log in; however, it is not mandatory [o]" accesskey="o">Log in</A></LI></UL></DIV><DIV id="search-controls" class="noprint"><FORM action="/Special:Search" id="searchform"> </FORM></DIV></DIV><DIV id="content"><H1 class="firstHeading">Team:Johns Hopkins/Modeling/OptAlgs</H1><DIV id="bodyContent"><H3 id="siteSub" class="noprint">From 2011.igem.org</H3><P><TITLE>VitaYeast - Johns Hopkins University, iGEM 2011</TITLE></P><DIV id="mydroplinemenu" class="droplinebar"><UL><LI><A href="#">Team</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Team/Members">Members</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Team/Acknowledgements">Acknowledgements</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Team/Advisors">Advisors</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Team/Sponsors">Sponsors</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Team/Attributions">Attributions</A></LI><LI><A href="/Team:Johns_Hopkins/Team/Gallery">Gallery</A></LI></UL><LI><A href="#">Vitamins</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Vit/Bg">Background</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Vit/Over">Overview</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Project/VitA">Vitamin A</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Project/VitC">Vitamin C</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Project/MeasureQuant">Measurements</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Project/Baking">Applications</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Vit/Results">Results</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Vit/Future">Future Plans</A></LI><LI><A href="#">Yeast Toolkit</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/YT/Bg">Background</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/YT/Over">Overview</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Project/PromUTR">Promoters and UTRs</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Project/Violacein">Violacein</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Project/Vector">Yeast Vector Library</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/YT/Results">Results</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/YT/Future">Future Plans</A></LI><LI><A href="#">Human Practices</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/HumanPrac">Overview</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/IRBProcess">IRB Approval</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Data">Data</A></LI><LI><A href="#">Modeling</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Modeling/Platforms">Platform</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Modeling/LBSMod">LBS Models</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Modeling/Opt">Optimization</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Modeling/Sensitivity">Sensitivity</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Modeling/ParaFit">Parameter Fitting</A></LI><LI><A href="#">Notebook</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Notebook/Protocols">Protocols</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Notebook/VitExperiments">Vitamin Experiments</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Notebook/YTExperiments">Yeast Toolkit Experiments</A></LI><LI><A href="https://2011.igem.org/Team:Johns_Hopkins/Safety">Safety</A></LI></DIV><DIV id="secondarycontentblue"><DIV id="boxheading">
			Related Links:</DIV><DIV id="boxcontent"><DL><DIV class="heading">Vitamin A:</DIV><DD><A href="#">Project</A></DD><DD><A href="#">Parts</A></DD></DL><DIV class="heading">Modeling:</DIV><DL><DD><A href="#">Modeling Platforms</A></DD><DD><A href="#">Analytic Methods</A></DD><DD><A href="https://2011.igem.org/Team:Johns_Hopkins/Modeling/Opt">Optimization</A></DD><DD><A href="#">Gene Expression</A></DD><DD><A href="#">Vitamin A</A></DD><DD><A href="#">Vitamin C</A></DD></DL></DIV></DIV><DIV id="primarycontent"><H6><SPAN class="mw-headline" id="CMA-ES"> CMA-ES </SPAN></H6>
The covariance matrix adaptation evolution strategy algorithm is stochastic in its selection of points to sample and does not require the approximation of derivatives<SUP><A href="#Foot1">[1]</A></SUP>. The algorithm begins with an initial mean and covariance matrix. At each generation (iteration) the mean and covariance matrix are used to generate samples from a multivariate normal distribution with the same dimensionality as the feasible region.<DIV class="thumb tright"><DIV class="thumbinner" style="width:302px;"><DIV class="thumbcaption">CMA-ES involves an evolution strategy for both a mean and a covariance matrix</DIV></DIV></DIV> The objective is evaluated at these sampled points. The points are ordered from smallest objective value (winners) to greatest value (losers). A weighted average of the list is taken in order to pick a new mean with more weight given to the winners. Of the μ points picked, the best λ are reserved to be carried over into the next round.
<P>This procedure is a form of maximum likelihood estimation. The weighting scheme attempts to select a new mean that will maximize the likelihood of best winners from generation N being picked in generation N+1. At the same time, the covariance matrix is also updated. This update is performed such that the best <I>generations</I> are more likely. Thus the distribution moves anisotropically: both the center of the distribution and the shape of the distribution change as it searches for a minimum.
</P><H6><SPAN class="mw-headline" id="DIRECT"> DIRECT </SPAN></H6><P>User Guide can be found <A href="https://static.igem.org/mediawiki/2011/d/db/Direct_optimization.pdf" class="external text" rel="nofollow">here</A>.
</P><P>Abbreviation of DIviding RECTangles, which is how the algorithm searches for the optimum value by globally converging on the minimal value<SUP><A href="#Foot2">[2]</A></SUP>. The algorithm belongs to the class of branch-and-bound optimizers. It is deterministic and performs relatively few function evaluations, but performs very poorly on &quot;hilly&quot; objective functions. However, since it does not require many evaluations of the objective, it is especially useful for simulations and &quot;black box&quot; functions.
</P>
Previous algorithms evaluate endpoints of regions in a function, but this is difficult in higher dimensions. To address this, DIRECT samples the midpoints of each area. Also, it looks at the entire sample region to determine if it should be broken into sub-regions during the iteration.
<P>To begin, DIRECT transforms the domain into a hyper-cube, divides it into regions depending on how optimal is, and continues to divide it into optimal hyper-rectangles. The algorithm then samples the center of each one. Once the algorithm finds a potentially optimal hyper-rectangle, it will divide it into smaller ones so that the area shrinks with each iteration. DIRECT stops when it is within 0.01% of the local minimum.
</P><H6><SPAN class="mw-headline" id="Implicit_Filtering">Implicit Filtering</SPAN></H6><P>&quot;Implicit ﬁltering is a hybrid of a projected quasi-Newton or Gauss-Newton algorithm for bound constrained optimization and nonlinear least squares problems and a deterministic grid-based search algorithm. The gradients for the quasi-Newton method and the Jacobians for the Gauss-Newton iteration are approximated with ﬁnite diﬀerences, and the diﬀerence increment varies as the optimization progresses. The points on the diﬀerence stencil are also used to guide a direct search.&quot;<SUP><A href="#Foot3">[3]</A></SUP></P><P>Implicit filtering works by minimizing an object function, f, in which f is constrained in a nominal design space, Ω, that is a hyperrectangle: 
</P><P>\[\Omega = \left ( x\in R^{N}\mid L_{i}\leq x_{i}\leq U_{i} \right )\]
</P><P>NOTE:
&quot;Implicit ﬁltering, and the other methods that are derived from coordinate search, are best used in cases where f is either not smooth, not everywhere deﬁned, discontinuous, or when derivatives of f are too costly to obtain. The motivating examples for the construction of implicit ﬁltering were problems in which f was a smooth function corrupted by low-amplitude, high-frequency noise, or which was not deﬁned (i.e. the code for computing f failed) at many points in the nominal design space Ω.&quot;<SUP><A href="#Foot4">[4]</A></SUP></P><P>Implicit filtering is a sampling method, in which f is only evaluated at a cluster of points in Ω. This evaluation determines the next cluster of points. This is done using a stencil. The stencil used in implicit filtering evaluates the function at a current iterate called \[f(x_{c})\] then samples the next 2N points on \[x_{c}\pm h*v_{i};1\leq i\leq N\] where \[v_{i} = e_{i}(L_{i}-U_{i})\] 
</P><P>e is the unit vector in the ith coordinate direction, and h, the scale varies as the optimization progresses. 
</P><P>Implicit filtering uses the values of f on the stencil to create a diﬀerence gradient which is then used in a quasi-Newton method. Results at each quasi-Newton iteration are reported. When the supply of scales, h, has been exhausted, the optimization will terminate.
</P><H6><SPAN class="mw-headline" id="Differential_Evolution"> Differential Evolution </SPAN></H6><P>It is a stochastic, population-based optimization evolutionary algorithm. It was developed to optimize real parameter, real valued functions.
It is a method that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. It does not guarantee an optimal solution is ever found.
DE algorithm works by having a population of candidate solutions (called agents). These agents are moved around in the search-space by using simple mathematical formulae to combine the positions of existing agents from the population. If the new position of an agent is an improvement it is accepted and forms part of the population, otherwise the new position is simply discarded. The process is repeated and by doing so it is hoped, but not guaranteed, that a satisfactory solution will eventually be discovered.
</P><P>General evolutionary algorithm procedure:
Initialization -&gt; Mutation -&gt; Recombination -&gt; Selection
</P><P>Initialization:
</P><P>Parameter limits should be defined, if not, parameter ranges should cover the suspected optimum
Define upper and lower bounds for each parameter and randomly select the initial parameter values uniformly on the intervals.
</P><P>Mutation:
</P><P>Small random alterations to one or more parameters of an existing population.
Each of the N parameter vectors undergoes mutation, recombination and selection. Mutation expands the search space. For a given parameter vector  randomly select three vectors such that the indices i, r1, r2 and r3 are distinct. Add the weighted difference of two of the vectors to the third.
</P><P>Recombination/Crossover:
</P><P>Uniform crossover: Inherits parameter values from parents with equal probability
</P><P>Non-uniform crossover: Takes parameters from one parent more often than the other
Recombination incorporates successful solutions from the previous generation. 
</P><P>Selection:
</P><P>Determine which among them will survive to the next generation
Random approach using “tournament selection” = randomly paired the winner with all possible competition.
DE: each child pits against one of its parents
</P><P>Mutation, recombination and selection continue until some stopping criterion is reached.
</P><H6><SPAN class="mw-headline" id="Quasi_Monte-Carlo_Sampling"> Quasi Monte-Carlo Sampling </SPAN></H6><P>Quasi-MC sampling is a powerful tool for stochastic optimization and analysis of initial conditions. It generates a sequence of random vectors while guaranteeing a predictable spacing between them. This enables us to draw relatively few random vectors without neglecting wide swaths of the sample space. The function below is called haltonseq and takes as input the length N of the vector to generate and the number M of vectors to sample and returns a MxN matrix with points generated using the Halton sequence<SUP><A href="#Foot5">[5]</A></SUP></P><P><A href="https://static.igem.org/mediawiki/2011/a/ae/Haltonseq.zip" class="external text" rel="nofollow">Haltonseq.zip</A></P><P><SPAN id="Foot1"><SUP>[1]</SUP> Igel, C., Suttorp, T., &amp; Hansen, N. (2006). A computational efficient covariance matrix update and a (1+1)-CMA for evolution strategies. Proceedings of the 8th annual conference on Genetic and evolutionary computation - GECCO ’06 (p. 453). New York, New York, USA: ACM Press.</SPAN></P><P><SPAN id="Foot2"><SUP>[2]</SUP> Finkel, Daniel E. DIRECT Optimization Algorithm User Guide. Raleigh: Center for Research in Scientific Computation, 2 Mar. 2003. PDF.</SPAN></P><P><SPAN id="Foot3"><SUP>[3],[4]</SUP>C T Kelley, “Users’ Guide for imfil Version 1.0.”</SPAN></P><P><SPAN id="Foot4"><SUP>[5]</SUP>J. H. Halton. 1964. Algorithm 247: Radical-inverse quasi-random point sequence. Commun. ACM 7, 12 (December 1964), 701-702.</SPAN></P></DIV><DIV class="printfooter">
Retrieved from &quot;<A href="http://2011.igem.org/Team:Johns_Hopkins/Modeling/OptAlgs">http://2011.igem.org/Team:Johns_Hopkins/Modeling/OptAlgs</A>&quot;</DIV></DIV></DIV><DIV id="footer-box" class="noprint"><DIV id="footer"><UL id="f-list"><LI id="t-recentchanges"><A href="/Special:RecentChanges" title="Recent changes">Recent changes</A></LI><LI id="t-whatlinkshere"><A href="/Special:WhatLinksHere/Team:Johns_Hopkins/Modeling/OptAlgs" title="List of all wiki pages that link here [j]" accesskey="j">What links here</A></LI><LI id="t-recentchangeslinked"><A href="/Special:RecentChangesLinked/Team:Johns_Hopkins/Modeling/OptAlgs" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</A></LI><LI id="t-specialpages"><A href="/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</A></LI><LI><A href="/Special:Preferences">My preferences</A></LI></UL></DIV><DIV id="footer"><UL id="f-list"><LI id="t-print"><A href="/wiki/index.php?title=Team:Johns_Hopkins/Modeling/OptAlgs&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</A></LI><LI id="t-permalink"><A href="/wiki/index.php?title=Team:Johns_Hopkins/Modeling/OptAlgs&amp;oldid=134340" title="Permanent link to this revision of the page">Permanent link</A></LI><LI id="privacy"><A href="/2011.igem.org:Privacy_policy" title="2011.igem.org:Privacy policy">Privacy policy</A></LI><LI id="disclaimer"><A href="/2011.igem.org:General_disclaimer" title="2011.igem.org:General disclaimer">Disclaimers</A></LI></UL></DIV></DIV></DIV></BODY></HTML>