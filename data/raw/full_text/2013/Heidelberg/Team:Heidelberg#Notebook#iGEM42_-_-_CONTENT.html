<HTML xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki  ltr ns-0 ns-subject page-Team_Heidelberg_Notebook_iGEM42"><DIV id="globalWrapper"><DIV id="top-section"><DIV id="p-logo"><A href="/Main_Page" title="Main Page">&quot;
	    </A></DIV><DIV id="menubar" class="left-menu noprint"><UL><LI class="selected"><A href="/Team:Heidelberg/Notebook/iGEM42">Page               </A></LI><LI class="new"><A href="/wiki/index.php?title=Talk:Team:Heidelberg/Notebook/iGEM42&amp;action=edit&amp;redlink=1">Discussion               </A></LI><LI><A href="/wiki/index.php?title=Team:Heidelberg/Notebook/iGEM42&amp;action=edit">View source               </A></LI><LI><A href="/wiki/index.php?title=Team:Heidelberg/Notebook/iGEM42&amp;action=history">History               </A></LI><LI style="color:white;cursor:default">teams</LI></UL></DIV><DIV class="right-menu noprint" id="menubar"><UL><LI id="pt-login"><A href="/wiki/index.php?title=Special:UserLogin&amp;returnto=Team:Heidelberg/Notebook/iGEM42" title="You are encouraged to log in; however, it is not mandatory [o]" accesskey="o">Log in</A></LI></UL></DIV><DIV id="search-controls" class="noprint"><FORM action="/Special:Search" id="searchform"> </FORM></DIV></DIV><DIV id="content"><H1 class="firstHeading">Team:Heidelberg/Notebook/iGEM42</H1><DIV id="bodyContent"><H3 id="siteSub" class="noprint">From 2013.igem.org</H3><DIV class="row"><DIV id="nav" class="navigation"><DIV class="item team" data-offset-l="-130"><H2>Team</H2><UL><LI><A href="/Team:Heidelberg/Team">Team Members</A></LI><LI><A href="/Team:Heidelberg/AttributionsII">Attributions</A></LI><LI><A href="/Team:Heidelberg/Team/Sponsors">Sponsors</A></LI><LI><A href="/Team:Heidelberg/Team/Collaboration">Collaborations</A></LI><LI><A href="/Team:Heidelberg/Team/Gallery">Gallery</A></LI></UL></DIV><DIV class="item project" data-offset-l="-144"><H2>Project</H2><UL><LI><A href="/Team:Heidelberg/NRPS">Background</A></LI><LI><A href="/Team:Heidelberg/Project">Overview</A></LI><LI><A href="/Team:Heidelberg/Project/Tyrocidine">Synthetic Peptides</A></LI><LI><A href="/Team:Heidelberg/Project/Indigoidine-Tag">Indigoidine-Tag</A></LI><LI><A href="/Team:Heidelberg/Project/Tag-Optimization">Tag Optimization</A></LI><LI><A href="/Team:Heidelberg/Project/Delftibactin">Gold Recycling</A></LI><LI><A href="/Team:Heidelberg/Project/Achievements">Achievements</A></LI></UL></DIV><DIV class="item notebook" data-offset-l="-139"><H2>Notebook</H2><UL><LI><A href="/Team:Heidelberg/Tyrocidine">Synthetic Peptides</A></LI><LI><A href="/Team:Heidelberg/Tyrocidine">Indigoidine-Tag</A></LI><LI><A href="/Team:Heidelberg/Indigoidine">Tag Optimization</A></LI><LI><A href="/Team:Heidelberg/Delftibactin">Gold Recycling</A></LI><LI><A href="/Team:Heidelberg/NRPSDesigner">NRPSDesigner</A></LI><LI><A href="/Team:Heidelberg/Notebook/Methods">Methods</A></LI><LI><A href="/Team:Heidelberg/Materials">Materials</A></LI></UL></DIV><DIV class="item parts" data-offset-l="-134"><H2>Parts</H2><UL><LI><A href="/Team:Heidelberg/Parts">Submitted Parts</A></LI><LI><A href="/Team:Heidelberg/Favorite_Parts">Favorite Parts</A></LI><LI><A href="/Team:Heidelberg/RFCs">Our RFCs</A></LI></UL></DIV><DIV class="item software" data-offset-l="-134"><H2>Software</H2><UL><LI><A href="/Team:Heidelberg/Project_Software">Project</A></LI><LI><A href="http://igem2013.bioquant.uni-heidelberg.de/NRPSDesigner/">NRPSDesigner</A></LI><LI><A href="/Team:Heidelberg/HumanPractice/iGEM42">iGEM42</A></LI><LI><A href="/Team:Heidelberg/OpenSource">Open Source</A></LI><LI><A href="/Team:Heidelberg/Project/AchievementsSoftware">Achievements</A></LI></UL></DIV><DIV class="item human" data-offset-l="-118"><H2>Human Practice</H2><UL><LI><A href="/Team:Heidelberg/HumanPractice">Overview</A></LI><LI><A href="/Team:Heidelberg/HumanPractice/BroadPublic">Broad Public</A></LI><LI><A href="/Team:Heidelberg/HumanPractice/Survey">Survey</A></LI><LI><A href="/Team:Heidelberg/HumanPractice/YoungGeneration">Young Generation</A></LI><LI><A href="/Team:Heidelberg/HumanPractice/Artists">Arts and Science</A></LI><LI><A href="/Team:Heidelberg/HumanPractice/BeyondScience">Beyond Science</A></LI><LI><A href="/Team:Heidelberg/HumanPractice/Experts">Experts</A></LI></UL></DIV><DIV class="item safety" data-offset-l="-115"><H2>Safety</H2><UL><LI><A href="/Team:Heidelberg/Safety">Safety</A></LI></UL></DIV><DIV class="item model" data-offset-l="-144"><H2>Modeling</H2><UL><LI><A href="/Team:Heidelberg/Modelling/Gold_Recovery">Gold Recycling</A></LI><LI><A href="/Team:Heidelberg/Modelling/Ind_Production">ind-Production</A></LI></UL></DIV><DIV class="item"><SPAN style="margin-left:6%">HOME</SPAN></DIV></DIV></DIV><DIV class="container"><DIV style="margin-top:80px"><H1><SPAN style="font-size:150%;color:#166F57;">iGEM 42.</SPAN><SPAN class="text-muted" style="font-size:90%"> The answer to everything.</SPAN></H1><P>Have you ever easily found the piece of information you wanted from past iGEM competitions? Right! That turned out to be very hard.Maybe you should try this tool which was developed to do exactly this: Lead you directly to the <B>information you want</B>.</P></DIV><DIV><A href="http://igem2013.bioquant.uni-heidelberg.de/shiny/iGEMPulse/homepage/index_iGEM42.html"><H2>Go to our external server to use the tool</H2></A></DIV><DIV class="row"><DIV class="col-sm-4"><UL class="pagination" style="margin-bottom:2%; margin-left:4%;"><LI><A href="#" id="backwards">«</A></LI><LI class="active month_tab" id="may"><A href="#" style="width:90px; text-align:center">May</A></LI><LI class="month_tab" id="june"><A href="#" style="width:90px; text-align:center">June</A></LI><LI class="month_tab" id="july"><A href="#" style="width:90px; text-align:center">July</A></LI><LI class="month_tab" id="august"><A href="#" style="width:90px; text-align:center">August</A></LI><LI class="month_tab" id="september"><A href="#" style="width:90px; text-align:center">September</A></LI><LI><A href="#" id="forwards">»</A></LI></UL><DIV style="margin-bottom:8%;"><DIV id="myCarousel" class="carousel slide"><DIV class="carousel-inner"><DIV class="item active may first"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 3</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">During this week and the previous ones the whole idea of this human practices project and the code for it evolved. Thus we start with several scrapy spiders and initial implementations of data display, text analysis and the first interesting findings on our private github repository. During this week the main task was to fix the several scraping scripts and expand them to generate more data.</P></DIV></DIV></DIV><DIV class="item may last"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 4</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">While the bug fixing and expansion of the srapy spiders was still going on, we started to put the data in R instead of JSON format, in order to start doing statistical analysis.</P></DIV></DIV></DIV><DIV class="item june first"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 6</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">After thinking about how to ideally put our data into a nice homepage, we decided to use the R-package shiny. After reading into how that actually works Nikos was the one to make the first step and implement our scatter-plot app.</P></DIV></DIV></DIV><DIV class="item june"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 8</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">Since we had a more elaborate app layout in mind and only few people were willing to do it with bootstrap, we had to look into ways of creating an individual app without using this. The funny thing is that we ended up with bootstrap all over our wiki and our software tools - including this one.</P></DIV></DIV></DIV><DIV class="item june last"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 9</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">During this week we started doing real progress. The second app - the timeline - was impelmented, we created a homepage draft and finally we also started doing the text mining on the abstracts of the teams.</P></DIV></DIV></DIV><DIV class="item july first"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 10</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">This week we had a non-sunny sunday indoors programming all day with the goal to finish the whole project. As it turned out in the end this was way too ambitious. Nevertheless we reimplemented our scoring function, created several different homepage designs, continued the text mining and generated a set of raw filtering functions. After this sunday we all focused on a different project or on our bachelor thesis.</P></DIV></DIV></DIV><DIV class="item august first"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 15</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">After a long break full of work we slowly started to finsih on this project and implemented a draft for the topics app.</P></DIV></DIV></DIV><DIV class="item august last"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 18</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">Since we still didn't have the functional filter, they were fixed. Thus we could now start exploring the data we generated and unfortunately we noticed, that part of the data was wrong or not passed through the filters correctly. So we started fixing bugs...</P></DIV></DIV></DIV><DIV class="item september first"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 19</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">In this week we found out that using external stylesheets and javascript together with the R code for the apps is easier than we thought. Thus we did some restyling and put the filters into a notebook. In parallel we worked on the data completion.</P></DIV></DIV></DIV><DIV class="item september"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 20</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">Now that we finally understood how many opportunities shiny offers, we generated new apps, added a tabular output of the teams and added more filter functions. These also include a filter for the team name. Unfortunately it turned out, that the methods extraction is anything but stable.</P></DIV></DIV></DIV><DIV class="item september"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 22</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">This week we took a closer look at the methods. We went through prominent iGEM teams and addedmethods to our list, that could actually be found in the abstracts.</P></DIV></DIV></DIV><DIV class="item september last"><DIV class="container"><DIV class="carousel-caption scrollContent2" data-spy="scroll" data-target="#navbarExample" data-offset="0"><H1>Week 23</H1><P style="font-size:10pt; text-align:justify; position:relative; margin-left:6%;">The week before wiki freeze - we did lots of style adjustments and added many details to our apps in order to present a fully developed tool. To actually use the tool you can now just click on the link above this box.</P></DIV></DIV></DIV></DIV></DIV></DIV><DIV class="jumbotron methods" data-spy="scroll" data-target="#navbarExample" data-offset="0" style="visibility:hidden;"><H2>Methods:</H2></DIV></DIV><DIV class="col-sm-8"><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a3" data-toggle="tab">Previous work</A></LI><LI><A href="#b3" data-toggle="tab">New scrapers</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="b3"><H2><SPAN class="mw-headline" id="Reimplementation_of_scraping"> Reimplementation of scraping </SPAN></H2><P>As the scraping scripts we started out with had a rather high run time and were organised pretty complicated, the whole thing was rewritten. The spiders use the central team (<A href="https://igem.org/Team_List?year=%d" class="external free" rel="nofollow">https://igem.org/Team_List?year=%d</A>) and results (<A href="https://igem.org/Results?year=%d" class="external free" rel="nofollow">https://igem.org/Results?year=%d</A>) page per year to go through all the teams at once instead of opening, editing and closing the JSON results file for every team. Within each team page HtmlXPathSelectors are used to generate the single values. As this of course depending on the exact same page structure, nothing but the two central pages can be easily scraped using these detailed selectors.
                                </P></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a4" data-toggle="tab">Data generation</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a4"><H2><SPAN class="mw-headline" id="Wiki_Scraping"> Wiki Scraping </SPAN></H2><P>We wrote a pipeline to collect and print the data for every team properly. Thus proper script exiting and output file specification via the command line were easier to implement. The track, which was missing until now was included in the scraping process.
Furthermore several bugs were fixed. We had encountered problems regarding whitespaces, espacially the dublication of teams when their name contains a blank space. We also took care of the proper construction of all the spider objects.
</P><H2><SPAN class="mw-headline" id="Data_conversion_to_R"> Data conversion to R </SPAN></H2><P>The JSON file needs to be converted to R compatible data for the analysis. The target file contains one dataframe for all single value parameters and one list for all multiple value parameters / gib text contents. Here unique naming of the teams was achieved by combination of name and year. A full liste of which parameters and contents were converted is displayed in table 4.1.
</P><TABLE class="wikitable"><CAPTION> Table 4.1: Parameters generated so far.
</CAPTION><TBODY><TR><TH> Data frame parameters </TH><TH> List elements
</TH></TR><TR><TD><UL><LI> Numerical:
</LI><LI> year
</LI><LI> students count
</LI><LI> advisors count
</LI><LI> instructors count
</LI><LI> regional awards count
</LI><LI> championship awards count
</LI><LI> biobrick count
</LI></UL><LI> Character strings:
</LI><LI> region
</LI><LI> wiki
</LI><LI> url (Team overview page)
</LI></TD><TD><UL><LI> year
</LI><LI> character vector of regional awards
</LI><LI> character vector of championship awards
</LI><LI> parts range
</LI><LI> advisor names
</LI><LI> project title
</LI><LI> abstract
</LI></UL></TD></TR></TBODY></TABLE></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a6" data-toggle="tab">Shiny app</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a6"><H2><SPAN class="mw-headline" id="First_shiny_app_implemented"> First shiny app implemented </SPAN></H2><P>A first shiny app that can display the numerical data in a scatterplot was created. Besides shiny it also uses the RCharts package for more aesthetic graphs.
                                </P></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a8" data-toggle="tab">Shiny concepts</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a8"><H2><SPAN class="mw-headline" id="Different_concepts_for_shiny_files"> Different concepts for shiny files </SPAN></H2><P>Since there are two different concepts of how to implement the page surrounding a shiny app, we tried out both.
See week 20 for the final solution we chose for building our apps.
</P><H3><SPAN class="mw-headline" id="R_builder_functions_for_html"> R builder functions for html </SPAN></H3><P>Files needed:
</P><UL><LI>./server.R
</LI><LI>./ui.R
</LI></UL><P>This solution turned out to be very complicated due to the combination of directly accessible html tags, those which need the tags() function and styling rules within the ui.R. Thus using the other concept seems more intuitive.
</P><H3><SPAN class="mw-headline" id="Separated_html_code"> Separated html code </SPAN></H3><P>File needed:
</P><UL><LI>./server.R
</LI><LI>./www/index.html
</LI></UL><P>Here the app is built directly in html and css syntax as any other basic homepage. This on the other hand became complicated, when integrating the server output in the app.
                                </P></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a9" data-toggle="tab">Frontend</A></LI><LI><A href="#b9" data-toggle="tab">Text analysis</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a9"><H2><SPAN class="mw-headline" id="Second_app_implemented"> Second app implemented </SPAN></H2><P>The second shiny app we impelmented was the timeline app. It counts teams, awards or students within each year and puts the numbers in a bar plot. For the plot we again use RCharts but this time with nvd3. In order to prevent errors we had to add empty values to the data since nvd3 can't handle incomplete datasets.
</P><H2><SPAN class="mw-headline" id="First_hompage_draft"> First hompage draft </SPAN></H2><P>A simple draft of the homepage was implemented using basic html and css tags.
This page is supposed to either become integrated in our wiki or to be a stand alone homepage.
</P><H3><SPAN class="mw-headline" id="Layout"> Layout </SPAN></H3><P>
page wrapper</P><DIV style="border:1pt solid black; background-color:grey; padding:20px; max-width:500px;">
page content<DIV style="border:1pt solid black; background-color:lightblue; padding:10px; text-align:center;"><P style="font-size:200%">Page Header</P><DIV style="border:1pt solid black; background-color:grey; padding:10px;">menu   bar</DIV><DIV style="margin:30px; padding:30px; border:1pt solid black; background-color:white; height:100px; font-weight:bold;"> SHINYAPPiframe </DIV><DIV style="border:1pt solid black; background-color:grey; padding:10px;"> page footer</DIV></DIV></DIV><H3><SPAN class="mw-headline" id="App_integration"> App integration </SPAN></H3><P>In order to integrate the apps, the central iframe was used as target for the links in the menu bar. The link would then for example look like this:<PRE>&lt;a href=&quot;apps/factsfigures/&quot; target=&quot;center-frame&quot;&gt;Facts &amp; figures&lt;/a&gt;</PRE></P></DIV><DIV class="tab-pane" id="b9"><P style="font-size:12pt; text-align:justify;">
                                == Text analysis drafts ==
For the text analysis we used python and it's nltk platform (see <A href="http://nltk.org" class="external autonumber" rel="nofollow">[1]</A>). The only text corpus used was the stopword corpus.
Independent of the analysis done a &quot;stemmer&quot; was run on the abstracts, which reduces all words to their very basic form. For the topwords and information content calculation simple counting was performed and for the information content the proportion of the stopwords corpus in the whole was determined.
For the extraction of the meshterms a list of terms in synthetic biology from Paul Oldahm and his colleagues (Oldham, P., Hall, S., &amp; Burton, G. (2012). Synthetic Biology: Mapping the Scientific Landscape. PLoS ONE, 7(4), e34368. doi:10.1371/journal.pone.0034368) was used. Here the stemmer was applied to both the abstract and the words list and the matches were again counted.
                                </P></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a10" data-toggle="tab">Frontend</A></LI><LI><A href="#b10" data-toggle="tab">Data generation</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a10"><H2><SPAN class="mw-headline" id="Creation_of_several_design_suggestions"> Creation of several design suggestions </SPAN></H2><P>During a meeting we decided to create three design proposals, so that the team could vote which one they like best. Out of the three one should be a modern design similar to other web pages, having a virtual third dimension. With regard to the Hitchhiker's Guide to the Galaxy we wanted one &quot;spacy&quot; design and lust but not least one alchemical / old fashioned design to fit our team logo.
Note: Since we finally used the same design as on our wiki, it's not worth showing the other design proposals or the introductory texts at this point. These can all be found on our wiki.
</P><H2><SPAN class="mw-headline" id="Draft_of_filtering_options"> Draft of filtering options </SPAN></H2><P>The drafts for most of the filtering functions were implemented. Table 1 gives an overview of the different parameters and their basic filter design.
</P><TABLE class="wikitable"><CAPTION><B>Table 1:</B> Overview of all filters.
</CAPTION><TBODY><TR><TH> Parameter </TH><TH> Type </TH><TH> Options* </TH><TH> Status
</TH></TR><TR><TD> Year </TD><TD> numeric </TD><TD> 2007-2012 </TD><TD> draft
</TD></TR><TR><TD> Region </TD><TD> string </TD><TD> levels </TD><TD> draft
</TD></TR><TR><TD> Track </TD><TD> string </TD><TD> levels </TD><TD> draft
</TD></TR><TR><TD> Students </TD><TD> numeric </TD><TD> 0, 5, 10, 15, 20, &gt;20 </TD><TD> draft
</TD></TR><TR><TD> Advisors </TD><TD> numeric </TD><TD> 0, 2, 5, 10, 15, &gt;15 </TD><TD> draft
</TD></TR><TR><TD> Instructors </TD><TD> numeric </TD><TD> 0, 2, 5, 10, 15, &gt;15 </TD><TD> draft
</TD></TR><TR><TD> Biobricks </TD><TD> numeric </TD><TD> 0, 5, 10, 20, 50, 100, 200, &gt;200 </TD><TD> draft
</TD></TR><TR><TD> Championship </TD><TD> character vector </TD><TD> levels </TD><TD> draft
</TD></TR><TR><TD> Regional </TD><TD> character vector </TD><TD> levels </TD><TD> draft
</TD></TR><TR><TD> Medals </TD><TD> string </TD><TD> bronze, silver, medal </TD><TD> missing
</TD></TR><TR><TD> Score </TD><TD> numeric </TD><TD> 0-100 (steps of 10) </TD><TD> draft
</TD></TR><TR><TD> Abstract </TD><TD> binary </TD><TD> provided/missing </TD><TD> missing
</TD></TR><TR><TD colspan="4"> * Levels means all possible values the parameter can have.
</TD></TR></TBODY></TABLE><P>The general code for filtering a numerical range parameter X using R looks like this:
<PRE>
FilterForX &lt;- function(data) {
	if (input$FILX_min == &quot;&gt;max&quot;) data &lt;- data[-which(data$X &lt; max),]
	else if (input$FILX_max == &quot;&gt;max&quot;) data &lt;- data[-which(data$X &lt; input$FILX_min),]
	else data &lt;- data[-which(data$X &lt; input$FILX_min | data$X &gt; input$X_max),]
	return(data)
}
</PRE>
The general code for filtering a single string parameter Y using R looks like this:
<PRE>
FilterForY &lt;- function(data) {
	matchY &lt;- rep(0, times=length(data$Y))
	for (i in 1:length(input$FILY)) {
		matchY[which(data$Y == input$FILY[i])] &lt;- 1
	}
	data &lt;- data[-which(matchY == 0),]
	rm(matchY)
	return(data)
}
</PRE>
For each filter the corresponding selection elements (max, min or multiple selection) are added underneath each other below the plot of the app. They are grouped as teams success and team composition.
                                </P></DIV><DIV class="tab-pane" id="b10"><H2><SPAN class="mw-headline" id="Scraping_of_BioBrick_count"> Scraping of BioBrick count </SPAN></H2><P>There is an API provided for accessing the registry, but unfortunately it only allows for search of a single specified BioBrick id. The fastest, but still very slow way to connect a team with it's BioBricks is doing an API request for every id in the teams parts range. The only assumption we made in order to speed things up, is that the BioBricks were submitted in a continuous parts range. Thus the matching is aborted when the first BioBrick in the parts rang can't be found.
</P><H2><SPAN class="mw-headline" id="Implementation_of_Scoring"> Implementation of Scoring </SPAN></H2><P>In order to solve the very sensitive problem of rating a team's success we started out with a subjective scoring by every one of our team members for the different awards and the medals. This native scoring turned out to be pretty consistent an thus we just calculated mean values and put the on an exponential scale in order to achieve a harsh separation of the highest top scoring teams and those who didn't get that far. For every team the score of the single awards was added up. As the awards rewarded differend every year, we normalised the summarized score of the teams in one year to a scale from 0 to 100%.
The whole analysis was added to the R-script converting the JSON file to the RData file.
</P><H2><SPAN class="mw-headline" id="Further_text_analysis_and_data_conversion"> Further text analysis and data conversion </SPAN></H2><P>In order to do the text analysis for the methods extraction we collected a raw list of methods, which is displayed in table 10.1. They were clustered in Preprocessing, Processing and Analysis. The script doing the analysis in python again stems both the abstract and the methods and matches them.
</P><TABLE class="wikitable"><CAPTION> Table 10.1: Clustered methods for text analysis
</CAPTION><TBODY><TR><TH colspan="3"> Preprocessing
</TH></TR><TR><TD> Fusion Proteins </TD><TD> Primer Design </TD><TD> cloning
</TD></TR><TR><TD> preparation of DNA </TD><TD> Restriction Digestion </TD><TD> Insert preparation
</TD></TR><TR><TD> cell fractionation </TD><TD> cell counting </TD></TR><TR><TH colspan="3"> Processing
</TH></TR><TR><TD> DNA sequencing </TD><TD> PCR </TD><TD> DNA Microarray
</TD></TR><TR><TD> arrays </TD><TD> interaction chromatography </TD><TD> purification
</TD></TR><TR><TD> Gel extraction </TD><TD> Ligation </TD><TD> Transformation
</TD></TR><TR><TD> FRET </TD><TD> DNA extraction </TD><TD> patch clamp
</TD></TR><TR><TH colspan="3"> Analysis
</TH></TR><TR><TD> Northern Blot </TD><TD> Southern Blot </TD><TD> Western blotting
</TD></TR><TR><TD> Bioinformatics </TD><TD> ELISA </TD><TD> Chromatography
</TD></TR><TR><TD> flow cytometry </TD><TD> X-Ray-crystallography </TD><TD> NMR
</TD></TR><TR><TD> Electron microscopy </TD><TD> Molecular dynamics </TD><TD> coimmunoprecipitation
</TD></TR><TR><TD> Electrophoretic mobility shift assay </TD><TD> southwestern blotting </TD><TD>size determination
</TD></TR><TR><TD> gel electrophoresis </TD><TD> macromolecule blotting and probing </TD><TD> immuno assays
</TD></TR><TR><TD> phenotypic analysis </TD><TD> imaging </TD><TD> spectroscopy
</TD></TR><TR><TD> spectrometry </TD></TR></TBODY></TABLE><P>The RData file was extended and now also includes the meshterms within the data-list as well as the information content and the track in the data-frame.
                                </P></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a15" data-toggle="tab">Topics app</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a15"><H2><SPAN class="mw-headline" id="Implementation_of_Topics_app_started"> Implementation of Topics app started </SPAN></H2><P>For the topics and the methods app we had several ideas on how to structure them. Besides a timeline of the hottest topics or histogramm view of the topics distribution the most important feature we had in mind was the direct search for the meshterms we extracted.
Pseudocode for the corresponding filtering functions and a draft of the interface were written, but the workload in the other projects was too big to actually create a functional app.
                                </P></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a18" data-toggle="tab">Bug fixes</A></LI><LI><A href="#b18" data-toggle="tab">Data completion</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a18"><H2><SPAN class="mw-headline" id="Filters_fixed"> Filters fixed </SPAN></H2><P>The drafts for most of the filtering functions had already been implemented, but ended up non-functional. This was due to data removal using empty vectors, which produces a severe error in R. Table 18.1 gives an overview of the different parameters and their basic filter design.
</P><TABLE class="wikitable"><CAPTION><B>Table 18.1:</B> Overview of all filters.
</CAPTION><TBODY><TR><TH> Parameter </TH><TH> Type </TH><TH> Options* </TH><TH> Status
</TH></TR><TR><TD> Year </TD><TD> numeric </TD><TD> 2007-2012 </TD><TD> final
</TD></TR><TR><TD> Region </TD><TD> string </TD><TD> levels </TD><TD> final
</TD></TR><TR><TD> Track </TD><TD> string </TD><TD> levels </TD><TD> final
</TD></TR><TR><TD> Students </TD><TD> numeric </TD><TD> 0, 5, 10, 15, 20, &gt;20 </TD><TD> final
</TD></TR><TR><TD> Advisors </TD><TD> numeric </TD><TD> 0, 2, 5, 10, 15, &gt;15 </TD><TD> final
</TD></TR><TR><TD> Instructors </TD><TD> numeric </TD><TD> 0, 2, 5, 10, 15, &gt;15 </TD><TD> final
</TD></TR><TR><TD> Biobricks </TD><TD> numeric </TD><TD> 0, 5, 10, 20, 50, 100, 200, &gt;200 </TD><TD> final
</TD></TR><TR><TD> Championship </TD><TD> character vector </TD><TD> levels </TD><TD> working
</TD></TR><TR><TD> Regional </TD><TD> character vector </TD><TD> levels </TD><TD> working
</TD></TR><TR><TD> Medals </TD><TD> string </TD><TD> bronze, silver, medal </TD><TD> missing
</TD></TR><TR><TD> Score </TD><TD> numeric </TD><TD> 0-100 (steps of 10) </TD><TD> final
</TD></TR><TR><TD> Abstract </TD><TD> binary </TD><TD> provided/missing </TD><TD> missing
</TD></TR><TR><TD colspan="4"> * Levels means all possible values the parameter can have.
</TD></TR></TBODY></TABLE><P>The general code for filtering a numerical range parameter X using R after this update is displayed below (changes are displayed in red).
<PRE>
FilterForX &lt;- function(data) {
	if (input$FILX_min == &quot;&gt;max&quot;) data &lt;- data[-which(data$X &lt; max),]
	<SPAN style="color:red;">else if (input$FILX_max == &quot;&gt;max&quot; &amp; input$FilX_min != &quot;min&quot;) data &lt;- data[-which(data$X &lt; input$FILX_min),]
	else if (input$FILX_max == &quot;&gt;max&quot; &amp; input$FilX_min == &quot;min&quot;) return(data)</SPAN>
	else data &lt;- data[-which(data$X &lt; input$FILX_min | data$X &gt; input$X_max),]
	return(data)
}
</PRE>
The general code for filtering a single string parameter Y using R now looks like this:
<PRE>
FilterForY &lt;- function(data) {
	matchY &lt;- rep(0, times=length(data$Y))
	for (i in 1:length(input$FILY)) {
		matchY[which(data$Y == input$FILY[i])] &lt;- 1
	}
	<SPAN style="color:red;">delete &lt;- which(matchY == 0)
	if (length(delete) != 0) data &lt;- data[-delete,]
	rm(delete)</SPAN>
	rm(matchY)
	return(data)
}
</PRE>
The code for matching the awards is slighly more complicated, since the awards are saved in the data-list and we want to reduce the data-frame. This is the pseudocode for the functions:
<PRE>
iterate through all awards to be included {
	(re-)set a vector for deleting those items from the data-list
	iterate through all the teams in the data-list {
		if the award matches one of the team awards:
		- expand the vector for the teams to keep with the name
		- expand the vector for the teams already matched
	}
	delete those teams from the data-list, that were already positive in order to save runtime
}
reduce data-frame according to the matching result
</PRE>
All the filter functions and corresponding layout elements were put together in one file to easily copy and paste them to the different apps.
                                </P></DIV><DIV class="tab-pane" id="b18"><H2><SPAN class="mw-headline" id="Incomplete_data"> Incomplete data </SPAN></H2><P>During the testing of the filters it was found, that there was no best team in 2007. After further investigation we found out, that the 2007 awards were on a different page than it was from 2008 onwards. Thus another scraper had be written and integrated into the pipeline in order to cover this page, too. This took a bit longer than for the other results pages, because its structure is entirely different from the standard one.
                                </P></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a19" data-toggle="tab">Frontend</A></LI><LI><A href="#b19" data-toggle="tab">Data completion</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a19"><H2><SPAN class="mw-headline" id="Restyling_filters_including_javascript_and_css"> Restyling filters including javascript and css </SPAN></H2><P>In order to have the whole apps in a compact layout, the filters were put into a notebook. To navigate and style this javascript and css had to be included. This works through the simple &quot;includeHTML()&quot;-function shiny contains.
The tab heading are implemented as a unordered list containing links. These links activate a javascript, which shifts between the containers displayed in the notebook. This works by first hiding all containers in that area and then showing the one that was specified as parameter, when calling the function from the link.
The style of the tabs and the notebook were adjusted to match the border color and radius of the bootstrap styled elements.
</P><H2><SPAN class="mw-headline" id="Adjustments_to_page_design"> Adjustments to page design </SPAN></H2><P>To allow for proper presentation in meetings, the design of the test-homepage was adjusted to current wiki design.
                                </P></DIV><DIV class="tab-pane" id="b19"><H2><SPAN class="mw-headline" id="Data_completion"> Data completion </SPAN></H2><P>As the data was not yet completely converted to R, the script doing so was altered to also include the results from the methods, meshterms and topics extractions, as well as the medals awarded. Prior to this the data update concerning the 2007 awards had to be manually corrected, since the registered team names and those on the results page were not exactly the same in some cases. These were:
</P><UL><LI> Wisconsin
</LI><LI> MIT
</LI><LI> St. Petersburg
</LI><LI> Davidson Missouri
</LI><LI> Boston U
</LI><LI> Mississippi
</LI><LI> Berkeley
</LI><LI> Michigan
</LI><LI> Colombia Israel
                                </LI><LI class="active"><A href="#a20" data-toggle="tab">Global elements</A></LI><LI><A href="#b20" data-toggle="tab">App implementation</A></LI><LI><A href="#c20" data-toggle="tab">Data completion</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a20"><H2><SPAN class="mw-headline" id="Expansion_of_Filters"> Expansion of Filters </SPAN></H2><P>The last filters missing (medal and abstract), another filter for team names and one for the information content of the abstract were implemented. Additionally the selection ranges of some filters were adjusted. See table 23.1 for the final filter setups.
</P><TABLE class="wikitable"><CAPTION><B>Table 23.1:</B> Overview of all final filters.
</CAPTION><TBODY><TR><TH> Parameter </TH><TH> Type </TH><TH> Options* </TH><TH> Status
</TH></TR><TR><TD> Year </TD><TD> numeric </TD><TD> 2007-2012 </TD><TD> final
</TD></TR><TR><TD> Region </TD><TD> string </TD><TD> levels </TD><TD> final
</TD></TR><TR><TD> Track </TD><TD> string </TD><TD> levels </TD><TD> final
</TD></TR><TR><TD> Students </TD><TD> numeric </TD><TD> 0, 5, 10, 15, 20, &gt;20 </TD><TD> final
</TD></TR><TR><TD> Advisors </TD><TD> numeric </TD><TD> 0, 2, 4, 6, 8, 10, 12, 14, &gt;14 </TD><TD> final
</TD></TR><TR><TD> Instructors </TD><TD> numeric </TD><TD> 0, 2, 5, 10, 15, &gt;15 </TD><TD> final
</TD></TR><TR><TD> Biobricks </TD><TD> numeric </TD><TD> 0, 5, 10, 20, 50, 100, 200, &gt;200 </TD><TD> final
</TD></TR><TR><TD> Championship </TD><TD> character vector </TD><TD> levels </TD><TD> final
</TD></TR><TR><TD> Regional </TD><TD> character vector </TD><TD> levels </TD><TD> final
</TD></TR><TR><TD> Medals </TD><TD> string </TD><TD> levels </TD><TD> final
</TD></TR><TR><TD> Score </TD><TD> numeric </TD><TD> 0-100 (steps of 10) </TD><TD> final
</TD></TR><TR><TD> Abstract </TD><TD> binary </TD><TD> all/only provided </TD><TD> final
</TD></TR><TR><TD> Information content </TD><TD> numeric </TD><TD> 0, 0.4, 0.45, 0.5, 0.55, 0.6 </TD><TD> final
</TD></TR><TR><TD> Team name </TD><TD> string </TD><TD> variable entry </TD><TD> final
</TD></TR><TR><TD colspan="4"> * Levels means all possible values the parameter can have, which is either generated automatically or manually.
</TD></TR></TBODY></TABLE><H3><SPAN class="mw-headline" id="Abstract"> Abstract </SPAN></H3><P>The filter for the abstract only checks, whether an abstract was submitted or not. See the pseudocode:
<PRE>
if user wants to see all teams return full data set
else {
	iterate through all row names in the data-frame {
		if the abstract of the team &quot;row name&quot; in the data-list matches the string &quot;-- No abstract provided yet --&quot; save the name to a vector
	}
	delete all teams without abstract
	return the reduced data set
}
</PRE>
Since the information content is also related to the abstract, they are put together in one tab of the filter notebook. As it turned out that the information content always is in a very small range around 50%, the possible selections were chosen accordingly. The filter function is similar to those of any other numeric parameter, where the only difference is that all choices are numeric and thus the different cases of minimum and maximum selection can be skipped.
</P><H3><SPAN class="mw-headline" id="Medal"> Medal </SPAN></H3><P>The medal filter is just the same as the filters for track or region, since it is also saved in the data-frame.
</P><H3><SPAN class="mw-headline" id="Team_Name"> Team Name </SPAN></H3><P>For filtering the team name a text entry box was introduced, together with a javascript, that checks on the entered search term. A list of all team names was created and converted to a javascript array using R and its package RJSONIO. The javascript code then compares the entered term(s) with this array and changes the text color to either red (no exact match) or black (exact match). To allow for multiple name entries comma-serapated terms can be entered and are automatically separated by the javascript for color changing and by the filter function.
The pseudocode of the filter funciton looks like this:
<PRE>
split the input string at every comma
iterate through all strings {
	find all teams having the string in their name and keep their ids
}
reduce and return dataset
</PRE></P><H2><SPAN class="mw-headline" id="Team_table_output"> Team table output </SPAN></H2><P>All the apps so far only displayed data, but with no option to see which teams contrbuted to each portion of the graphs. Thus a table output was implemented, that shows the teams' names, years and wiki links. To allow for better overview, one can select how many tams should be display (none, 5, 10, 20, 50, 100 or all) and in which order. This can be done either by the score, displaying the best teams at the top of the list, by year starting with most recent teams, or alphabetically. The data-frame displayed always represents the fully filtered data. Thus the user can narrow the number of teams down using the filters and can then go directly to the corresponding wiki pages.
                                </P></DIV><DIV class="tab-pane" id="b20"><H2><SPAN class="mw-headline" id="Facts_and_Figures_app"> Facts and Figures app </SPAN></H2><P>Since the type of data handled in the scatterplot and the timeline app is very similar, the two apps were put together into one app changing it's appearance depending on the chosen x-axis scale. For this a conditional panel was used to either display selection for the scatterplot y-axis parameters or the one for the timeline-summing parameters.
</P><P>In order to have a continuous design and to be able to target both plot types to the same div the scatterplot was changed from rPlot to nPlot. This means it is now generated using nvd3 instead of the standard R-methods.
</P><P>Additionally a selection for the categories was added. The data displayed can now be grouped by either region, track or medal awarded. The grouping per year is no longer needed, since the timeline gives the optimal time-resolution of the data.
</P><H2><SPAN class="mw-headline" id="Methods_app"> Methods app </SPAN></H2><P>The goal of the methods app was to quickly lead the user to wikis providing high quality protocols for various methods. For this purpose the methods were clustered and now the interface was implemented. It contains two main drop down menus - one for the method cluster and one for the particular method. The options given in the second drop down menu are determined by the first one via conditional panels. There is only one responsive filter applied to the data, which is similar to that for matching the awards. The only differences are, that exact matches instead of regular expressions are detected in the data set and that no empty rows have to be deleted resulting data set. The result is displayed only through the table containing all teams matching the method, which can again be customized regarding the number and order of teams.
To give an overview over the most popular - or until now the most mentioned - methods a table displaying the top 10 methods was added to be constantly displayed in the application. Unfortunately this list only contains 9 elements using the current list of methods and thus the list has to be extended and the text analysis has to be optimised.
</P><H2><SPAN class="mw-headline" id="Topics_app"> Topics app </SPAN></H2><P>In the topics app the main element is the entry box, where the user can enter a term to find, which works very similar to the entry box for team name filter. The text turns red when there is no exact match in the meshterms assigned to the teams and otherwise black. Those teams exactly matching the searched term are again displayed in a tabular format. The filter function currently is exactly the same as for the methods, but has to be altered, to also allow for typing mistakes, case unsensitivity and partial string matches. Here we also added a list of the top 10 topics.
                                </P></DIV><DIV class="tab-pane" id="c20"><H2><SPAN class="mw-headline" id="Data_update_and_completion"> Data update and completion </SPAN></H2><P>There were many automatic and manual corrections done on the data. These included synchronisation of track and award naming, as well as some double or missing awards.
</P><H3><SPAN class="mw-headline" id="Name_synchronisation"> Name synchronisation </SPAN></H3><P>The naming of the tracks and awards was not conserved over the years, but basically kept the value they had. One example is the extension of the 2007 Energy track to the Food or Energy track in 2008. The same applies for other compined tracks, but there were also minor differences, that needed fixing, as for example medals starting with upper or lower case letters. Most of these were solved using regular expressions, when converting the data from JSON to R. See table 23.2 for all synchronisations made.
</P><TABLE class="wikitable"><TBODY><TR><TH colspan="3"> Championship awards
</TH></TR><TR><TH> Regular expression </TH><TH> Replacement </TH><TH> Covered occurances
</TH></TR><TR><TD> Grand Prize </TD><TD> Grand Prize </TD><TD><UL><LI> Grand Prize
</LI><LI> Grand Prize, Winner of the BioBrick Trophy
</LI><LI> Grand Prize Winner
</LI></UL></TD></TR><TR><TD> (1st)|(First) Runner Up </TD><TD> 1st Runner Up </TD><TD><UL><LI> 1st Runner Up
</LI><LI> First Runner Up 
</LI><LI> 1st Runner Up, Winner of the PoPS Prize
</LI></UL></TD></TR><TR><TD> (2nd)|(Second) Runner Up </TD><TD> 2nd Runner Up </TD><TD><UL><LI> 2nd Runner Up
</LI><LI> Second Runner Up
</LI><LI> 2nd Runner Up, Winner of the Synthetic Standard
</LI></UL></TD></TR><TR><TD> Environment </TD><TD> Best Environment Project </TD><TD><UL><LI> Best Environment Project
</LI><LI> Best Environmental Project
</LI><LI> Environmental Sensing
</LI></UL></TD></TR><TR><TD> Energy </TD><TD> Best Food &amp; Energy Project </TD><TD><UL><LI> Best Food &amp; Energy Project
</LI><LI> Best Food or Energy Project
</LI><LI> Energy
</LI></UL></TD></TR><TR><TD> Health </TD><TD> Best Health &amp; Medicine Project </TD><TD><UL><LI> Best Health &amp; Medicine Project
</LI><LI> Best Health or Medicine Project
</LI><LI> Health &amp; Medicine
</LI></UL></TD></TR><TR><TD> Foundational </TD><TD> Best Foundational Advance Project </TD><TD><UL><LI> Best Foundational Advance Project
</LI><LI> Best Foundational Advance
</LI><LI> Best Foundational Tech.
</LI><LI> Foundational Research
</LI></UL></TD></TR><TR><TD> New Application </TD><TD> Best New Application Project </TD><TD><UL><LI> Best New Application Project
</LI><LI> Best New Application Area
</LI></UL></TD></TR><TR><TD> Part, Natural </TD><TD> Best New BioBrick Part, Natural </TD><TD><UL><LI> Best New BioBrick Part, Natural
</LI><LI> Best New BioBrick Part, Natural, Runner Up</LI></UL><P>(differenciating between great teams on this leveldoesn't serve the purpose of the tool)
</P></TD></TR><TR><TD> Best Model </TD><TD> Best Model </TD><TD><UL><LI> Best Model
</LI><LI> Best Modeling / Sim.
</LI></UL></TD></TR><TR><TD> Information Processing </TD><TD> Best Information Processing Project </TD><TD><UL><LI> Best Information Processing Project
</LI><LI> Information Processing
</LI></UL></TD></TR><TR><TD> Software Tool </TD><TD> Best Software </TD><TD><UL><LI> Best Software Tool
</LI></UL><P>(Best Software Tools will be one with the Best Software)
</P></TD></TR><TR><TD> Presentation </TD><TD> Best Presentation </TD><TD><UL><LI> Best Presentation
</LI><LI> Best Presentation, Runner Up
</LI></UL></TD></TR><TR><TH colspan="4"> Regional awards
</TH></TR><TR><TH> Regular expression </TH><TH> Replacement </TH><TH> Covered occurances
</TH></TR><TR><TD> Grand Prize </TD><TD> Grand Prize </TD><TD rowspan="12"><P>Regional prizes always end
with the corresponding region.
Besides this other minor differences
as for the championhsip awards are removed.
</P></TD></TR><TR><TD> Finalist </TD><TD> Regional Finalist
</TD></TR><TR><TD> Human Practices </TD><TD> Best Human Practices Advance
</TD></TR><TR><TD> Experimental Measurement </TD><TD> Best Experimental Measurement Approach
</TD></TR><TR><TD> Model </TD><TD> Best Model
</TD></TR><TR><TD> Device, Engineered </TD><TD> Best New BioBrick Device, Engineered
</TD></TR><TR><TD> Part, Natural </TD><TD> Best New BioBrick Part, Natural
</TD></TR><TR><TD> Standard </TD><TD> Best New Standard
</TD></TR><TR><TD> Poster </TD><TD> Best Poster
</TD></TR><TR><TD> Presentation </TD><TD> Best Presentation
</TD></TR><TR><TD> Wiki </TD><TD> Best Wiki
</TD></TR><TR><TD> Safety </TD><TD> Safety Commendation
</TD></TR><TR><TH colspan="3"> Medals, Regions, Tracks
</TH></TR><TR><TH> Regular expression </TH><TH> Replacement </TH><TH> Covered occurances
</TH></TR><TR><TD> [Bb]ronze </TD><TD> Bronze </TD><TD rowspan="3"> upper or lower case medals
</TD></TR><TR><TD> [Ss]ilver </TD><TD> Silver
</TD></TR><TR><TD> [Gg]old </TD><TD> Gold
</TD></TR><TR><TD> America </TD><TD> America </TD><TD rowspan="3"> All regions on american continents were put together.
</TD></TR><TR><TD> US </TD><TD> America
</TD></TR><TR><TD> Canada </TD><TD> America
</TD></TR><TR><TD> Medic </TD><TD> Health &amp; Medicine </TD><TD><UL><LI> Health &amp; Medicine
</LI><LI> Health/Medicine
</LI><LI> Medical
</LI></UL></TD></TR><TR><TD> Energy </TD><TD> Food &amp; Energy </TD><TD><UL><LI> Food &amp; Energy
</LI><LI> Food/Energy
</LI><LI> Energy
</LI></UL></TD></TR><TR><TD> Foundational </TD><TD> Foundational Advance </TD><TD><UL><LI> Foundational Advance
</LI><LI> Foundational Research
</LI></UL></TD></TR></TBODY></TABLE><H3><SPAN class="mw-headline" id="Updated_scoring_function"> Updated scoring function </SPAN></H3><P>After the in depth curation of all the award names, the scoring function had to be updated, since some awards had never been included in the scoring due to their rare awarding and some were lost in the naming issues. After updating the scores list, the data conversion to RData was rerun and the scoring was briefly checked by reviewing the list of the &quot;best&quot; teams.
</P><H3><SPAN class="mw-headline" id="Manual_data_curation"> Manual data curation </SPAN></H3><P>For some reason the 2011 championship awards were entirely missing on the standard results page. Thus we had to go directly to the jamboree results page and add the right awards to every team in 2011. This was done directly in the JSON file an the RData-file was updated imediately.
</P><H3><SPAN class="mw-headline" id="Bug-fix:_NA-values"> Bug-fix: NA-values </SPAN></H3><P>The award filters match the full team list to retrieve the names of the teams to keep in the dataset. These are then taken from the already reduced data set, which produces empty rows in the data for those teams, that match the award filter and were already removed the data-frame by another filter prior to the award matching. The naming of those empty rows is &quot;NA.number&quot;. Thus in order to remove these empty rows those row-names containing &quot;NA&quot; were removed. This was a really bad idea, because we spend lots of time trying to find out why our tool doesn't like the UNAM MEXICO teams. This bug was fixed by adding a dot to the regular expression and separately removing the first empty row, which would exactly match &quot;NA&quot;.
                                </P></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a22" data-toggle="tab">Methods</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a22"><H2><SPAN class="mw-headline" id="Update_of_methods"> Update of methods </SPAN></H2><P>The list of the methods was slightly updated and the clusters were removed, since they turned out to be not very intuitive. In order to find methods, that are actually mentioned in abstracts we went through those of teams who were successful in either the new application track, experimental measurement aproches and other practice associated directions. The updated list is displayed in table 22.1.
After rerunning the postprocessing of our data sets the top 10 methods list actually contained 10 methods of which many were newly added.
</P><TABLE class="wikitable"><CAPTION> Table 22.1: Updated methods list without clusters
</CAPTION><TBODY><TR><TH> Old </TH><TH> New </TH><TH> Removed
</TH></TR><TR><TD>Fusion Proteins, Primer Design, preparation of DNA, Restriction Digestion, Insert preparation, cell fractionation, cell counting, PCR, interaction chromatography, purification, Gel extraction, Ligation, Transformation, FRET, DNA extraction, patch clamp, Northern Blot, Southern Blot, Bioinformatics, ELISA, Chromatography, flow cytometry, X-Ray-crystallography, NMR, Electron microscopy, Molecular dynamics, coimmunoprecipitation, Electrophoretic mobility shift assay, size determination, gel electrophoresis, macromolecule blotting and probing, immuno assays, phenotypic analysis, imaging, spectroscopy, spectrometry
</TD><TD>traditional cloning, Gibson, bacterial artificial chromosome, protein interaction, FISH, assembly line, Sequencing, Microarray, computer simulation, drug production, encapsulation, genome deletion, mutagenesis, next generation sequencing, image processing, kill switch, Western Blot, Mass spectrometry, southwestern blot, fluorescence microscopy
</TD><TD>cloning, DNA sequencing, DNA Microarray, arrays, Western blotting, southwestern blotting
</TD></TR></TBODY></TABLE></DIV></DIV></DIV></DIV></DIV><DIV class="labjournal-weekly"><DIV><UL class="nav nav-tabs"><LI class="active"><A href="#a23" data-toggle="tab">Final details</A></LI></UL></DIV><DIV class="jumbotron weekly"><DIV class="scrollContent nav navbar" data-spy="scroll" data-target="#navbarExample" data-offset="0"><DIV class="tab-content"><DIV class="tab-pane active" id="a23"><H2><SPAN class="mw-headline" id="Bug_fixing"> Bug fixing </SPAN></H2><P>We noticed, that not all of the award filters gave the right number of teams. This was due to false unlisting in the JSON to RData conversion script. After fixing this bug and after removing the false runner up awards in 2011 all the awards were finally correct.
By converting the methods to lower case before matching them methods missing beforehand, as for example Gibson and FRET, could also be detected.
</P><H2><SPAN class="mw-headline" id="Design_adjustments"> Design adjustments </SPAN></H2><P>In order to have a nice layout when integrating the apps into a page resembling our wiki, a text box gicing a short introduction to the corresponding app was put next to the major input elements. This top section is now optically separated from the results area and all apps fit nicely into the minimum width of the iframe, which is 900px.
</P><H2><SPAN class="mw-headline" id="Chart_details"> Chart details </SPAN></H2><P>As most of our charts are only displaying discrete values we wanted to get rid of the extra decimal positions in the axis labeling. This was achieved by adding a short piece of javascript in the corresponding nvd3 plot parameters. Since the number of tick marks was not reduced by the rounding of the numbers this produced repetitive tick marks if only small values were displayed. To avoid this the height and the position of the plot were changed depending on the number of ticks to be displayed. As the final detail browser compatibility tags were added to the css and axis labels were added to the plots.
                                </P></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV><DIV class="row"><DIV class="col-md-12"><DIV class="imageMap" aria-haspopup="true"><CENTER>Thanks to </CENTER></DIV></DIV></DIV><DIV><DIV class="printfooter">
Retrieved from &quot;<A href="http://2013.igem.org/Team:Heidelberg/Notebook/iGEM42">http://2013.igem.org/Team:Heidelberg/Notebook/iGEM42</A>&quot;</DIV></DIV></DIV><DIV id="footer-box" class="noprint"><DIV id="footer"><UL id="f-list"><LI id="t-recentchanges"><A href="/Special:RecentChanges" title="Recent changes">Recent changes</A></LI><LI id="t-whatlinkshere"><A href="/Special:WhatLinksHere/Team:Heidelberg/Notebook/iGEM42" title="List of all wiki pages that link here [j]" accesskey="j">What links here</A></LI><LI id="t-recentchangeslinked"><A href="/Special:RecentChangesLinked/Team:Heidelberg/Notebook/iGEM42" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</A></LI><LI id="t-specialpages"><A href="/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</A></LI><LI><A href="/Special:Preferences">My preferences</A></LI></UL></DIV><DIV id="footer"><UL id="f-list"><LI id="t-print"><A href="/wiki/index.php?title=Team:Heidelberg/Notebook/iGEM42&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</A></LI><LI id="t-permalink"><A href="/wiki/index.php?title=Team:Heidelberg/Notebook/iGEM42&amp;oldid=361142" title="Permanent link to this revision of the page">Permanent link</A></LI><LI id="privacy"><A href="/2013.igem.org:Privacy_policy" title="2013.igem.org:Privacy policy">Privacy policy</A></LI><LI id="disclaimer"><A href="/2013.igem.org:General_disclaimer" title="2013.igem.org:General disclaimer">Disclaimers</A></LI></UL></DIV></DIV></DIV></DIV></DIV></DIV></DIV></BODY></HTML>