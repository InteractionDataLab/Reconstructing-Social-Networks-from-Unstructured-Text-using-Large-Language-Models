<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_Vilnius-Lithuania-OG_Gan_Introduction skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:Vilnius-Lithuania-OG/Gan Introduction</SPAN></H1></DIV></DIV></DIV><TITLE>Collaborations</TITLE><DIV id="" class="clearfix"><HEADER id="header" class="page-section full-header"><DIV id="header-wrap" style="padding-left:1%"><DIV class="clearfix"><NAV id="primary-menu"><UL><LI id="homeheader"><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG">Home</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Overview">Project</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Overview">Overview</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Design">Design</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Design_Regulatory">Design for Regulatory Parts</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Model">Modelling</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Results">Results</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Demonstrate">Proof of Concept</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Measurement">Measurement</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Improve">Improve</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Nucleotide_Design">Substrate Design Prospects</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Entrepreneurship">Entrepreneurship</A></LI></UL><LI id="softwareh"><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Software">Software</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Software">Motivation</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Gan_Introduction">Generative Adversarial Network – GAN</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/ProteinGAN">Protein GAN</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/ReactionGAN">Reaction GAN</A></LI><LI id="partsh"><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Parts">Parts</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Parts">Overview</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Parts#section-basic">Basic Parts</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Parts#section-composite">Composite Parts</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Parts#section-collection">Collection</A></LI><LI id="notebookh"><A href="/pages/notebook/index.html">Notebook</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/catseqguide">Using the CAT-Seq</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/labnotebook">Lab Journal</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/InterLab">Interlab</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Safety">Safety</A></LI><LI id="humanh"><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Human_Practices">Human practices</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Human_Practices">Human Practices</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Public_Engagement">Education and Public Engagement</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Collaborations">Collaborations</A></LI><LI id="peopleh"><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/People">People</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/People">Team</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Attributions">Attributions</A></LI><LI><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/Sponsors">Sponsors</A></LI></NAV></DIV></DIV></HEADER><SECTION id="slider" class="slider-element slider-parallax full-screen force-full-screen with-header swiper_wrapper page-section clearfix"><DIV class="slider-parallax-inner"><DIV class="swiper-container swiper-parent"><DIV class="swiper-wrapper"><DIV class="swiper-slide" style="background-image: url('https://static.igem.org/mediawiki/2018/f/fd/T--Vilnius-Lithuania-OG--gan.jpg');"><DIV class="container clearfix"><DIV class="slider-caption slider-caption-center"><H2 data-caption-animate="fadeInUp">Introduction To GANs</H2></DIV></DIV></DIV></DIV></DIV></DIV></SECTION><DIV id="page-menu"><DIV id="page-menu-wrap"><DIV class="container clearfix"><DIV class="menu-title">Explore <SPAN>GANs</SPAN></DIV><NAV class="one-page-menu"><UL><LI><A href="#" data-href="#section-introduction">Introduction</A></LI><LI><A href="#" data-href="#section-examples">Examples</A></LI><LI><A href="#" data-href="#section-synthetic">GANs and Synthetic Biology</A></LI></UL></NAV></DIV></DIV></DIV><SECTION style="overflow:hidden; position:relative; background-color: #FFF;"><DIV class="content-wrap"><DIV class="single-post nobottommargin"><DIV class="container clearfix"><SECTION id="section-introduction" class="page-section"><DIV class="tekstodydis"><DIV class="fancy-title title-border-color"><H2>What are Generative Adversarial Networks?</H2></DIV><P><B>Generative Adversarial Networks</B> (GANs) are <A href="#" data-toggle="tooltip" title="" data-original-title="Deep-learning networks perform automatic feature extraction without human intervention, unlike most traditional machine-learning algorithms">deep neural network</A>
	architectures comprised of two different networks, contesting with each other.</P><P>In 2014, <B>Ian Goodfellow</B> and his colleagues at University of Montreal introduced GANs in their <A href="https://arxiv.org/abs/1406.2661">research article</A></P><BLOCKQUOTE class=""><P>Generative Adversaral networks is the most interesting idea in the last ten years in machine learning</P><FOOTER class="blockquote-footer">Yann LeCun, Director, Facebook Ai</FOOTER></BLOCKQUOTE><P>These generative networks have an immense potential, as they can learn to <B>mimic any distribution of a given dataset</B>. GANs are creative „robot artists“ which are capable to imagine and generate things we can grasp and understand: images, music, speech, stories...</P><DIV align="center"><P>	Images generated by Creative Adversarial Networks [1]	</P></DIV><SECTION id="section-introduction" class="page-section"><DIV class="fancy-title title-border-color"><H2>Introduction by Analogy</H2></DIV><P>Let‘s say there is a jewelery store which purchases diamonds from customers and later resells them.</P><P>However, there are customers that have decided to try and sell fake diamonds. In such case, the jewelery store must be able to distinguish between the fake and real diamonds or else they will start losing money.</P><P>Initially, the forger might make a lot of mistakes when making and selling the fake diamonds and it will be easy for jewelery shop to identify that those diamonds are, in fact, fake. Yet, the forger will try many different techniques to simulate an authentic diamond and eventually might trick the store owners. After that, the forger knows that certain methods work better then the others, and will build upon those techniques to improve even more.</P><P>At the same time, the jewelery store might get some feedback from other shop owners or diamond quality experts. As the store receives more and more diamonds, they will become better and better at distinguishing them. </P><P>Therefore, the main goal of the forger is to make diamonds that are indistinguishable from the real ones, and the goal of the jewelery store is to try and tell them apart as accurately as possible.</P><P>This back and forth competition is the main idea behind <B>Generative Adversarial Networks</B>.</P><P>Using this analogy, we can come up with the architecture of a GAN.</P><P>There are two main components of GANs: the Generator and the Discriminator.</P><P>The diamond forger in the example is more formally known as the <B>Generator Network</B>. Such network randomly generates an output (fake diamond) from some initial values. As the Generator gets better after each round, <B>it learns how to better shape the output</B> so that the discriminator would have a harder time differentiating the generated output from the real one (or, in our example case, fake diamonds from the real diamonds).</P><P>On another hand, the jewelery store is known as the <B>Discriminator Network</B>.Just as the generative network tries to produce an output that is more similar to real output, the discriminator is trying to determine the differences between real and fake output as best as it can and <B>learns from its mistakes</B>.</P><P>Just like the forger‘s main goal is to create seamingly real diamonds, the <B>ultimate goal</B> of a Generative Adversarial network is to have a generative network that can produce outputs which are <B>indistinguishable from the real ones</B>.</P><DIV class="fancy-title title-border-color"><H2>Formal Introduction</H2></DIV><P>Let us now explore GANs‘ architecture in terms of image generation. In this case, the Generator is used to generate real-looking images and the Discriminator‘s job is to identify if the image is fake or not. In turn, these two networks,  pitted against each other, are in a constant battle as one (Generator) is trying to fool the other (Discriminator).</P><P>The system input can frequently be a <B>random noise</B>, for example a Guassian distribution, and values can be sampled from this disribution and fed into the generator network. Consequently, from those values some kind of image is generated. Following the output of a generator, the discriminator network receives that image and compares it to the real images from a provided dataset. </P><P>If the discriminator network performs well, it will swiftly decide that the initially generated image is fake and so, the game will continue. Yet, this time the generator will adjust its parameters just a little bit and try again. Just like that, the two networks will compete and try to improve and outperform each other with each round. Eventually, the Generator will reach a level of sophistication in which the generated images <B>will not be distinguishable</B> from real images anymore, which is the ultimate goal of GANs.</P><DIV class="toggle toggle-bg"><DIV class="togglet">Mathematical Description</DIV><DIV class="togglec"><P>The generative adversarial networks can be described as a <B>zero-sum game</B>, where the objective function is represented as a minimax function.</P><DIV align="center"><P><FONT size="3" style="font-size: 11pt">	Objective function	</FONT></P></DIV><P>The Discriminator is trying to <B>maximize</B> the objective function, therefore a <B>gradient ascent</B> can be performed on the objective function.</P><DIV align="center"><P><FONT size="3" style="font-size: 11pt">	Gradient Ascent	</FONT></P></DIV><P>In contrast, the generator tries to <B>minimize</B> the objective function, therefore a <B>gradient descent</B> can be performed and by altering between gradient ascent and descent, GANs can be trained.</P><DIV align="center"><P><FONT size="3" style="font-size: 11pt">	Gradient descent	</FONT></P></DIV><P>Yet, it was observed that optimizing the Generator objection does not work well, because when the sample is generated that is likely to be classifeid as fake, the model tries to learn from the gradients turn out relatively flat. Therefore, the generator objective function was changed so that <B>instead of minimizing</B> the likelihood of discriminator being correct, <B>it maximizes the likelihood of discriminator being wrong</B>. According to this new objective function, the gradient ascent is performed on the generator.</P><DIV align="center"><P><FONT size="3" style="font-size: 11pt">	New Generator Objective Function	</FONT></P></DIV></DIV></DIV><SECTION id="section-examples" class="page-section"><DIV class="fancy-title title-border-color"><H2>Applications and Examples of GANs</H2></DIV><H3>Transfer of image domain – CycleGANs</H3><P>These GANs transform images from one domain (say real scenery) to another domain (Say Van Gogh paintings) [8].</P><P>It can also transform pictures between zebras and horses!</P><H3>Super Resolution</H3><P>Super Resolution GANs (srGANs) allow to transform low resolution images into high resolution ones [9].</P><H3>High resolution image synthesis</H3><P>GAN algorithm called pix2pixHD allow to generate synthetic real life images from a semantic map [9].</P><H3>Generating images from text descriptions</H3><P>Researchers have also showed that GANs can be trained to generate visual scenaries that are described only by text [10].</P><H3>Drug Discovery</H3><P>Even though mainstream generative adversarial network research revolves around visuals, researchers from Insilico Medicine proposed an approach of drug discovery using GANS [11].</P><P>Similar work with anti-cancer compounds resulted in prediction of compounds that are already proven to be anti-cancer agents and new untested compounds that should be validated with further experiments.</P><SECTION id="section-synthetic" class="page-section"><DIV class="fancy-title title-border-color"><H2>GANs and Synthetic Biology</H2></DIV><P>There is no doubt the Generative Adversarial Networks is an amazing tool which can bring immense changes into numerous, if not all, scientific fields. </P><P>Yet, expanding GANs can be a challenging task frequently requires a complete rethink of whole network architecture as was shown by previous examples [12-14], and has yet to reach the field of Synthetic Biology.</P><P>Despite that, we believe that GANs have the potential to be an <B>indespensible tool for a synthetic biology</B> and have decided to press forward and <B>take the first steps in smart in-silico biological part creation</B>.</P><P><A href="https://2018.igem.org/Team:Vilnius-Lithuania-OG/ProteinGAN"> Click here to find how we used GANs </A></P><DIV class="toggle toggle-bg"><DIV class="togglet">References</DIV><DIV class="togglec"><FONT size="3" style="font-size: 11pt"><OL><LI><P align="justify">Goodfellow,	Ian, et al. &quot;Generative adversarial nets.&quot; Advances in
									neural information processing systems. 2014.</P></LI><LI><P align="justify">Justin	Johnson, F. (2018). [online] stanford.edu. Available at:
									http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture13.pdf
									[Accessed 28 Sep. 2018].</P></LI><LI><P align="justify">Zhang,	Zhifei, Yang Song, and Hairong Qi. &quot;Age progression/regression
									by conditional adversarial autoencoder.&quot; The IEEE Conference on
									Computer Vision and Pattern Recognition (CVPR). Vol. 2. 2017.</P></LI><LI><P>Isola,	Phillip, et al. &quot;Image-to-image translation with conditional
									adversarial networks.&quot; arXiv preprint (2017).</P></LI><LI><P>Towards	Data Science. (2018). Generative Adversarial Networks — Explained
									– Towards Data Science. [online] Available at:
									https://towardsdatascience.com/generative-adversarial-networks-explained-34472718707a
									[Accessed 28 Sep. 2018].</P></LI><LI><P>Liu,	Xuanqing, and Cho-Jui Hsieh. &quot;From Adversarial Training to
									Generative Adversarial Networks.&quot; arXiv preprint
									arXiv:1807.10454 (2018).</P></LI><LI><P>Kdnuggets.com.	(2018). Generative Adversarial Networks – Hot Topic in Machine
									Learning. [online] Available at:
									https://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html
									[Accessed 28 Sep. 2018].</P></LI><LI><P align="justify">JZhu,	Jun-Yan, et al. &quot;Unpaired image-to-image translation using
									cycle-consistent adversarial networks.&quot; arXiv preprint (2017).</P></LI><LI><P align="justify">Ledig,	Christian, et al. &quot;Photo-Realistic Single Image
									Super-Resolution Using a Generative Adversarial Network.&quot; CVPR.
									Vol. 2. No. 3. 2017.</P></LI><LI><P align="justify">Reed,	Scott, et al. &quot;Generative adversarial text to image synthesis.&quot;
									arXiv preprint arXiv:1605.05396 (2016).</P></LI><LI><P align="justify">YouTube.	(2018). Generative Adversarial Networks for Drug Discovery 4x3.
									[online] Available at: https://www.youtube.com/watch?v=xkcHP_OOjyM
									[Accessed 29 Sep. 2018].</P></LI><LI><P align="justify">Khrabrov,	K., et al. &quot;DruGAN: An Advanced Generative Adversarial
									Autoencoder Model for de Novo Generation of New Molecules with
									Desired Molecular Properties in Silico.&quot; (2017).</P></LI><LI><P align="justify">Beers,	Andrew, et al. &quot;High-resolution medical image synthesis using
									progressively grown generative adversarial networks.&quot; arXiv
									preprint arXiv:1805.03144 (2018).</P></LI><LI><P>Galbusera, Fabio, et al. &quot;Exploring the potential of generative
									adversarial networks for synthesizing radiological images of the
									spine to be used in in silico trials.&quot; Frontiers in
									Bioengineering and Biotechnology 6 (2018)</P></LI></OL></FONT></DIV></DIV></SECTION></SECTION></SECTION></DIV></SECTION></DIV></DIV></DIV></SECTION></DIV></BODY></HTML>