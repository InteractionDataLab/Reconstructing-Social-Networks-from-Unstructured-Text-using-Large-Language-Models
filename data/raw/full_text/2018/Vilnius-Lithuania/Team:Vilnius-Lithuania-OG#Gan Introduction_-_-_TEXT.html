Team:Vilnius-Lithuania-OG/Gan Introduction
Collaborations
Home
Project
Overview
Design
Design for Regulatory Parts
Modelling
Results
Proof of Concept
Measurement
Improve
Substrate Design Prospects
Entrepreneurship
Software
Motivation
Generative Adversarial Network – GAN
Protein GAN
Reaction GAN
Parts
Overview
Basic Parts
Composite Parts
Collection
Notebook
Using the CAT-Seq
Lab Journal
Interlab
Safety
Human practices
Human Practices
Education and Public Engagement
Collaborations
People
Team
Attributions
Sponsors
Introduction To GANs
Explore GANs
Introduction
Examples
GANs and Synthetic Biology
What are Generative Adversarial Networks?
Generative Adversarial Networks (GANs) are deep neural network architectures comprised of two different networks, contesting with each other.
In 2014, Ian Goodfellow and his colleagues at University of Montreal introduced GANs in their research article
Generative Adversaral networks is the most interesting idea in the last ten years in machine learning
Yann LeCun, Director, Facebook Ai
These generative networks have an immense potential, as they can learn to mimic any distribution of a given dataset. GANs are creative „robot artists“ which are capable to imagine and generate things we can grasp and understand: images, music, speech, stories...
Images generated by Creative Adversarial Networks [1]
Introduction by Analogy
Let‘s say there is a jewelery store which purchases diamonds from customers and later resells them.
However, there are customers that have decided to try and sell fake diamonds. In such case, the jewelery store must be able to distinguish between the fake and real diamonds or else they will start losing money.
Initially, the forger might make a lot of mistakes when making and selling the fake diamonds and it will be easy for jewelery shop to identify that those diamonds are, in fact, fake. Yet, the forger will try many different techniques to simulate an authentic diamond and eventually might trick the store owners. After that, the forger knows that certain methods work better then the others, and will build upon those techniques to improve even more.
At the same time, the jewelery store might get some feedback from other shop owners or diamond quality experts. As the store receives more and more diamonds, they will become better and better at distinguishing them.
Therefore, the main goal of the forger is to make diamonds that are indistinguishable from the real ones, and the goal of the jewelery store is to try and tell them apart as accurately as possible.
This back and forth competition is the main idea behind Generative Adversarial Networks.
Using this analogy, we can come up with the architecture of a GAN.
There are two main components of GANs: the Generator and the Discriminator.
The diamond forger in the example is more formally known as the Generator Network. Such network randomly generates an output (fake diamond) from some initial values. As the Generator gets better after each round, it learns how to better shape the output so that the discriminator would have a harder time differentiating the generated output from the real one (or, in our example case, fake diamonds from the real diamonds).
On another hand, the jewelery store is known as the Discriminator Network.Just as the generative network tries to produce an output that is more similar to real output, the discriminator is trying to determine the differences between real and fake output as best as it can and learns from its mistakes.
Just like the forger‘s main goal is to create seamingly real diamonds, the ultimate goal of a Generative Adversarial network is to have a generative network that can produce outputs which are indistinguishable from the real ones.
Formal Introduction
Let us now explore GANs‘ architecture in terms of image generation. In this case, the Generator is used to generate real-looking images and the Discriminator‘s job is to identify if the image is fake or not. In turn, these two networks,  pitted against each other, are in a constant battle as one (Generator) is trying to fool the other (Discriminator).
The system input can frequently be a random noise, for example a Guassian distribution, and values can be sampled from this disribution and fed into the generator network. Consequently, from those values some kind of image is generated. Following the output of a generator, the discriminator network receives that image and compares it to the real images from a provided dataset.
If the discriminator network performs well, it will swiftly decide that the initially generated image is fake and so, the game will continue. Yet, this time the generator will adjust its parameters just a little bit and try again. Just like that, the two networks will compete and try to improve and outperform each other with each round. Eventually, the Generator will reach a level of sophistication in which the generated images will not be distinguishable from real images anymore, which is the ultimate goal of GANs.
Mathematical Description
The generative adversarial networks can be described as a zero-sum game, where the objective function is represented as a minimax function.
Objective function
The Discriminator is trying to maximize the objective function, therefore a gradient ascent can be performed on the objective function.
Gradient Ascent
In contrast, the generator tries to minimize the objective function, therefore a gradient descent can be performed and by altering between gradient ascent and descent, GANs can be trained.
Gradient descent
Yet, it was observed that optimizing the Generator objection does not work well, because when the sample is generated that is likely to be classifeid as fake, the model tries to learn from the gradients turn out relatively flat. Therefore, the generator objective function was changed so that instead of minimizing the likelihood of discriminator being correct, it maximizes the likelihood of discriminator being wrong. According to this new objective function, the gradient ascent is performed on the generator.
New Generator Objective Function
Applications and Examples of GANs
Transfer of image domain – CycleGANs
These GANs transform images from one domain (say real scenery) to another domain (Say Van Gogh paintings) [8].
It can also transform pictures between zebras and horses!
Super Resolution
Super Resolution GANs (srGANs) allow to transform low resolution images into high resolution ones [9].
High resolution image synthesis
GAN algorithm called pix2pixHD allow to generate synthetic real life images from a semantic map [9].
Generating images from text descriptions
Researchers have also showed that GANs can be trained to generate visual scenaries that are described only by text [10].
Drug Discovery
Even though mainstream generative adversarial network research revolves around visuals, researchers from Insilico Medicine proposed an approach of drug discovery using GANS [11].
Similar work with anti-cancer compounds resulted in prediction of compounds that are already proven to be anti-cancer agents and new untested compounds that should be validated with further experiments.
GANs and Synthetic Biology
There is no doubt the Generative Adversarial Networks is an amazing tool which can bring immense changes into numerous, if not all, scientific fields.
Yet, expanding GANs can be a challenging task frequently requires a complete rethink of whole network architecture as was shown by previous examples [12-14], and has yet to reach the field of Synthetic Biology.
Despite that, we believe that GANs have the potential to be an indespensible tool for a synthetic biology and have decided to press forward and take the first steps in smart in-silico biological part creation.
Click here to find how we used GANs
References
Goodfellow, Ian, et al. "Generative adversarial nets." Advances in          neural information processing systems. 2014.
Justin Johnson, F. (2018). [online] stanford.edu. Available at:          http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture13.pdf          [Accessed 28 Sep. 2018].
Zhang, Zhifei, Yang Song, and Hairong Qi. "Age progression/regression          by conditional adversarial autoencoder." The IEEE Conference on          Computer Vision and Pattern Recognition (CVPR). Vol. 2. 2017.
Isola, Phillip, et al. "Image-to-image translation with conditional          adversarial networks." arXiv preprint (2017).
Towards Data Science. (2018). Generative Adversarial Networks — Explained          – Towards Data Science. [online] Available at:          https://towardsdatascience.com/generative-adversarial-networks-explained-34472718707a          [Accessed 28 Sep. 2018].
Liu, Xuanqing, and Cho-Jui Hsieh. "From Adversarial Training to          Generative Adversarial Networks." arXiv preprint          arXiv:1807.10454 (2018).
Kdnuggets.com. (2018). Generative Adversarial Networks – Hot Topic in Machine          Learning. [online] Available at:          https://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html          [Accessed 28 Sep. 2018].
JZhu, Jun-Yan, et al. "Unpaired image-to-image translation using          cycle-consistent adversarial networks." arXiv preprint (2017).
Ledig, Christian, et al. "Photo-Realistic Single Image          Super-Resolution Using a Generative Adversarial Network." CVPR.          Vol. 2. No. 3. 2017.
Reed, Scott, et al. "Generative adversarial text to image synthesis." arXiv preprint arXiv:1605.05396 (2016).
YouTube. (2018). Generative Adversarial Networks for Drug Discovery 4x3.          [online] Available at: https://www.youtube.com/watch?v=xkcHP_OOjyM          [Accessed 29 Sep. 2018].
Khrabrov, K., et al. "DruGAN: An Advanced Generative Adversarial          Autoencoder Model for de Novo Generation of New Molecules with          Desired Molecular Properties in Silico." (2017).
Beers, Andrew, et al. "High-resolution medical image synthesis using          progressively grown generative adversarial networks." arXiv          preprint arXiv:1805.03144 (2018).
Galbusera, Fabio, et al. "Exploring the potential of generative          adversarial networks for synthesizing radiological images of the          spine to be used in in silico trials." Frontiers in          Bioengineering and Biotechnology 6 (2018)
