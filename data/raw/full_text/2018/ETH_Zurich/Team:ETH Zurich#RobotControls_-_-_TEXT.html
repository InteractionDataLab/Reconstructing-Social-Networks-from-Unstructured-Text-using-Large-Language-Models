Team:ETH Zurich/RobotControls
Project
Description
Applied Design
Team Members
Attributions
Sponsoring
Notebook
Safety
Downloads
Wet Lab
Tar Receptor Evolution
Approach A
Approach B
Experiments
InterLab
Hardware
Hardware Overview
Microscope
Mechanics
Syringe Pump
Microfluidic Chip
Bubbling
Software
Software Overview
Motility Readout
Luminescence Algorithm
Robot Controls
Path Planning
Logo Website
Model
Model Overview
Integrated Models
Motility Model
Split Luciferase Model
Diffusion Model
Bubbling Model
Holographic Imaging Model
Screening Assay Model
Model Parameters
Human Practices
Human Practices
Education & Engagement
Achievements
Results
Parts Overview
Demonstrate
Collaborations
Content
Introduction Table
Home
A.R.O.M.A.
Logo Website
Project
Description
Applied Design
Team Members
Attributions
Sponsoring
Notebook
Safety
Downloads
Wet Lab
Tar Receptor Evolution
Approach A
Approach B
Experiments
InterLab
Hardware
Hardware Overview
Microscope
Mechanics
Syringe Pump
Microfluidic Chip
Bubbling
Software
Software Overview
Motility Readout
Luminescence Algorithm
Robot Controls
Path Planning
Model
Model Overview
Integrated Models
Motility Model
Split Luciferase Model
Diffusion Model
Bubbling Model
Screening Assay Model
Holographic Imaging Model
Human Practices
Human Practices
Education & Engagement
Achievements
Results
Parts Overview
Demonstrate
Collaborations
Robot Controls.
Scroll
Introduction
On this page we give a brief introduction on the ROS interface for all of our DIY hardware components and explain how they interact with each other.
Description of the components
THE PLATFORM:
We decided to interface all of our components in the robotics framework ROS (Robotic Operating System). Although this platform is normally used by developers, it allows to us establish a very easy interface between individual hardware components or even computing units. Therefore, ROS provided the perfect solution to control the DIY components which are all (except for the camera) directly connected to a RaspberryPi.
INTERFACING THE BASIC PARTS:
Every basic part has its own node. A node represents a small process which controls an individual component such as for example a syringe pump and contains a pipe to which one can send the respective commands.  In this way the controlling commands can be conveniently send from a normal computer and later from another algorithm which controls the autonomous workflow on AROMA. This top-level algorithm is named State Machine.
CAMERA NODE:
The only hardware component which needs to be operated using a proper computer is our camera. Especially when running the motility readout algorithm the real-time processing of an input image sequence at 30fps is necessary. Our camera readout and image processing algorithm also has an interface to ROS and therefore as also shown on the Demonstration page again the computing unit processing the imaging data can be easily interface with the hardware components controlled by the GPIO pins of our RaspberryPi. As the imaging sensor is very specific we even needed to program the integration into ROS on our own.
Results
We programmed all the software tools required to autonomously run AROMA. However, we also enforced a maximum level of flexibility such that also only one single syringe pump can be controlled conveniently. Therefore, our individual hardware components can also be used to equip a lab when only having a really minimalistic budget.
Sponsors
Contact Us
