<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_ETH_Zurich_Microscope skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:ETH Zurich/Microscope</SPAN></H1></DIV><DIV id="HQ_page"><DIV id="bodyContent"><DIV id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><DIV class="container-nav-menu"><DIV class="nav-menu"><DIV class="nav-menu-left "><DIV class="nav-item" id="nav-item1"><SPAN>Project</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Description">Description</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Applied_Design">Applied Design</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Team">Team Members</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Attributions">Attributions</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Sponsoring">Sponsoring</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Notebook">Notebook</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Safety">Safety</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Download">Downloads</A></LI></UL></DIV><DIV class="nav-item" id="nav-item2"><SPAN>Wet Lab</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Tar">Tar Receptor Evolution</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ApproachA">Approach A</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ApproachB">Approach B</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Experiments">Experiments</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/InterLab">InterLab</A></LI></UL></DIV><DIV class="nav-item" id="nav-item3"><SPAN>Hardware</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Hardware">Hardware Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Microscope">Microscope</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Mechanics">Mechanics</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/SyringePump">Syringe Pump</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/MicrofluidicChip">Microfluidic Chip</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/bubbling">Bubbling</A></LI></UL></DIV><DIV class="nav-item" id="nav-item4"><SPAN>Software</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Software">Software Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Motility_Readout">Motility Readout</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ImageAnalysis">Luminescence Algorithm</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/RobotControls">Robot Controls</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Path_Planning">Path Planning</A></LI></UL></DIV></DIV><DIV class="nav-menu-middle "><DIV class="nav-item" id="home"><A href="https://2018.igem.org/Team:ETH_Zurich"><TITLE id="title6">Logo Website</TITLE></A></DIV></DIV><DIV class="nav-menu-right "><DIV class="nav-item" id="nav-item5"><SPAN>Model</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Model">Model Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/integratedModel">Integrated Models</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/motilityModel">Motility Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/splitModel">Split Luciferase Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/diffusionModel">Diffusion Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/bubbelingModel">Bubbling Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/HolographicModel">Holographic Imaging Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Screening">Screening Assay Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Parameter">Model Parameters</A></LI></UL></DIV><DIV class="nav-item" id="nav-item6"><SPAN>Human Practices</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Human_Practices">Human Practices</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Public_Engagement">Education &amp; Engagement</A></LI></UL></DIV><DIV class="nav-item" id="nav-item7"><SPAN>Achievements</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Results">Results</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Parts">Parts Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Demonstrate">Demonstrate</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Collaborations">Collaborations</A></LI></UL></DIV></DIV></DIV><DIV class="container-content"><DIV id="tongue1" class="content-tongue"><DIV class="tongue-div" id="tongue-div1">Content</DIV></DIV><DIV class="content-text"><SPAN href="section-Introduction" class="content-item">Introduction</SPAN><SPAN href="container_table" class="content-item">Table</SPAN></DIV></DIV></DIV><DIV class="main-menu"><A href="https://2018.igem.org/Team:ETH_Zurich"><DIV class="home">
        Home
      </DIV></A><DIV class="main-titel"><A href="https://2018.igem.org/Team:ETH_Zurich">
        A<SPAN>.</SPAN>R<SPAN>.</SPAN>O<SPAN>.</SPAN>M<SPAN>.</SPAN>A<SPAN class="main-letterSpacing">.</SPAN></A></DIV><A href="https://2018.igem.org/Team:ETH_Zurich"><DIV class="menu-logo"><TITLE id="title6">Logo Website</TITLE></DIV></A></DIV><DIV class="main-submenu"><DIV class="alt-main-submenu-item" id="alt-nav-item1" href="#project"><SPAN>Project</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Description">Description</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Applied_Design">Applied Design</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Team">Team Members</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Attributions">Attributions</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Sponsoring">Sponsoring</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Notebook">Notebook</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Safety">Safety</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Download">Downloads</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item2" href="#parts"><SPAN>Wet Lab</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Tar">Tar Receptor Evolution</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ApproachA">Approach A</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ApproachB">Approach B</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Experiments">Experiments</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/InterLab">InterLab</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item3" href="#modelling"><SPAN>Hardware</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Hardware">Hardware Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Microscope">Microscope</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Mechanics">Mechanics</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/SyringePump">Syringe Pump</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/MicrofluidicChip">Microfluidic Chip</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/bubbling">Bubbling</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item4"><SPAN>Software</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Software">Software Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Motility_Readout">Motility Readout</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ImageAnalysis">Luminescence Algorithm</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/RobotControls">Robot Controls</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Path_Planning">Path Planning</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item5"><SPAN>Model</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Model">Model Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/integratedModel">Integrated Models</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/motilityModel">Motility Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/splitModel">Split Luciferase Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/diffusionModel">Diffusion Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/bubbelingModel">Bubbling Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Screening">Screening Assay Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/HolographicModel">Holographic Imaging Model</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item6"><SPAN>Human Practices</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Human_Practices">Human Practices</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Public_Engagement">Education &amp; Engagement</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item7"><SPAN>Achievements</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Results">Results</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Parts">Parts Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Demonstrate">Demonstrate</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Collaborations">Collaborations</A></LI></UL></DIV></DIV><DIV class="mobileMenuBg" style="visibility: hidden"><DIV class="container-titel"><DIV class="titel" id="titel">
        Microscope<SPAN>.</SPAN></DIV><DIV class="scroll">Scroll</DIV></DIV><DIV class="section-Introduction contentTable" contenttable="Introduction" contentref=".section-Introduction"><P>
        Throughout the project we pursued and experimented with multiple imaging approaches. On the final version of AROMA we used the <A href="#brightfield_id"> brightfield motility imaging </A>approach, corresponding to<A href="https://2018.igem.org/Team:ETH_Zurich/ApproachA" target="_blank">  Approach A </A>, presented
        on the left hand side. Furthermore we present a possible improvement of this brightfield approach, namely a<A href="#lensless_id"> lensless microscope</A> which would come at a reduced height and cost but so far does not provide enough resolution
        yet. For our luminescence <A href="https://2018.igem.org/Team:ETH_Zurich/ApproachB" target="_blank">  approach B </A>  we also created an <A href="#luminescence_id"> imaging solution</A>shown on the right.
        Although the requirements are pretty different for all of those three imaging approaches, the hardware implementation is always based on our <A href="#modular_mic_id">modular imaging casing system</A> and the same imaging chip.
      </P></DIV><DIV class="container_figure" id="fig0"><DIV class="figures_container"><DIV class="figure" id="fig1"><DIV class="subfigure_caption">Brightfield Imaging Setup</DIV></DIV><DIV class="figure" id="fig2"><DIV class="subfigure_caption">Luminescence Imaging Setup</DIV></DIV><DIV class="figure" id="fig3"><DIV class="subfigure_caption">Lensless Imaging Setup</DIV></DIV></DIV><DIV class="figure_caption caption_center">Figure showing our different imaging setups.</DIV></DIV><DIV id="brightfield_id" class="sectionh1 contentTable contentBrightField" contenttable="Bright Field" contentref=".contentBrightField">Brightfield Microscope</DIV><DIV class="sectionh2">Introduction</DIV><DIV class="text">
      Brightfield imaging is the most commonly used microscope setup. One illuminates the sample from one side and images from the other. The attenuation of light at the sample is then visible as a dark spot on an otherwise bright background. The benefit of using this approach is the relatively simple design and the fact that the concepts are well-known and have been applied for a very long time. Additionally, having a small focus plane results in fewer artifacts from the microfluidic chip and dirt and allows to precisely focus on the plane of <SPAN class="italic">E. coli</SPAN>. The only downside of this approach is the limited contrast. Biological samples often do not provide a strong contrast, which is also the case for <SPAN class="italic">E. coli</SPAN>. This can be explained with the attenuation not being strong enough. Nevertheless, we were keen to test this method and optimize it to image <SPAN class="italic">E. coli</SPAN> in a quality that makes it suitable for our image processing algorithm. Meaningly, to resolve them on a single-cell level.
    </DIV><DIV class="sectionh2">Theory</DIV><DIV class="text"><DIV class="subtitel">Illumination</DIV>
      The illumination is a crucial part when it comes to microscopy. In brightfield microscopy a LED is used as a light source which should illuminate the source as evenly as possible. Not only the intensity but also the direction of the light rays are important. Ideally they should be perfectly parallel. We looked into different techniques for achieving such a lighting, such as the Koehler illumination. During our experiments we found out, that due to our special evenly illuminating LED we did not need to add additional lenses. Therefore we ended up placing the LED at a distance of around 10 cm from the sample. Without adding complexity to our setup this ensures even lighting and satisfies our requirements.
    </DIV><DIV class="text"><DIV class="subtitel">Magnification</DIV></DIV><DIV class="text clearfix"><DIV class="textpicture-right textpicture30"><DIV class="figure_caption caption_left">Brightfield Microscope Setup</DIV></DIV>
      We decided to go for a 10x magnification. When considering the size of E. coli (~1 µm) and the sensor’s pixel size of 1.67 µm, a magnification of 10x results in the cells having roughly the size of 6 pixels. In order to achieve the desired magnification we used an infinity lens setup. We therefore used two plano-convex lenses with a ratio of their focal lengths of 1:10. We placed the lens with the low focal length (objective lens) right after the sample with a distance of the focal length. Then we place the second lens (tube lens) with the long focal length in theoretical arbitrary distance to the first lens. The last step is to place the sensor again in the focal distance of the long lens. This results in the rays to be parallel between the two lenses and enables an easy exchange of the objective lens (corresponding to achieving a different magnification). In this so called infinity optics, the distance between the objective and tube lens can be chosen arbitrarily. One also has to consider that the amount of aberrations increases when using an objective lens with an extremely short focal distance. Therefore, having a 10x magnification is also a good tradeoff between sharpness, magnification and compactness of the setup.
    </DIV><DIV class="sectionh2">Implementation</DIV><DIV class="text"><DIV class="subtitel">Set-Up</DIV>
      To build the brightfield microscope we started to design and develop all the necessary parts (LCCSM system) which were then 3D printed. The <A href="#modular_mic_id">LCCSM </A>is the basis for our brightfield microscope and we customized and optimized every single part. We started by mounting the camera sensor inside the base plate. Then we stacked a height segment of 5 cm and then mounted the 5 cm Thorlabs mount part.
In that mount we can fit the rail system of Thorlabs. Both of our lenses are mounted to the rails which allows an easy adjustment of their height. Ideally one places the lenses in a way such that the they face each other with the flat side in order to reduce aberrations. As already described in the theory section the less curved, tube lens is placed facing the sensor and the objective lens facing the sample. We used a 250 mm and 24 mm lens so the distance in between the sensor and the tube lens should be exactly 250 mm and the objective lens should be 24 mm away from the sample, while the distance in between the lenses does not have any effect. This results in an exact magnification of 10.4x. 
We would not recommend using a higher magnification as the setup becomes even taller (when using another tube lens) or the sharpness is reduced due to aberrations (when using another objective lens). The rail system of Thorlabs is then enclosed in our casing system which protects the apparatus from external spill light. 
Approximately 24mm behind the objective lens, the microfluidic chip is mounted. The mount allows to move the chip horizontally, making it possible to image different channels. On top of that we put the lid, another 10 cm part and finally the part containing the LED lightsource. The total setup can reach a height of up to 45 cm, but depending on the magnification and light source system this is usually lower.
    </DIV><DIV class="text"><DIV class="subtitel">Illustration Video</DIV></DIV><DIV class="text"><DIV class="container_table"><DIV class="table_caption caption_center">Parts Used in our brightfield setup.</DIV><DIV class="table"><TABLE><THEAD><TR><TH>3D Parts Used</TH><TH>Optical Elements Used</TH></TR></THEAD><TBODY><TR><TD>2x 10cm, 5cm, 1cm section</TD><TD>Thorlabs 8x 10cm rods</TD></TR></TBODY><TBODY><TR><TD>Thorlabs top and bottom adapter</TD><TD>Thorlabs Rod Connector CP02/M</TD></TR></TBODY><TBODY><TR><TD>Microfluidic chip case</TD><TD>Tube Lens - f=200mm plano convex LA1708</TD></TR></TBODY><TBODY><TR><TD>Filter section</TD><TD>Object Lens - f=25.4mm plano convex LA 1951 </TD></TR></TBODY><TBOD><TBODY><TR><TD>Top LED section</TD><TD>Bright LED (LED-CO) Distrelec</TD></TR></TBODY></TBOD></TABLE></DIV></DIV></DIV><DIV class="text"><DIV class="subtitel">Focusing</DIV>
      Focusing the two lenses ended up being one of the hardest challenges at first. It is extremely difficult to measure the exact distances from the lens to the sensor or sample and one therefore needs different, more precise techniques. The tube lens, with the long focal length, which sits above the sensor, can be calibrated in the following way: One only mounts this single lens in front of the camera. One then points the whole thing towards a distant object, 50m or more away. You then adjust the distance of the lens to the camera sensor until you see a sharp image of the distant object. The theory behind this is simple. The distant object is so far away that focusing to it essentially means focusing on infinite rays coming into the lens. And as the basics of lens theory tell us infinite rays are directed through the focal point of a lens resulting in a sharp image.
In order to focus the objective lens we needed to assemble the whole microscope as explained above. We then have two possibilities. We can either move the sample up and down or the objective lens. We tested both strategies. First, we built a height adjustable sample tray, which worked, but ended up being not very practical, as one ideally wants the sample to stay at a place and additionally it makes it harder to add a function to move the sample from left to right in order to swap the microfluidic channel. [TRALALA Microfluidic Link] Due to those reasons we stuck to the second possibility: moving the objective lens. We implemented this by simply adding a longer thread to the lens which is anyways screwed into the Thorlab mount. This way we don’t screw the lens thightly in, but adjust its focus by screwing it further in or out. Sometimes it is these small things making a self built microscope setup work.
    </DIV><DIV class="picture picture60"><DIV class="picture-caption">
        Robert focusing the tube lens to infinity
      </DIV></DIV><DIV class="text"><DIV class="subtitel">Optimization</DIV></DIV><DIV class="text clearfix"><DIV class="textpicture-right textpicture40"><DIV class="figure_caption caption_left">The bandpass filter mounted on the modular microscope</DIV></DIV>
When implementing the above-mentioned strategies one can already obtain very good results. We were able to easily image beads with diameters of 5, 3 and 1 µm. They were clearly distinguishable and well visible without any further processing of the image. It was still hard to clearly identify single E. coli bacteria. This can be explained with the aberration, in particular the chromatic aberrations. As we used inexpensive lenses we had to deal with strong chromatic aberrations and as our sensor is monochromatic they created a blur over the whole image. This is why we added a bandpass filter, only letting light of a specific wavelength pass. This improved our result significantly, enabling us to image E. coli with our own microscope.
    </DIV><DIV class="text"><DIV class="subtitel">Comparison</DIV>
      In order to better classify our brightfield imaging solution, we compare our results to two commercially available solutions. In terms of compactness our solution is roughly comparable to USB, handheld microscopes. In particular, we compared our own setup with the DinoLite high magnification device, the AM4515T8, which is to date, one of Dino Lite’s highest magnification devices and costs around 700 Euros. While the AM4515T8 is more compact than our device, in our experiments we could not resolve E.coli at all making it unsuitable for our approach. Bigger, high-end lab microscopes obviously achieve a way better resolution and overall imaging quality. However, their price is significantly higher and they cannot be packed onto a small robot like AROMA.
    </DIV><DIV class="sectionh2">Results</DIV><DIV class="text">
      We achieved great results with our brightfield microscope. We were able to clearly resolve E.coli with our own LCCSM system and a cheap monochromatic imaging sensor. This allowed us to further process the images and determine the motility of the tiny bacteria. <A href="https://2018.igem.org/Team:ETH_Zurich/Motility_Readout" target="_blank"> See motility image analysis</A>. We would like to particularly highlight that we do not know any commercially available platform at a comparable price that achieves the same resolution capabilities. Furthermore we want to point out that with our LCCSM system even higher magnifications are possible, when sacrificing the compactness.
    </DIV><DIV class="picture picture60"><DIV class="picture-caption">
        E. Coli imaged with our brightfield imaging setup after adding contrast
      </DIV></DIV><DIV id="lensless_id" class="sectionh1 contentTable contentLensless" contenttable="Lensless Microscope" contentref=".contentLensless">Lensless Microscope</DIV><DIV class="sectionh2">Introduction</DIV><DIV class="text">
      While our brightfield imaging approach generated good and reliable results, the underlying concepts are already well known and have been applied fora very long time. As we want our biosensor to be as cheap and compact as possible, we also did some research on how the brightfield approach could be further improved or expanded. Throughout this research we came across the field of lensless microscopy, which to us seems the perfect evolution in combination with the motility imaging problem.
However, as there are only a few groups in the world using lensless devices we also knew that it would be extremely difficult to get such a device running. Our first experiments on the lensless approach went very well and we were able to resolve 8 µm small yeast cells. However, as the follow-up experiments and improvements did not lead to the expected results, we decided to create a <A href="https://2018.igem.org/Team:ETH_Zurich/HolographicModel" target="_blank"> model </A>of this lensless system. This model actually perfectly confirmed all our experimental data but unfortunately also predicted difficulties to actually achieve the resolution necessary to resolve single E. coli cells using our available hardware.
Therefore, we put most of our effort in developing our brightfield microscope presented above. Nevertheless, in the following, we will show you some of our setups, results and how our own lensless imaging system evolved over time. We do hope that other iGEM teams in the future jump on this track and overcome the difficulties that come with this approach.  
    </DIV><DIV class="sectionh2">The evolution of our lensless microscope</DIV><DIV class="text"><DIV class="subtitel">Theory</DIV>
      Unlike the brightfield imaging approach shown above, a lensless microscope is not in need of lenses at all. This on the one hand reduces the cost of the overall setup but more importantly also shrinks the size of the microscope significantly
      as shown on top.
    </DIV><DIV class="text"><DIV class="subtitel">The first iteration</DIV>
      Our first prototype of a lensless imaging system simply consisted of a few LEGO bricks, a mobile phone as the lightsource and a raspberry pi camera chip with the lens being removed as explained <A href="http://kmdouglass.github.io/posts/accessing-the-raspberry-pi-camera-image-sensor.html">here</A>.
      The Figure below shows this overall setup. Notice that for the very first experiments the pinhole is not really needed.
    </DIV><DIV class="text">
      This classical shadow imaging setup, in which the incoherent LED lightsource is placed approximately 4-5 cm away from the sample and the sample as close as possible to the imaging sensor already leads to impressive results when imaging a sample of approximately 50 µm or bigger with strong contrast. The figure below for instance shows the result of imaging a hair in this setup. However, the limited coherence and the unrestricted large size of the lightsource (~0.5 cm radius) makes it impossible to resolve smaller structures with less contrast like for instance yeast cells. This is due to the fact that the shadows created from each “ray” of light simply overlap such that in the end everything blurs. This problem can be overcome by placing a pinhole in front of the light source as shown in the figure 2.3.

    </DIV><DIV class="container_figure"><DIV class="figures_container"><DIV class="figure"><DIV class="subfigure_caption">The raspberry pi camera sensor with a removed lens</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">Very first lensless measurement: A hair</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">The overall setup after adding a pinhole</DIV></DIV></DIV></DIV><DIV class="text"><DIV class="subtitel">The second iteration - adding a pinhole</DIV>
      From a theoretical perspective, the pinhole together with the incident bright light approximately leads to plane waves and a holographic image with a fringe magnification of 1. The holographic image is created through the interference of the incoming wave which passes the sample unscattered and the secondary waves which are emitted by the objects as illustrated in figure 3. By only adding a pinhole to the setup above we were able to successfully image yeast cells (see picture BELOW)
    </DIV><DIV class="container_figure"><DIV class="figures_container"><DIV class="figure"><DIV class="subfigure_caption">Illustration of the lensless setup by [Göröcs, Z., Ozcan, A., &amp; Member, S. (2013). On-Chip Biomedical Imaging, 6, 29–46.]</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">Illustration how the interference pattern forms by Jericho, M. H., &amp; Kreuzer, H. J. (2011). Point Source Digital In-Line Holographic Microscopy, 3–31. https://doi.org/10.1007/978-3-642-15813-1
          </DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">Measuring 8um large yeast cells with our own setup seen in figure 2</DIV></DIV></DIV></DIV><DIV class="text"><DIV class="subtitel">The final iteration</DIV></DIV><DIV class="text clearfix"><DIV class="textpicture-right textpicture30"><DIV class="figure_caption caption_left">The final Lensless Setup realised with our LCCSM</DIV></DIV>
      These first improvements were relatively easy to achieve, however in order to resolve even smaller structures the setup has to be significantly improved. There are two measures in  order to resolve even smaller particles whose interference patterns are even closer to each other. One would be to again reduce the size of the pinhole and the other one to get another imaging chip with a smaller pixel size. The second method was unfortunately not possible for us as we were already using an imaging chip with a tiny pixel size of 1.12 µm. Therefore we refined our setup once again and placed an even smaller pinhole (50 µm) after the lightsource. As now the overall light intensity reaching the imaging chip is greatly reduced, a proper casing is needed in order to avoid interference from ambient light. We therefore designed a suitable setup which is also added to the LCCSM system with which we were able to resolve beads as small as 1 µm. The results are shown below.
    </DIV><DIV class="container_figure" id="container_figure_6"><DIV class="figures_container"><DIV class="figure"><DIV class="subfigure_caption">1um beads</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">2um beads</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">3um beads</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">5um beads</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">E. coli in a high density visible in the background</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">Imaging of a microfluidic chip</DIV></DIV><DIV class="figure_caption caption_center">Different measurements accomplished with the Lensless microscope</DIV></DIV></DIV><DIV class="text">
      Nevertheless, it was not possible for us to resolve single E. coli in this setup. The reason for this lies in the fact that, in line with the results of our simulation (HERE LINK TO SIMULATION PAGE), the bacteria simply do not have enough contrast for our limited pixel size. What we did see though is a dense population of bacteria.
    </DIV><DIV class="sectionh2">Outlook</DIV><DIV class="text"><DIV class="subtitel">Possible future improvements to our final setup</DIV>
      Chulwoo et. al [https://doi.org/10.1364/OE.18.004717] propose using a briefringent crystal to introduce phase contrast to overcome this problem of limited contrast, however we did not have enough time and resources to implement this approach. Another idea to further improve the resolution and to achieve magnification even without lenses would be to switched to a monochromatic, coherent laser diode as lightsource (405 nm,150 mW from Thorlabs) and a very tiny pinhole (1 µm) to create a spherical wavefront. In such a setup, an additional magnification can be achieved through placing the sample way closer to the pinhole than to the sample as shown in the figure below. However, it is important to bear in mind that for this approach the monochromatic light source as well as the tiny pinhole are absolutely vital, as otherwise there would be too many interference patterns that overlap. In addition, an advanced image processing pipeline (like for instance holopy) is needed to infer the real objects from the hologram.
    </DIV><DIV class="container_figure"><DIV class="figures_container"><DIV class="figure_caption caption_center">Illustration how an additional magnification can be achieved in a lensless setup (left) compared with the standard setup (right) by Sang Bok Kim, Hojae Bae, Kyo-in Koo, Mehmet R. Dokmeci, Aydogan Ozcan, A. K. (2012). Lens-free Imaging for Biological Applications. J Lab Autom, 17(1), 43–49. https://doi.org/10.1177/2211068211426695.Lens-Free</DIV></DIV></DIV><DIV class="text"><DIV class="subtitel">Conclusion</DIV>
      With the lensless imaging setup presented above, we were able to distinguish structures as small as 1 µm beads. However, due to the lack of contrast, it was not possible to resolve individual E. coli cells. We still think that a lensless microscope would be the ideal evolution of our brightfield microscope, although also further issues such as the lack of a focal plane in a lensless microscope would have to be addressed.
    </DIV><DIV id="luminescence_id" class="sectionh1 contentTable contentLuminescence" contenttable="Lensless Microscope" contentref=".contentLuminescence">Luminescence Imaging</DIV><DIV class="sectionh2">Introduction</DIV><DIV class="text">
      Above, we presented two approaches on how to read out the biological signal corresponding to <A href="https://2018.igem.org/Team:ETH_Zurich/ApproachA" target="_blank">  Approach A </A>. We also invested time and effort to create a proper readout solution for <A href="https://2018.igem.org/Team:ETH_Zurich/ApproachB" target="_blank">  Approach B </A>. In particular, we added parts to our <A href="#modular_mic_id">LCCSM </A> system in order to satisfy the requirements in luminescence imaging and created an <A href="hhttps://2018.igem.org/Team:ETH_Zurich/ImageAnalysis" target="_blank">  algorithm </A> which allows us to read out a luminescence signal.
    </DIV><DIV class="text"><DIV class="subtitel">Design</DIV>
      The goal of the luminescence imaging solution is to detect a very low intensity of light. Inspired by TRALALA REF 1 which shows a luminescence detection in combination with  smartphone cameras, we decided to build our own luminescence imaging solution, based on our <A href="#modular_mic_id">LCCSM </A> system. Since the light intensity of a luminescence signal is very low, it is crucial to ensure an efficient capture of photons and to optimally protect the imaging chamber from external spill light (vgl TRALALA REF1). In order to increase the number of photons actually reaching our chip, we decided to put reflective aluminum foil in the lid of our imaging chamber. Ideally, this should double the intensity at the chip as the light emitted to the top is then also reflected down onto our sensor. The resulting system is shown below if figure TRALALA:

    </DIV><DIV class="container_figure" id="fig4"><DIV class="figures_container"><DIV class="figure"><DIV class="subfigure_caption">Sample holder</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">Imaging Camera</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">Reflective Cover</DIV></DIV><DIV class="figure_caption caption_center"> The Luciferase Imaging setup </DIV></DIV></DIV><DIV class="sectionh2">Implementation
    </DIV><DIV class="text"><DIV class="subtitel">Imaging Chip and Camera</DIV>
      In order to read out such a low intensity signal, it is crucial to use a very sensitive imaging chip. In first experiments we were using the standard <A href="https://www.raspberrypi.org/documentation/hardware/camera/">Raspberry Pi Camera
        module v2</A> which is based on the Sony IMX219 sensor. However with this chip it was not possible to resolve the luminescence signal. Therefore we decided to switch to the <A href="http://www.arducam.com/camera-modules/10mp-mt9j001mt9j003/">MT9J001</A>
      camera module which is based on the On-Semi MT9J001 monochrome raw sensor and provides a low-noise CMOS imaging technology that achieves near CCD quality in terms of sensitivity and
      signal to noise ratio. We hera have a SNR of 34dB vs 36dB of the RaspberryPi Camera Sensor. Currently this chip is rather designed for developers use, that’s why we needed to implement the integration into
      our software pipeline on our own. (see <A href="https://2018.igem.org/Team:ETH_Zurich/Software">Software Overview</A>)
    </DIV><DIV class="text"><DIV class="subtitel">Experiments</DIV>
      During multiple testing runs we verified our hardware as well as the corresponding software readout (see <A href="https://2018.igem.org/Team:ETH_Zurich/Software">Software Overview</A>). In all our experiments, the goal was to detect a luminescence signal generated by the enzymatic conversion of luciferin to oxyluciferin by the firefly luciferase. Since we expected the signal level to be rather low, all of the experiments included many negative controls. Furthermore, in the initial testing phase  plate reader measurements were conducted in parallel to verify our own measurement data.
In the graph below, we present the result of a series of measurements taken with our own device. The x-axis, depicts the different samples, while the y-axis shows the intensity of the luminescence signal measured by our device. The figure clearly shows that we can resolve the luminescence signal, as only the samples that are supposed to emit photons (i.e. induced cells in buffer with luciferase, 1:1 induced cells together with uninduced cells, 1:3 induced cells together with uninduced cells and notably also uninduced cells in buffer with luciferase) lead to a signal of 0.2 or above. The fact that also the uninduced cells in the buffer with luciferase create a signal can be explained by the effect of leaky protein expression. 
All of the negative controls led to a signal around zero. This variation in the signal is solely due to noise (e.g. the thermal noise of the sensor which varies over time). 
On the whole, this figure shows that we can clearly resolve and detect the luminescence signal. We further verified our design through repeated executions of this kind of experiment which always led to similar results. 
We were very satisfied with the results achieved by our low-cost device as we are able to reliably detect the luminescence signal generated by induced E. coli and can even detect the signal generated by uninduced cells through leakage. 
    </DIV><DIV class="container_figure" id="fig5"><DIV class="figure_caption caption_center">
        Data generated with our own luminescence soft- and hardware. The sample was always a drop of 40uL and in all measurements with cells, a constant OD of 0.4 was ensured.
      </DIV></DIV><DIV class="text"><DIV class="subtitel">Results</DIV>
      We were very satisfied with the results achieved by our low-cost device as we are able to reliably detect the luminescence signal generated by induced E. coli and can even detect the signal generated by uninduced cells through leakage.
    </DIV><DIV class="text"><DIV class="subtitel">References</DIV></DIV><DIV class="references"><UL><LI>
          Kim, H., Jung, Y., Doh, I. J., Lozano-Mahecha, R. A., Applegate, B., &amp; Bae, E. (2017). Smartphone-based low light detection for bioluminescence application. Scientific Reports, 7(June 2016), 1–11. https://doi.org/10.1038/srep40203
        </LI><LI>
          https://www.onsemi.com/pub/Collateral/MT9J003-D.PDF
        </LI></UL></DIV><DIV id="modular_mic_id" class="sectionh1 contentTable contentModular" contenttable="Modular Casing System" contentref=".contentModular">Modular Casing System</DIV><DIV class="sectionh2">Introduction
    </DIV><DIV class="text clearfix"><DIV class="textpicture-right textpicture20"><DIV class="figure_caption caption_left">Overview of the LCCSM</DIV></DIV>
      We designed one single casing system suitable for all of our imaging approaches. This platform can be used by everyone to built their own microscope in a very modular way and to also further expand it. We used it to do brightfield imaging, lensless imaging, luminescence detection as well as fluorescence imaging. 
The original idea was to create an enclosure to reduce spill light. This evolved into a system that allows to build a whole microscope with the 3D printed parts and additional components (e.g. a camera chip, LED lightsource, lenses, pinholes, depending on the requirements). The system is based on a click mechanism making it extrememly easy to assemble and disassemble.
    </DIV><DIV class="sectionh2">The Parts</DIV><DIV class="container-robotpart"><DIV class="robotpart"><DIV class="robotpart-description"><SPAN class="robotpart-header">The main component</SPAN>
          This is essentially a box with a hole in the top and the bottom. Where the hole sits we created an angled border, where the next box can be clicked in from the top. These boxes vary in height and enclose the microscope. This box connector is present on all parts, making it extremely flexible to connect all of them together.
        </DIV></DIV><DIV class="robotpart"><DIV class="robotpart-description"><SPAN class="robotpart-header">The base</SPAN>
          Here we mount the sensor. We created custom mounts for the Raspberry Pi camera and the arducam. It also acts as a stand or a mount to the robot.
        </DIV></DIV><DIV class="robotpart"><DIV class="robotpart-description"><SPAN class="robotpart-header">The sample holder</SPAN>
          This is where one introduces the sample into the microscope. We created a sliding drawer that can be used to push the sample into the imaging chamber. It is completely enclosed, so it does not let any spill light in.
        </DIV></DIV><DIV class="robotpart"><DIV class="robotpart-description"><SPAN class="robotpart-header">The microfluidic chip holder</SPAN>
          For the microfluidic chip we custom-built a case that allows to slide the chip horizontally enabling to image the different channels of the microfluidic chip. It also holds the microfluidic chip tightly in place and is fully enclosed.
        </DIV></DIV><DIV class="robotpart"><DIV class="robotpart-description"><SPAN class="robotpart-header">The Lens or Pinhole or Filter mount</SPAN>
          In order to mount pinholes, filters or lenses we created segments with a small hole in the middle. This allows the part to be mounted in the middle. Additionally we add small screws to each of the four sides to be able to tighten the part in the middle and position it to our desire.

        </DIV></DIV><DIV class="robotpart"><DIV class="robotpart-description"><SPAN class="robotpart-header">The Thorlabs mount
          </SPAN>
          As we decided to use a 10x magnification lens setup for our brightfield approach we realised it would be difficult to adjust the distances between the lenses, the chip and the sample precisely without having rods that the parts are sliding on. This is why we decided to integrate the Thorlabs rod system into our modular microscope setup. By making them fit tightly inside our 3D printed part we can adjust the height of each lens very precisely and individually. This part also allows to add other Thorlabs components in the microscopy setup such as for instance filters for fluorescence imaging.
        </DIV></DIV><DIV class="robotpart"><DIV class="robotpart-description"><SPAN class="robotpart-header">The Light mount</SPAN>
          At the very top of the microscope one often has a light source. We created a variety of different mounts that allow to place differently sized laser diodes (for the lensless system) or LEDs on top of our microscope.
        </DIV></DIV></DIV><DIV class="text"><DIV class="subtitel">Conclusion</DIV>  The common, very simple clicking mechanism makes every part completely modular. This allows great flexibility and the design of complex setups by combining the simple parts. As the system already went through numerous iterations it is optimized to include all necessary functionality. It has proven to be extremely useful in the process of iterating through different setups and we would not have been able to implement all of these approaches without the LCCSM system in such a small amount of time.  To enable everyone to make use of it we provide further instructions and downloads to the 3D files at the link below: </DIV><DIV class="download-button"><A href="https://2018.igem.org/Team:ETH_Zurich/Download" target="_blank"><SPAN>Download CAD files and instructions</SPAN></A></DIV></DIV><DIV class="mobileMenuBg"><FOOTER><DIV class="sponsor-title">Sponsors</DIV><DIV class="multimedia-title">Contact Us</DIV></FOOTER></DIV></DIV></DIV></DIV></DIV></DIV></BODY></HTML>