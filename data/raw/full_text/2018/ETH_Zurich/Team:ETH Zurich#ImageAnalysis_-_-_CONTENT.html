<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_ETH_Zurich_ImageAnalysis skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:ETH Zurich/ImageAnalysis</SPAN></H1></DIV><DIV id="HQ_page"><DIV id="bodyContent"><DIV id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><DIV class="container-nav-menu"><DIV class="nav-menu"><DIV class="nav-menu-left "><DIV class="nav-item" id="nav-item1"><SPAN>Project</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Description">Description</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Applied_Design">Applied Design</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Team">Team Members</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Attributions">Attributions</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Sponsoring">Sponsoring</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Notebook">Notebook</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Safety">Safety</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Download">Downloads</A></LI></UL></DIV><DIV class="nav-item" id="nav-item2"><SPAN>Wet Lab</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Tar">Tar Receptor Evolution</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ApproachA">Approach A</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ApproachB">Approach B</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Experiments">Experiments</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/InterLab">InterLab</A></LI></UL></DIV><DIV class="nav-item" id="nav-item3"><SPAN>Hardware</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Hardware">Hardware Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Microscope">Microscope</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Mechanics">Mechanics</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/SyringePump">Syringe Pump</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/MicrofluidicChip">Microfluidic Chip</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/bubbling">Bubbling</A></LI></UL></DIV><DIV class="nav-item" id="nav-item4"><SPAN>Software</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Software">Software Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Motility_Readout">Motility Readout</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ImageAnalysis">Luminescence Algorithm</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/RobotControls">Robot Controls</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Path_Planning">Path Planning</A></LI></UL></DIV></DIV><DIV class="nav-menu-middle "><DIV class="nav-item" id="home"><A href="https://2018.igem.org/Team:ETH_Zurich"><TITLE id="title6">Logo Website</TITLE></A></DIV></DIV><DIV class="nav-menu-right "><DIV class="nav-item" id="nav-item5"><SPAN>Model</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Model">Model Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/integratedModel">Integrated Models</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/motilityModel">Motility Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/splitModel">Split Luciferase Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/diffusionModel">Diffusion Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/bubbelingModel">Bubbling Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/HolographicModel">Holographic Imaging Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Screening">Screening Assay Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Parameter">Model Parameters</A></LI></UL></DIV><DIV class="nav-item" id="nav-item6"><SPAN>Human Practices</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Human_Practices">Human Practices</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Public_Engagement">Education &amp; Engagement</A></LI></UL></DIV><DIV class="nav-item" id="nav-item7"><SPAN>Achievements</SPAN><UL class="submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Results">Results</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Parts">Parts Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Demonstrate">Demonstrate</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Collaborations">Collaborations</A></LI></UL></DIV></DIV></DIV><DIV class="container-content"><DIV id="tongue1" class="content-tongue"><DIV class="tongue-div" id="tongue-div1">Content</DIV></DIV><DIV class="content-text"><SPAN href="section-Introduction" class="content-item">Introduction</SPAN><SPAN href="container_table" class="content-item">Table</SPAN></DIV></DIV></DIV><DIV class="main-menu"><A href="https://2018.igem.org/Team:ETH_Zurich"><DIV class="home">
        Home
      </DIV></A><DIV class="main-titel"><A href="https://2018.igem.org/Team:ETH_Zurich">
        A<SPAN>.</SPAN>R<SPAN>.</SPAN>O<SPAN>.</SPAN>M<SPAN>.</SPAN>A<SPAN class="main-letterSpacing">.</SPAN></A></DIV><A href="https://2018.igem.org/Team:ETH_Zurich"><DIV class="menu-logo"><TITLE id="title6">Logo Website</TITLE></DIV></A></DIV><DIV class="main-submenu"><DIV class="alt-main-submenu-item" id="alt-nav-item1" href="#project"><SPAN>Project</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Description">Description</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Applied_Design">Applied Design</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Team">Team Members</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Attributions">Attributions</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Sponsoring">Sponsoring</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Notebook">Notebook</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Safety">Safety</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Download">Downloads</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item2" href="#parts"><SPAN>Wet Lab</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Tar">Tar Receptor Evolution</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ApproachA">Approach A</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ApproachB">Approach B</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Experiments">Experiments</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/InterLab">InterLab</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item3" href="#modelling"><SPAN>Hardware</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Hardware">Hardware Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Microscope">Microscope</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Mechanics">Mechanics</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/SyringePump">Syringe Pump</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/MicrofluidicChip">Microfluidic Chip</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/bubbling">Bubbling</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item4"><SPAN>Software</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Software">Software Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Motility_Readout">Motility Readout</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/ImageAnalysis">Luminescence Algorithm</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/RobotControls">Robot Controls</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Path_Planning">Path Planning</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item5"><SPAN>Model</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Model">Model Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/integratedModel">Integrated Models</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/motilityModel">Motility Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/splitModel">Split Luciferase Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/diffusionModel">Diffusion Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/bubbelingModel">Bubbling Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Screening">Screening Assay Model</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/HolographicModel">Holographic Imaging Model</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item6"><SPAN>Human Practices</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Human_Practices">Human Practices</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Public_Engagement">Education &amp; Engagement</A></LI></UL></DIV><DIV class="alt-main-submenu-item" id="alt-nav-item7"><SPAN>Achievements</SPAN><UL class="alt-submenu"><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Results">Results</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Parts">Parts Overview</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Demonstrate">Demonstrate</A></LI><LI><A href="https://2018.igem.org/Team:ETH_Zurich/Collaborations">Collaborations</A></LI></UL></DIV></DIV><DIV class="mobileMenuBg" style="visibility: hidden"><DIV class="container-titel"><DIV class="titel" id="titel">
        Luminescence
        Algorithm<SPAN>.</SPAN></DIV><DIV class="scroll">Scroll</DIV></DIV><DIV class="sectionh1  contentTable contentIntro" contenttable="Introduction" contentref=".contentIntro">Introduction</DIV><DIV class="text">
      The goal of the luminescence readout algorithm is to detect very low levels of light intensity. As already described in the Hardware section we therefore first had to get a more sensitive image sensor. Overall, when looking at the pictures
      with a human eye, no difference between imaging no sample and luminescence sample is visible as it is shown below.
    </DIV><DIV class="container_figure"><DIV class="figures_container"><DIV class="figure"><DIV class="subfigure_caption">Raw picture of imaging an induced sample, actually emitting photons.</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">Raw picture of an empty sample. No photons are emitted.</DIV></DIV></DIV><DIV class="figure_caption caption_center">Raw imaging pictures which are the input to our luminescence detection algorithm.</DIV></DIV><DIV class="sectionh2">Idea</DIV><DIV class="text">
      Due to this results it was very clear from the beginning that the signal is very weak. Therefore an analysis of the picture on the pixel level was absolutely necessary. As we were already expecting the signal to be quite close to the noise
      level, we thought of analysing the entire image, hoping that the random noise from picture to picture will roughly cancel out and the overall noise level will stay constant.
      
      Furthermore, before being able to start the image analysis, we had to work on the camera in order to tune it towards a maximum exposure time (in the end about 5 seconds). Furthermore we put the camera’s analog gain to a maximum such that when
      any electrons are generated by photons, they will be amplified and hopefully their signal will be stronger than the noise level.
    </DIV><DIV class="sectionh2">Algorithmic Approach</DIV><DIV class="text">

      The first step of our algorithm is to actually average each pixel value for 5 consecutive images. This step is done in order to reduce the amount of random noise in each pixel.

      In a second step we analyse this average of the 5 pictures from step one further. As already described in the introduction, from the very beginning we thought of analysing the overall pictures as we expected this to be far more robust against
      noise. (Indeed, later experiments showed that it is almost impossible to detect that there is a luminescence signal when analysing the pixels individually). As every individual pixel can take a value in between 0 and 255, we performed a
      binning i.e. we counted how many values have one and the same value. This binning idea is illustrated below.
    </DIV><DIV class="container_figure"><DIV class="figure_caption caption_center">Illustration of the binning of the picture.</DIV></DIV><DIV class="text">
      The result of the binning of an averaged initial image (i.e. an averaged image when there is no sample inside the imaging chamber) is shown below together with the exemplary sampling of an induced image. It is clearly visible that most of the
      pixels have a pretty low value in between roughly 0 and 20 and that also there is not an obvious difference in between those two disctributions.

    </DIV><DIV class="container_figure"><DIV class="figures_container"><DIV class="figure"><DIV class="subfigure_caption">Resulting distribution of binning the averaged pictures taken from an empty sample</DIV></DIV><DIV class="figure"><DIV class="subfigure_caption">Resulting distribution of binning the averaged pictures taken from an induced sample</DIV></DIV></DIV><DIV class="figure_caption caption_center">Resulting distributions of the binning.</DIV></DIV><DIV class="text">
      Nevertheless, if you substract the distributions from one another and only look at the region of interest around 15 one arrives at the figure shown below. Substracting the initial image (i.e. when there is nothing inside the imaging chamber) basically
      means that we eliminate the background noise which comes for instance from the outside temperature)
    </DIV><DIV class="container_figure"><DIV class="figure_caption caption_center">Result of substracting the two distibutions shown in Figure 3.</DIV></DIV><DIV class="text">
      One can clearly see from the figure above that the difference is not a lot but is still a significant. Also when repeating this kind of experiment one will arrive at the same result
      which goes in line with the intuition that the image of the induced sample should have more pixels at higher values than the reference one where there is no sample/signal. To lastly transform this figure into a score, the initial idea was to take the
      integral over the absolute value of the shown distribution and normalise it to get an intensity value. However, we found an even better solution: When simply multiplying all the number of pixel values in the interval [0,8] with -1 and in the
      interval [9,20] with +1 this will yield to a better signal as this reduces the accumulation of random noise in comparison with taking the absolute value.
      
      The final output of the algorithm in a proper luminescence imaging session is shown in the figure below.
    </DIV><DIV class="container_figure"><DIV class="figure_caption caption_center">Output of the final luminescence detection algorithm.</DIV></DIV><DIV class="sectionh1   contentTable contentResult" contenttable="Results" contentref=".contentResult">Result</DIV><DIV class="text">
      Therefore as already shown in the hardware section, together, our hardware and this algorithm are able to reliably resolve the luminescence signal. The sample consisted always of a volume of 40uL at a constant OD.
      We also did a significance analysis later on in order to ensure that the luminescence signal is significantly different from the signal when no samples are present. When performing a two sided significance test, the p-value is way smaller than
      1% for all of the samples with induced cells. Therefore it is very unlikely that noise led to the outcome of our luminescence detection algorithm as such a p-value basically says that the two distributions which were compared in the test differ significantly.
    </DIV><DIV class="container_figure"><DIV class="figure_caption caption_center">Result of the significance analysis.</DIV></DIV><DIV class="sectionh1    contentTable contentConclusion" contenttable="Conclusion" contentref=".contentConclusion">Conclusion
    </DIV><DIV class="text">
      Overall, our algorithm together with the hardware is capable of detecting this luminescence signal as shown above. Obviously, there is still some room for improvements both, on the hardware as well as software side, however the presented
      solution served our purposes during the project.

    </DIV></DIV><DIV class="mobileMenuBg"><FOOTER><DIV class="sponsor-title">Sponsors</DIV><DIV class="multimedia-title">Contact Us</DIV></FOOTER></DIV></DIV></DIV></DIV></DIV></DIV></BODY></HTML>