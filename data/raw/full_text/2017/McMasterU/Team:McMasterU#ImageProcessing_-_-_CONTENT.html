<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_McMasterU_ImageProcessing skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:McMasterU/ImageProcessing</SPAN></H1></DIV><DIV id="HQ_page"><DIV id="bodyContent"><DIV id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><DIV id="mainContainer"><DIV id="menuContainer" align="center"><UL><LI><A href="https://2017.igem.org/Team:McMasterU">HOME</A></LI><LI><A href="#">WET LAB
            					</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/Description">Project Description</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/DNAzyme">DNAzyme Plate Experiment</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/CDifficile">C. Difficile Project</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/InterLab">InterLab</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/Demonstrate">Results</A></LI></UL><LI><A href="#">DRY LAB
            					</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/ImageProcessing">Image Processing</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/Model">Enzyme Model</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/Genetic">SELEX Optimization with Machine Learning</A></LI><LI><A href="#">HUMAN PRACTICES
            					</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/HP/Silver">Silver Medal</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/HP/Gold_Integrated">Integrated Human Practices</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/Engagement">Public Engagement</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/Collaboration">Collaboration</A></LI><LI><A href="#">TEAM
            					</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/Team">Members</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/Sponsors">Sponsors</A></LI><LI><A href="https://2017.igem.org/Team:McMasterU/Attributions">Attributions</A></LI></DIV><DIV id="contentContainer"><DIV class="band"><H1>Image Processing</H1><P>We set out to create a program that would identify and measure fluorescence in petri dishes from photographs. A problem that the wet lab had encountered was that the fluorescence measured would include auto-fluorescence of the bacteria, which is a systematic bias. Through computer analysis and processing, we endeavoured to eliminate auto-fluorescence from images and quantify the size and intensity for areas of fluorescence.</P><H2> Subtracting Images </H2><P>Our first program successfully converted images to an array of pixel values in greyscale, and subtracted one image from another. We aimed to have the first image of just bacteria auto-fluorescence subtracted from the image taken of bacteria fluorescence under stimulus, to yield an image of bacteria fluorescence without auto-fluorescence.</P><P>This did not yield accurate results, as it was difficult to align the two images with perfect positioning of the petri dish. As well, the bacteria auto-fluoresced differently at different time points, yielding different fluorescing patters when the two photos were taken.</P><H2> Identify Everything, Then Filter </H2><P>Our next strategies focused on different ways of identifying individual objects within an image, and then having human intervention decide which parts are auto-fluorescing and which are not. As there was contention between group members on whether a spot constituted as measured fluorescence or auto-fluorescence, we decided this would be the most reasonable way rather than constructing an algorithm and determined auto-fluorescence.</P><H4> 1)	Labeling via intensity differences: Recursively </H4><P>For every pixel that was within a certain intensity difference than a neighbour, changed value to the same discrete value as neighbour. End result should be areas of discrete values in the image. We ultimately could not overcome runtime errors. </P><H4> 2)	Labeling via intensity differences: Bubble sort style </H4><P>Same end goal, but instead of recursion the program passes through the entire picture’s array of pixels in a loop until no new changes are made. End result was either too specific to noise or too vague that it misjudged shapes. Could not determine ideal intensity threshold. </P><H4> 3)	OpenCV Canny Edge Detection </H4><P>After manipulating the image via Gaussian blurring and changing intensity thresholds, we were able to fairly accurately identify significant objects in everyday photos, but there was simply too much noise in the petri dish photos. As well, markings on the petri dish blocked/interfered with patches of fluorescence so we could not achieve accurate measurements.</P><H2>  Neural Networks </H2><P>We ventured into image identification with neural networks in hopes that the “black box” logistics within neural networks could overcome our blind spots in how to specifically identify auto-fluorescence. We were able to replicate a neural network program that used the MNIST handwriting dataset as training data to predict handwritten numbers. However, we were unable to adapt this network for identification of fluorescence patches. We could not delineate the prediction to give an accurate representation of a patch, and the program was not receptive to our training data.  As well, we also suspected that we could not produce enough training data for the program to be able to make accurate predictions. </P><H2> Future Steps </H2><P>We hope that combining a curated dataset from our OpenCV results that we approved would be sufficient training data for the neural network. There is still a lot of troubleshooting and learning to be done on machine learning to make our neural network function as per our expectations. </P></DIV><DIV class="band"><NAV id="menu" align="center"><H4>Follow Us</H4><H5>© 2017 mGEM</H5></NAV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></BODY></HTML>