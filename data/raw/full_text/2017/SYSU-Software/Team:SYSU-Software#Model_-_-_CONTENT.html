<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_SYSU-Software_Model skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:SYSU-Software/Model</SPAN></H1></DIV><DIV id="HQ_page"><DIV id="bodyContent"><DIV id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><P><TITLE>Page Title</TITLE></P><DIV id="truePage" class="realPage"><DIV id="firstnav" class="ui fixed collapsed borderless ten menu"><DIV class="ui simple dropdown item page-nav"><A href="https://2017.igem.org/Team:SYSU-Software/Project" class="page-link">Project</A><DIV class="menu page-category"><A href="https://2017.igem.org/Team:SYSU-Software/Project#description" class="item">Description</A><A href="https://2017.igem.org/Team:SYSU-Software/Project#applied-design" class="item">Applied Design</A><A href="https://2017.igem.org/Team:SYSU-Software/Project#wet-lab" class="item">Wet-Lab Validation</A><A href="https://2017.igem.org/Team:SYSU-Software/Project#demonstrate" class="item">Demonstrate</A></DIV></DIV><DIV class="ui simple dropdown item page-nav" id="active-page"><A href="https://2017.igem.org/Team:SYSU-Software/Model" class="page-link">Modeling</A><DIV class="menu page-category"><A href="https://2017.igem.org/Team:SYSU-Software/Model#overview" class="item">Overview</A><A href="https://2017.igem.org/Team:SYSU-Software/Model#recommendation-system" class="item">Recommendation System</A><A href="https://2017.igem.org/Team:SYSU-Software/Model#simulation" class="item">Simulation for General Genetic Circuits</A><A href="https://2017.igem.org/Team:SYSU-Software/Model#references" class="item">References</A></DIV></DIV><DIV class="ui simple dropdown item page-nav"><A href="https://2017.igem.org/wiki/index.php?title=Team:SYSU-Software/HP" class="page-link">Human Practices</A><DIV class="menu page-category"><A href="https://2017.igem.org/wiki/index.php?title=Team:SYSU-Software/HP#overview_id" class="item">Overview</A><A href="https://2017.igem.org/wiki/index.php?title=Team:SYSU-Software/HP#silver" class="item">Silver</A><A href="https://2017.igem.org/wiki/index.php?title=Team:SYSU-Software/HP#gold" class="item">Gold</A><A href="https://2017.igem.org/wiki/index.php?title=Team:SYSU-Software/HP#integrated-human-practice" class="item">Integrated Human Practice</A><A href="https://2017.igem.org/wiki/index.php?title=Team:SYSU-Software/HP#public-engagement" class="item">Public Engagement</A></DIV></DIV><DIV class="ui simple dropdown item page-nav"><A href="https://2017.igem.org/Team:SYSU-Software/Collaborations" class="page-link">Collaborations</A><DIV class="menu page-category"><A href="https://2017.igem.org/Team:SYSU-Software/Collaborations#overview" class="item">Overview</A><A href="https://2017.igem.org/Team:SYSU-Software/Collaborations#scut-china-a" class="item">SCUT-CHINA-A</A><A href="https://2017.igem.org/Team:SYSU-Software/Collaborations#nju-china" class="item">NJU-China</A><A href="https://2017.igem.org/Team:SYSU-Software/Collaborations#hkust" class="item">Hong_Kong_HKUST</A><A href="https://2017.igem.org/Team:SYSU-Software/Collaborations#sysu-china" class="item">SYSU-CHINA</A><A href="https://2017.igem.org/Team:SYSU-Software/Collaborations#scau-china" class="item">SCAU-CHINA</A></DIV></DIV><DIV class="ui simple dropdown item page-nav"><A href="https://2017.igem.org/Team:SYSU-Software/InterLab" class="page-link">Interlab</A><DIV class="menu page-category"><A href="https://2017.igem.org/Team:SYSU-Software/InterLab#overview" class="item">Overview</A><A href="https://2017.igem.org/Team:SYSU-Software/InterLab#experiment-design" class="item">Experiment Design</A><A href="https://2017.igem.org/Team:SYSU-Software/InterLab#material-and-methods" class="item">Material and Methods</A><A href="https://2017.igem.org/Team:SYSU-Software/InterLab#results" class="item">Results</A></DIV></DIV><DIV class="ui simple dropdown item page-nav"><A href="https://2017.igem.org/Team:SYSU-Software/Safety" class="page-link">Safety</A><DIV class="menu page-category"><A href="https://2017.igem.org/Team:SYSU-Software/Safety#dry-lab" class="item">Biosafety in Dry Lab</A><A href="https://2017.igem.org/Team:SYSU-Software/Safety#wet-lab" class="item">Biosafety in Wet Lab</A></DIV></DIV><DIV class="ui simple dropdown item page-nav"><A href="https://2017.igem.org/Team:SYSU-Software/Attributions" class="page-link">Attributions</A><DIV class="menu page-category"><A href="https://2017.igem.org/Team:SYSU-Software/Attributions#overview" class="item">Overview</A><A href="https://2017.igem.org/Team:SYSU-Software/Attributions#group-structure" class="item">Group Structure</A><A href="https://2017.igem.org/Team:SYSU-Software/Attributions#attribution-in-project" class="item">Attribution in Project</A><A href="https://2017.igem.org/Team:SYSU-Software/Attributions#journey-planning" class="item">Journey Planning and Financing</A><A href="https://2017.igem.org/Team:SYSU-Software/Attributions#acknowledgements" class="item">Acknowledgements</A></DIV></DIV><DIV class="ui simple dropdown item page-nav"><A href="https://2017.igem.org/Team:SYSU-Software/Team" class="page-link">Team</A><DIV class="menu page-category"><A href="https://2017.igem.org/Team:SYSU-Software/Team#biology-group" class="item">Biology Group</A><A href="https://2017.igem.org/Team:SYSU-Software/Team#programmers" class="item">Programmers</A><A href="https://2017.igem.org/Team:SYSU-Software/Team#modeling-group" class="item">Modeling Group</A><A href="https://2017.igem.org/Team:SYSU-Software/Team#designers" class="item">Designers</A><A href="https://2017.igem.org/Team:SYSU-Software/Team#advisors" class="item">Advisors</A><A href="https://2017.igem.org/Team:SYSU-Software/Team#instructors" class="item">Instructors</A><A href="https://2017.igem.org/Team:SYSU-Software/Team#notebook" class="item">Notebook</A></DIV></DIV><DIV class="ui simple dropdown item page-nav"><A href="https://2017.igem.org/Team:SYSU-Software/Medal" class="page-link">Medal</A><DIV class="menu page-category"><A href="https://2017.igem.org/Team:SYSU-Software/Medal#overview" class="item">Overview</A><A href="https://2017.igem.org/Team:SYSU-Software/Medal#bronze" class="item">Bronze</A><A href="https://2017.igem.org/Team:SYSU-Software/Medal#silver" class="item">Silver</A><A href="https://2017.igem.org/Team:SYSU-Software/Medal#gold" class="item">Gold</A></DIV></DIV><DIV class="ui simple dropdown item page-nav"><A href="https://2017.igem.org/Team:SYSU-Software/Statements" class="page-link">Statements</A><DIV class="menu page-category"><A href="https://2017.igem.org/Team:SYSU-Software/Statements#term-of-use" class="item">Term of Use</A><A href="https://2017.igem.org/Team:SYSU-Software/Statements#bio-safety-alerts" class="item">Bio Safety Alerts</A><A href="https://2017.igem.org/Team:SYSU-Software/Statements#privacy-policy" class="item">Privacy Policy</A><A href="https://2017.igem.org/Team:SYSU-Software/Statements#cookie-policy" class="item">Cookie Policy</A></DIV></DIV></DIV><DIV id="first-page"><H1 id="top-title">Model</H1><H2 id="slogan">Synbio is just a S-Din away!</H2><H3 id="sysu-software-2017">SYSU-Software 2017</H3><DIV class="page-content"><H2 id="overview">Overview</H2><DIV class="overview"><P>What makes S-Din work are the clever algorithms behind it. Our modelling team uses many techniques e.g. Machine Learning, ODE to develop the Recommendation System and the Simulation System which help S-Din achieve state of the art performance. </P></DIV></DIV></DIV><DIV class="modeling"><SECTION class="plain"><H2 id="recommendation-system">Recommendation System</H2><H3>Introduction</H3><DIV class="paragraph"><P>The users of our software are all innovative researchers on Synthetic Biology, who are interested in many different biological fields. The purpose of our system is to recommend most related genetic parts to the users based on the research interest the users offer to our system.</P><P>The information that we use to make recommendation is a database built by NLP and Random Walk which contains scores between each key word and each genetic part. Formally, it is a <CODE>n * m</CODE> matrix <CODE>A</CODE>, where <CODE>n</CODE> is the number of key words and <CODE>m</CODE> is the number of parts. The element at row <CODE>i</CODE>, column <CODE>j</CODE> is the score between the <CODE>i</CODE>th keyword and <CODE>j</CODE>th genetic part, which reflects the connection between them(higher score means higher connection).</P><P>The overall strategy of our system is Collaborative Filtering , i.e. we first search the similar key words in our database of the unknown word offered by users and then recommend the genetic parts which are highly related to key words that we found to the users.</P><P>A natural question is how to find the most similar key words in our dataset of a given unknown word in an accurate and efficient way? Here is our general solution : To quantify the semantic similarities between words accurately ,we use technique in Deep Learning to convert words into numerical vectors and the cosine similarities between each vectors can represents the semantic similarities between words. To search the similar key words efficiently, we use the KD Tree Algorithm, a fast algorithm based on binary tree, to implement the K Nearest Neighbors strategy.</P></DIV><H3>Models used in the system</H3><H4>Word2Vec Algorithm</H4><DIV class="paragraph"><P>Word2vec is an algorithm that produces word embedding , i.e. it converts a corpus of text into a high dimensional real vector space(in our case , the dimension is 400) and each word in the corpus is assigned to a vector in the vector space. If two words are similar semantically , then they will be close under cosine distance measure.</P><P>In our Recommendation System, we use gensim, an open source Python module focused on Natural Language Processing , to train our word2vec model and the corpus we use to feed the model is wikimedia, which can be downloaded from:<A href="https://dumps.wikimedia.org/" target="_blank">https://dumps.wikimedia.org/</A></P><P>The reason why we use Word2vec is that it can distinguish the semantic meanings of words accurately by Deep Learning technique, which outperforms the traditional semantic analysis methods greatly.</P></DIV><H4>KD Tree Algorithm</H4><DIV class="paragraph"><P>The KD Tree algorithm is rather efficient when searching for the most similar items with averaged time complexity<CODE>O(log(n))</CODE>,thus the users can get recommendation instantly after they enter their interested new word to our system.</P><P>The KD Tree Algorithm consists of the following two parts:</P><OL><LI>Construct KD Tree based on the normalized word vectors of the key words in the database which we previously mentioned. (Offline)</LI><LI>When the user enter a new word , we search the similar key words along the KD Tree that we constructed in step 1) . (Online)</LI></OL><P>Note that KD Tree Algorithm is based on Euclidean distance measure , while in our case , we need to calculate the cosine distance of the word vectors. To solve this problem ,we normalize all the word vectors of key words before constructing KD Tree and normalize the word vector of new words offered by users before letting it travel along the constructed KD Tree. The reason behind the method is that by Law of Cosines:
          $$|x_1-x_2|=\sqrt{x_1^2+x_2^2-2|x_1||x_2|\cos(x_1,x_2)}\,,\,\,x_1,x_2\in R^n$$
          </P><P>while since <CODE>x<SUP>1</SUP>,x<SUP>2</SUP></CODE> are normalized, we have :
          $$|x_1-x_2| = \sqrt{1+1-2\cos(x_1,x_2)}\,,\,\,x_1,x_2\in R^n, |x_1|=|x_2|=1$$
          </P><P>Now we see that the calculation of cosine distance between normalized vectors can be replaced by the calculation of Euclidean distance since they can determine each other in this normalization context.</P><P>In our Recommendation System , we use the KD Tree implementation in scikit-learn , a simple and efficient open source machine learning module in Python. For more details of KD Tree algorithm, see: <A href=" https://en.wikipedia.org/wiki/K-d_tree" target="_blank">wiki page of K-D Tree</A></P></DIV><H4>Random Walk with Restart Algorithm</H4><P>Random Walk with Restart(RWR) is an algorithm adapted from the PageRank algorithm and it focuses on characterizing the affiliation between each item. We treat the relation between key words and genetic parts as an undirected graph where nodes represent key words or parts and edges represent connection between words and parts. Imagine there is a walker travelling on the graph mentioned above and each time he faces two choices: 1) Randomly travelling along an edge connected to the current node. 2) Teleport to node K. After a long time of random travelling , the frequency the walker reaches each node represents the affiliation between each node and node K , which we use to characterize the relation between key words and parts. For more detailed mathematical formulation of PageRank, see: <A href="https://en.wikipedia.org/wiki/PageRank" target="_blank">wiki page of page rank</A></P><H3>Algorithms used in the Recommendation System</H3><H4>Calculating affiliation between key words and parts</H4><DIV class="paragraph"><P>We used random walk with restart to calculate the affiliation between key words and all parts in the dataset. The calculation is done by updating the probability vector iteratively ,once the probability vector is converged, it can be viewed as the affiliation between various parts and key words. Therefore, the higher the probability is, the closer the key word and part are.</P><P>Here is the Algorithm that we use in our project:</P></DIV><H5>Define Transition Matrix <CODE>M</CODE></H5><DIV class="paragraph"><P>Let <CODE>M</CODE> be the transition matrix of the graph <CODE>G</CODE> with size of <CODE>(n+m)^2</CODE>where <CODE>n</CODE> represents the number of keywords and <CODE>m</CODE> represents the number of parts. The entry in row <CODE>i</CODE> and column <CODE>j</CODE> of <CODE>M</CODE> is <CODE>1/k</CODE> if node <CODE>j</CODE> of <CODE>G</CODE> has degree <CODE>k</CODE>, and one of the adjacent node is <CODE>i</CODE>. Otherwise the entry is 0</P><P> Note that the first <CODE>n</CODE> columns(rows) represent key words and the other <CODE>m</CODE> columns(rows) represent the parts.</P></DIV><H5>Prespecify β</H5><DIV class="paragraph"><P>β is the probability that the walker continues to follow the edges connected to the current node, thus <CODE>1-β</CODE> is the probability the walker will teleport to the initial node</P></DIV><H5>Iterate over <CODE>v</CODE></H5><DIV class="paragraph"><P><CODE>for</CODE> keyword <CODE>i</CODE> in <CODE>1 to N</CODE></P><H6>Define and initialize <CODE>v</CODE></H6><P>Let <CODE>e<SUB>i</SUB></CODE> be the column vector that has 1 in the row for node <CODE>i</CODE> and 0’s elsewhere, i.e.
          $$e_{ij}=\delta_{ij}=
          \begin{cases}
          1, &amp; \text{if $i=j$} \\
          0, &amp; \text{if $i\neq j$} 
          \end{cases}$$
          </P><P>And <CODE>e<SUB>i</SUB></CODE> is the column vector such that each item reflects the probability the walker stays at each node of the graph and the initial <CODE>v</CODE> is set to be <CODE>e<SUB>i</SUB></CODE>.</P><H6>Update <CODE>v</CODE> by</H6><P>$$v'=\beta M v+(1-\beta)e_N$$</P><P>update code{v} until the terminal condition is satisfied, i.e.
          $$|v^{(t)}-v^{(t-1)}|&lt;\epsilon,\,\,\text{for sometime $t$}$$
          </P><H6>Modify <CODE>v</CODE></H6><P>Since the first n components of <CODE>v</CODE> are the affiliation between key word <CODE>i</CODE> and the other key words which we are not interested , therefore we only keep the last m components of <CODE>v</CODE>, which reflects the affiliation between key word <CODE>i</CODE> and all the parts.</P></DIV><H4>Build KD Tree of Keywords</H4><DIV class="paragraph"><P>Once the user enter a new word to our system, we need to search for similar key words efficiently , thus we build a KD Tree of key words to implement this function.</P><P>Here is our Algorithm</P></DIV><H5>Train word vector model</H5><DIV class="paragraph"><P>We feed our word vector model with Wikimedia corpus . After the training process is done, we have a model that can convert words into numerical vectors, i.e.
          $$f:\Gamma\rightarrow R^n$$
          </P><P>where Γ denoted the corpus space</P></DIV><H5>Convert keywords into normalized vectors</H5><DIV class="paragraph"><P>let <CODE>T</CODE> denotes the set of word vectors</P><P><CODE>for</CODE> keyword <CODE>i</CODE> in <CODE>1 to N</CODE>:</P><P><CODE>T</CODE>.append \( \frac{f(i)}{|f(i)|_2} \)</P></DIV><H5>Build KD Tree</H5><P>We use the standard construction procedure to build KD Tree of set <CODE>T</CODE>. Details will be ignored here. For the people who are interested , we offered a link to wikipedia in section2.</P><H4>Collaborative Filtering</H4><DIV class="paragraph"><P>This is the final step to construct our Recommendation System , overall we use collaborative filtering strategy to make prediction.</P><P>Here is the algorithm</P></DIV><H5>Transform users input</H5><P>We get users input word <CODE>k</CODE>, we then convert it into normalized word vector <CODE>v</CODE>, i.e. $$v=\frac{f(k)}{|f(k)|}$$</P><H5>Search K most similar keywords(KNN)</H5><P>Let <CODE>v</CODE> travel along the KD Tree in a way like binary search , we can end up with <CODE>K</CODE>(in our case , <CODE>K</CODE> is set to be 5) most similar key words(KNN) to the current word <CODE>k</CODE>.</P><H5>Make Recommendation</H5><DIV class="paragraph"><P>We have calculated the affiliation between key words and parts which shall be used to guide our final recommendation. Let <CODE>p<SUB>i</SUB></CODE> denotes the connection between the <CODE>i</CODE>the part and the current word <CODE>k</CODE> , we calculate <CODE>p<SUB>i</SUB></CODE> by formula $$p_i=\sum^K_{n=1}\frac{\text{Affiliation}(w_n,p_i)}{\text{distance}(w_n,k)+\text{bias}}$$
          </P><P>where \( \{w_n|n=1,2,...,K\}\) denotes the <CODE>k</CODE> most similar key words</P><P><CODE>Affiliation(w<SUB>n</SUB>, p<SUB>i</SUB>)</CODE>denotes the connection between <CODE>w<SUB>i</SUB></CODE> and the <CODE>i</CODE>th part and <CODE>distance(w<SUB>i</SUB>, k)</CODE> denotes the the Euclidean distance between the normalized word vectors of <CODE>w<SUB>n</SUB></CODE> and word <CODE>k</CODE>.</P><P>After the computation of \(\{p_i|i=1,2,...,m\}\), we use heap sort algorithm to get <CODE>R</CODE> highest <CODE>p<SUB>i</SUB></CODE> and recommend to the users the corresponding parts.Besides, we use exactly the same strategy to make recommendation of related projects to the users. For simplicity, we ignore the details here.</P></DIV></SECTION><SECTION class="plain"><H2 id="simulation">Simulation for General Genetic Circuits</H2><H3>Introduction</H3><P>The users of S-Din are all active and innovative researchers in Synthetic Biology, who come up with many interesting and new ideas in a wide range of fields. Our software helps them achieve their creative goals by allowing them to combine various genetic parts together to form brand-new genetic circuits that may never exist before. To help the researchers have a deeper understanding of how the genetic system that they created works, we construct an ODE system to simulate the dynamic behaviors of the genetic system mathematically. The main challenge of simulation is the uncertainty of genetic circuits since the users can construct them arbitrarily. Therefore, we build a rather general model capable of simulating various genetic circuits.</P><H3>Model</H3><DIV class="paragraph"><P>The interaction among the substances in genetic circuits can be characterized by a <CODE>n * n</CODE> relation matrix <CODE>R</CODE>, where <CODE>n</CODE> is number of substances. The entry in row <CODE>i</CODE> and column <CODE>j</CODE> has 3 possible values for 3 possible relations, i.e. $$
          R_{i,j}=
          \begin{cases}
          1 &amp; \text{if $i$ promotes $j$} \\
          -1 &amp; \text{if $i$ inhibits $j$} \\
          0 &amp; \text{No effect}
          \end{cases}
          $$</P><P>Therefore , the <CODE>j</CODE>th column records all the impacts the system exerts to the <CODE>j</CODE>th substances.</P><P>Let <CODE>x<SUB>j</SUB>(t)</CODE> denotes the concentration of substance <CODE>j</CODE> at time <CODE>t</CODE> , then we use the following ODE to characterize <CODE>x<SUB>j</SUB>(t)</CODE> for \(j\in\{1,2,...n\}\)
          $$ \frac{\mathbb{d}x_j(t)}{\mathbb{d}t} = \prod_{i=1}^n\{ \frac{R_{ij}(R_{ij}+1)}{2}f(x_i(t))+\frac{(R_{ij}+1)(R_{ij}-1)}{-1}+\frac{R_{ij}(R_{ij}-1)}{2}g(x_i(t))\}- \beta \times x_j(t)
          $$
          </P><P>where β represents the degradation rate and:
          $$ f(x)=1+\frac{1}{1+\mathbb{e}^{-x}}; f(x)=1-\frac{1}{1+\mathbb{e}^{-x}} $$
          </P><H3>Imlementation</H3><P>We use Scipy, an efficient open source numerical module in Python, to give the numerical solutions to the ODE system. Specifically, we use the odeint function in Scipy. For more information about odeint function, see <A href=" https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html" target="_blank">documentation of scipy</A>.</P></DIV></SECTION><SECTION class="plain" id="references"><H2>References</H2><UL><LI> Jure Leskovec, Anand Rajaraman, Jeffrey David Ullman. Mining of Massive Datasets. Second Edition, Cambridge, Nov 2014, 9781107077232.</LI><LI>Bor-Sen Chen, Yu-Chao Wang. Synthetic Gene Network: Modeling, Analysis and Robust Design Methods. First Edition, CRC press, May 2, 2014, 9781466592698.</LI></UL></SECTION></DIV><DIV id="contact"><DIV id="contact-content"><DIV class="contact-item"><DIV class="contact-heading">contact</DIV><DIV class="contact-value">sysusoftware@126.com</DIV></DIV><DIV class="contact-item"><DIV class="contact-heading">address</DIV><DIV class="contact-value">135# Xin'gang Rd(W.)Sun Yat-sen University, Guangzhou, China</DIV></DIV><DIV class="contact-item"><DIV class="contact-heading">GET IN TOUCH</DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></BODY></HTML>