<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_Heidelberg_Software_GAIA skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:Heidelberg/Software/GAIA</SPAN></H1></DIV><DIV id="HQ_page"><DIV id="bodyContent"><DIV id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><DIV class="container"><DIV class="navbar-header"><A type="button" data-canvas="body" id="sidebarCollapse" class="navbar-toggle" data-toggle="offcanvas" data-target="#sidebar" style="color: #393939;margin-top: 9px;">NAVIGATION
                    </A></DIV><DIV class="collapse navbar-collapse" id="bs-example-navbar-collapse-1"><UL class="nav navbar-nav pull-right"><LI class="dropdown"><A href="https://2017.igem.org/Team:Heidelberg/Team">People </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Team">Team</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Attributions">Attributions</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Sponsoring">Sponsoring</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/For_Judges">For Judges</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Jamboree">Giant Jamboree</A></LI></UL><LI class="dropdown"><A href="https://2017.igem.org/Team:Heidelberg/Description">Project </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Description">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Design">Background &amp; Design </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Pace">PACE</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Predcel">PREDCEL</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Results">Results Summary</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Validation">Software Validation</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Organosilicons">Organosilicons</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Protein_Interaction">Protein Interaction</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Cytochrome_Engineering">Cytochrome Engineering</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Optogenetics">Optogenetics</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/CRISPR">CRISPR Cas9</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/InterLab">InterLab Study</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Achievements">Achievements</A></LI><LI class="dropdown"><A href="https://2017.igem.org/Team:Heidelberg/Parts">Parts </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Basic_Part">Basic Parts</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Composite_Part">Composite Parts</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Improved_Part">Improved Part</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Part_Collection">Parts Collection</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Part_List">Part List</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/RFC">RFC</A></LI><LI class="dropdown"><A href="https://2017.igem.org/Team:Heidelberg/Model">Modeling </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Phage_Titer">Phage Titer</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Mutagenesis_Induction">Mutagenesis Induction</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Mutation_Rate_Estimation">Mutation Rate Estimation</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Lagoon_Contamination">Lagoon Contamination</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Medium_Consumption">Medium Consumption</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Tools">Interactive Web Tools</A></LI><LI class="dropdown"><A href="https://2017.igem.org/Team:Heidelberg/Software">Software </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software">AiGEM Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software/DeeProtein">DeeProtein</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software/GAIA">GAIA</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software/SafetyNet">SafetyNet</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software/MAWS">MAWS 2.0</A></LI><LI class="dropdown"><A href="https://2017.igem.org/Team:Heidelberg/Human_Practices">Human Practices </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Human_Practices">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/HP/Gold_Integrated">Integrated Human Practices</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Interviews">Expert Interviews</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Safety">Safety &amp; Security</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Engagement">Public Engagement</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Education">Education</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Collaborations">Collaborations</A></LI><LI class="dropdown"><A href="https://2017.igem.org/Team:Heidelberg/Notebook">Notebook </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Notebook">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Experiments">Methods</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Materials">Materials</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Database">Notebook Database</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Toolbox">Toolbox Guide</A></LI></DIV></DIV><NAV id="sidebar" style="z-index: 10001; background-color: white;border: none;box-shadow:1px 0px 0px #393939;" class="navmenu navmenu-default navmenu-fixed-left offcanvas" role="navigation"><A class="navmenu-brand" href="https://2017.igem.org/Team:Heidelberg"> iGEM TEAM HEIDELBERG 2017</A><DIV id="sidebarHide" data-toggle="offcanvas" data-target="#sidebar" style="padding-left: 20px;"><A style="font-family: 'Josefin Sans' !important; font-size: 16px; line-height: 18px; height: 18px;"> COLLAPSE NAVIGATION </A></DIV><UL class="nav navmenu-nav" id="sidenav"><LI><A data-toggle="collapse" data-target="#People_side">People </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Team">Team</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Attributions">Attributions</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Sponsoring">Sponsoring</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/For_Judges">For Judges</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Jamboree">Giant Jamboree</A></LI></UL><LI><A data-toggle="collapse" data-target="#Project_side">Project </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Description">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Design">Background &amp; Design </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Pace">PACE</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Predcel">PREDCEL</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Results">Results Summary</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Validation">Software Validation</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Organosilicons">Organosilicons</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Protein_Interaction">Protein Interaction</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Cytochrome_Engineering">Cytochrome Engineering</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Optogenetics">Optogenetics</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/CRISPR">CRISPR Cas9</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/InterLab">InterLab Study</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Achievements">Achievements</A></LI><LI><A data-toggle="collapse" data-target="#Parts_side">Parts </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Basic_Part">Basic Parts</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Composite_Part">Composite Parts</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Improved_Part">Improved Part</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Part_Collection">Parts Collection</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Parts#Part_List">Part List</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/RFC">RFC</A></LI><LI><A data-toggle="collapse" data-target="#Model_side">Modeling </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Phage_Titer">Phage Titer</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Mutagenesis_Induction">Mutagenesis Induction</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Mutation_Rate_Estimation">Mutation Rate Estimation</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Lagoon_Contamination">Lagoon Contamination</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Medium_Consumption">Medium Consumption</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Model/Tools">Interactive Web Tools</A></LI><LI><A data-toggle="collapse" data-target="#AI_side">Software </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software">AiGEM Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software/DeeProtein">DeeProtein</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software/GAIA">GAIA</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software/SafetyNet">SafetyNet</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Software/MAWS">MAWS 2.0</A></LI><LI><A data-toggle="collapse" data-target="#HP_side">Human Practices </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Human_Practices">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/HP/Gold_Integrated">Integrated Human Practices</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Interviews">Expert Interviews</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Safety">Safety &amp; Security</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Engagement">Public Engagement</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Education">Education</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Collaborations">Collaborations</A></LI><LI><A data-toggle="collapse" data-target="#Notebook_side">Notebook </A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Notebook">Overview</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Experiments">Methods</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Materials">Materials</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Database">Notebook Database</A></LI><LI><A href="https://2017.igem.org/Team:Heidelberg/Toolbox">Toolbox Guide</A></LI></NAV><DIV style="background-color: white !important; padding: 0 !important; margin: 0 !important;"><DIV class="page-title" style="background-color: white !important; border-top: 0px solid #222;"><DIV class="container" style=" padding: 0 !important;"><DIV class="col-lg-12 col-md-12 col-xs-12" style="padding-right: 0 !important; padding-bottom: 0 !important; position: relative; left: -10px;"><DIV style="border-right: 5px solid #393939; padding: 20px 20px 0px 0px"><DIV class="header-title heidelberg-turk"> 
    GAIA </DIV><DIV class="header-subtitle" style="color: #393939 !important;"> 
    Genetic artificially intelligent algorithm </DIV></DIV></DIV></DIV></DIV><DIV class="container" style="background-color: white !important; padding: 0 !important;"><DIV class="col-lg-12 col-md-12 col-xs-12" style="padding: 0 !important; margin: 0px important!;"><DIV class="container" style="position: relative; left: -10px; border-left: 5px solid #393939; border-top: 5px solid #393939; padding: 0 !important"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="text-align: justify; text-color: #393939 !important; padding: 20px 5px 0px 20px !important; font-weight: bold !important; font-family: 'Open Sans' !important">
        
Directed evolution of protein sequences is an arduous task often requiring multiple rounds of library generation and selection and the application of different surrogate objective functionalities as evolutionary stepping stones. To this day there is no universal computational tool available that is able to reduce the number of required cycles of exploration and selection, to minimize the required library complexity and increase the possible stepsize of one round of directed evolution.
Here we present GAIA (Genetic Aritficially Intelligent Algorithm) an innovative software able to fast-forward the directed evolution of protein sequences <I>in silico</I>. GAIA is a genetic algorithm responsible for sequence mutation and selection, which is interfaced with DeeProtein, a pretrained deep neural network providing functional protein sequence classification. GAIA achieves <I>in silico</I> directed evolution of proteins by iterative random amino acid substitution followed by selection via maximization of the DeeProtein classification score for the desired target functionality. By finetuning DeeProtein to the specific evolutionary task, GAIA can be optimized to facilitate virtually any functionality transfer on a given input protein sequence. Thereby, GAIA provides the required evolutionary stepping stones critical to success of directed evolution experiments by means of pure computation.
    
    </DIV></DIV><DIV style="padding-top: 50px; padding-bottom:50px;"><DIV class="heidel-form container"><DIV class="heidel-form-header col-lg-12" style="text-align: left !important;"><A href="https://github.com/igemsoftware2017/AiGEM_TeamHeidelberg2017" style="color: #000000">                 Fork us on GitHub!</A></DIV></DIV></DIV><DIV class="container"><DIV class="row"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="display: inline-block; padding-bottom: 10px; padding-top:10px;"><H2>Introduction</H2>
Directed evolution of protein sequences is a field of increasing importance. Especially with the exploitation of enzymes in the chemical and biotechnological industry, evolved enzymes, tailored to certain reactions or environments became highly sought after. Despite conventional directed protein evolution experiments are an arduous, time consuming task, consisting of multiple rounds of library generation (exploration) with subsequent selection of the fittest candidates (exploitation). Unlike for other similarly expensive experiments, to this day there is no computational tool available dedicated to the <I>a priori</I> simplification and speedup of directed evolution apporaches.
That is because from a computational perspective the task of directed evolution is more than complex: An average protein has a length of 350 Amino acid residues, considering an alphabet of 20 amino acids the combinatory options (\(20^{350}\)) exceeds the number of particles in the universe (estimated on \(10^{89}\)) by far. Thus simple brute force algorithms do not succeed here, in fact a certain knowledge, an intelligent feature selection and dimensionality reduction is crucial to focus on the profitable mutations. Handcrafted features however would be tailored to a partiular directed evolution task and thus need to be fitted and tuned before they could be applied on other directed evolution experiments. A more convenient solution could be provided by deep learning, allowing to learn the properties of the manifold of the functional sequence space. With that knowledge, the tremendous combinatory space is reduced to a processable size.

    </DIV></DIV></DIV><DIV class="container"><DIV class="row"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="display: inline-block; padding-bottom: 10px; padding-top:10px;"><H2 id="Generative">Generative Modeling</H2>
As we demonstrated with <A href="https://2017.igem.org/Team:Heidelberg/Software/DeeProtein">DeeProtein</A> we were able to learn an abstract protein representation, encoding sequence and features. Generative modeling exploits learned data distributions to sample new artificial datapoints from that distribution (figure 1). Sampling from trained representations is possible through calculation of the gradients with respect to the inputs, leaving the weights untouched. While this form of generative modelling is applied in style transfers <X-REF>Gatys2016Image</X-REF> and googles deep dream generator <X-REF>google2015deep</X-REF>, it has strong limitations as the results stringly depend on the distribution of the input. More elaborated models have been described in forms of generative adversarial networks <X-REF>goodfellow2014generative</X-REF> and variational autoencoders <X-REF>kingma2013auto</X-REF>. While these models have been applied on image <X-REF>goodfellow2014generative</X-REF> and sound <X-REF>Li2017Midi</X-REF> data, their output is often noisy, blurred and distorted. For functional protein sequence generation, noisy or distorted outputs would be fatal. Further the training of such complex models like GANs and VAEs is rather difficult and conversion in case of GANs not even guaranteed.
To circumvent these obstacles by mimicking nature's concept of evolution, we decided to implement a genetic algorithm for sequence generation and attach a deep neural network model as a scoring function to control sequence selection. For this task we exploited our learned  <A href="https://2017.igem.org/Team:Heidelberg/DeeProtein#Representation">protein representation</A> in form of a deep residual neural network.

<DIV class="col-lg-12 col-md-12 col-xs-12"><DIV class="mdl-shadow--4dp" style="padding:20px; float:left}"><DIV class="img-caption title"><STRONG><B>
      
Figure 1: The idea of generative modeling. 
    </B></STRONG></DIV><DIV class="img-caption subtitle">
      
Generative modeling exploits the learned distribution of proteins of a certain class in the protein space (left) to generate artificial samples from that distribution (right). This can be achieved by various techniques such as generative adversarial networks <X-REF>goodfellow2014generative</X-REF>, variational autoencoders <X-REF>kingma2013auto</X-REF> and simple inversion of the gradients. However the learned distribution can also be used to categorize a given, perturbated sample, returning its class probability. With its interface between deep learning model, holding the latent data representation and its genetic algorithm, GAIA performs generative modelling by perturbating an input sequence towards the distribution of the goal functionality.  
            
    </DIV></DIV></DIV></DIV></DIV></DIV><DIV class="container"><DIV class="row"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="display: inline-block; padding-bottom: 10px; padding-top:10px;"><H2>Algorithm</H2><DIV class="col-lg-12 col-md-12 col-xs-12"><DIV class="mdl-shadow--4dp" style="padding:20px; float:left}"><DIV class="img-caption title"><STRONG><B>
      
Figure 2: The architecture of the GAIA algorithm. 
    </B></STRONG></DIV><DIV class="img-caption subtitle">
      
An input sequence is passed to the algorithm and mutations are introduced, based on a user defined mutation rate, to expand sequence to a library of 100 mutation variants. Subsequently the variants are passed to the interfaced deep neural network. The obtained scores are used to compute the GAIA score of the variants and rank them. The top 5 sequences are kept and stored to rebuild the library by mutagenesis, while the rest of the library is discarded. This cycle is repeated until convergence of the GAIA score.
            
    </DIV></DIV></DIV></DIV></DIV></DIV><DIV class="container"><DIV class="row"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="display: inline-block; padding-bottom: 10px; padding-top:10px;"><H3>Genetic Component</H3>
For sequence generation we implemented a genetic algorithm, as it is inspired by the biological principle of evolution. The algorithm starts from an entry sequence, introduces mutations and scores the sequences by a deep neural network. High scoring sequences are retained and used as starting points for the next generation. Within one generation a pool of 100 amino acids is considered. To commence the input sequence is duplicated to fill the generation pool and on each copy a user defined number of initial mutations is introduced. Additionally the last highest scoring sequence is kept as reference in the pool. The mutation rate decreases with increasing generation numbers to facilitate conversion. In order to introduce a mutation, position and the introduced amino acid are determined randomly. The position to be mutated is drawn from a uniformal distribution over the sequence (either the complete sequence or a subset of interest). The new amino acid is drawn from a distribution considering the <I>E.Coli</I> codon usage to mimic the biological environment and optimize expression. This has the addidional benefit that rare amino acids, which tend to affect the DeeProtein score to greater extent due to their higher information content, do not get artificially overrepresented.
Subsequently each sequence in the generation pool is scored by the deep learning classification model for protein functionality. Depending on the classification scores a GAIA internal score (see below) is calculated, considering the goal functionality and eventual undesireable functionalities. Further a term is added accounting for the BLOSSUM62 distance between the sequence and the original entry sequence. The generation is then ranked by scores and the top 5 candidates are retained to build the next generation, all other sequences are discarded. The next generation is constructed from the retained candidates in a 50:20:20:10 ratio depending on the sequence rank. This cycle is repeated until convergence of the GAIA-scores. An overview on the GAIA algorithm is provided in figure 2.

    </DIV></DIV></DIV><DIV class="container"><DIV class="row"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="display: inline-block; padding-bottom: 10px; padding-top:10px;"><H4>GAIA-Score</H4>
The GAIA score is calculated as:
$$ S = (\sum_{g}^G g_{weight} \cdot g_{logit} - \sigma (g_{variance}) - \sum_{a}^A a_{weight} \cdot a_{logit} + \sigma (a_{variance}))
\cdot \frac{1}{\sum_{g}^G} - b_{weight} \cdot b_{score} $$
where \( G \) is the specified set of goal terms and \( A \) the specified terms to avoid.
The blossum weight is determined as:
$$ \frac{2}{11 \cdot l} $$
with sequence length \(l\) and the blossum score respectively as:
$$ \sum_{i}^l B_{62}(m_{i}, r_{i}) $$
with \(B_{62}\) is the BLOSSUM62 matrix, \(r\) the residue in the original sequence, and \(m\) the same position on the mutated sequence.

    </DIV></DIV></DIV><DIV class="container"><DIV class="row"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="display: inline-block; padding-bottom: 10px; padding-top:10px;"><H3>Deep Learning Model</H3>
As the scoring function for the genetic algorithm we apply a DeeProtein model (in its ResNet30 architecture) as described <A href="https://2017.igem.org/Team:Heidelberg/Software/DeeProtein#Architecture">here</A>. In order to better capture the sequence space of the evolutionary task we recommend to fine tune the pretrained, broad network to a more narrow sequence space. In our case we fine tuned the model applied in the <A href="https://2017.igem.org/Team:Heidelberg/Validation">validation process</A> on the narrow space of beta-glucuronidase related functions and beta-lactamase related sequences respectively. Fine tuning a pretrained model to a specific task is a common technique in deep learning is it is much easier to carry out than training a new network for the specific task from scratch. 
Furthermore it is reasonable to add additional data obtained from wet lab experiments to this fine scale training to improve classification performance and force the model to recognize the relevant positions or features in greater detail. Therefore the proposed GAIA system can be improved by this recursive engineering cycle.

    </DIV></DIV></DIV><DIV class="container"><DIV class="row"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="display: inline-block; padding-bottom: 10px; padding-top:10px;"><H2>Objectives</H2>
To verify the concept of GAIA and to demonstrate that a deep learning-driven genetic algorithm is capable of helping synthetic biologists in the context of protein engineering and directed we focused on two model proteins to evaluate key properties. 
Beta-lactamase, mediating the resistance against beta-lactame antibiotics, was selected as a model protein as its activity can easily be determined experimentally in a semi-quantitative. Of further advantage is the high number of identified sequence variants in the UniProt database. Therefore we chose it to evaluate, whether we can use GAIA to increase or decrease the activity of a given protein and to which extent the DeeProtein score correlates with the protein activity. Therefore we created and <A href="https://2017.igem.org/Team:Heidelberg/Validation">measured a broad spectrum of GAIA generated variants</A>.
To also demonstrate the possibility to generate and increase a different protein activity in a related protein by applying GAIA <I>in silico</I> evolution we relied on altering the activity of a beta-glucuronidase to obtain beta-galactosidase activity. The feasibility of such a function transfer has already been demonstrated by conventional experimental methods <X-REF>matsumura2001vitro</X-REF>.<H2><I>in silico </I>Results</H2><H3>Selectivity in mutationsites</H3>
Before we set out to the <I>in silico </I>evolution of beta-lactamases we asserted the performance of GAIA by comprehensive metrics. The distribution of mutation rates over the residues is an important factor in directed evolution experiments, both determining the output and driving the evolution process. As this distribution is unknown and context specific it can not be approximated universally by computational tools. In GAIA the DeeProtein component is deployed to score the candidates naively generated by the genetic algorithm. Thus the latent knowledge in the deep neural network mimics the hidden distribution of mutation rates. As neural networks are a black box method, where the reasons for the internal states are extremely complex and very hard to disentangle, we performed comprehensive tests to shed light on the hidden distribution by asserting the effect of each mutation position-wise.<DIV class="col-lg-12 col-md-12 col-xs-12"><DIV class="mdl-shadow--4dp" style="padding:20px; float:left}"><DIV class="img-caption title"><STRONG><B>
      
Figure 3: The effect of mutations is not uniformal throughout the sequence. 
    </B></STRONG></DIV><DIV class="img-caption subtitle">
      
The heatmap shows the impact on the GAIA score for every possible amino acid substitution in the beta-lactamase sequence. The sequence position is depicted on the x-axis, while the y-axis displays the performed substitution. The impact is color coded from yellow for positive to red for negative impacts. While positive impact is made on small patches across the whole sequence, a cluster of positively impacting residues can be observed for residues 242 to 246. In contrast strong negative impact for all kind of substitutions is detected for the residues 255-263. Interestingly these residues form a beta-sheet through the center of the protein. Negative impact is also detected selectively for the introduction of Aspartic acid and glutamic acid at the sequence patches from 68-81 and from 180-200.
            
    </DIV></DIV></DIV><DIV class="col-lg-12  col-md-12 col-xs-12 pull-left image-box-left;"><DIV class="mdl-shadow--4dp" style="padding:20px; float:left; min-height: 420px !important; width: 100% !important"><DIV class="img-caption title"><STRONG><B>
Figure 3: The effect of mutations is not uniformal throughout the sequence. </B></STRONG></DIV><DIV class="img-caption subtitle">
          
For better visibility this figure is scrollable.
           
        </DIV></DIV></DIV><H3>Impact of Mutagenesis on GAIA-Score</H3>
To investigate the relation between GAIA score and the number of introduced mutations, we performed random mutagenesis studies and plotted the resulting scores of the candidates. The score decreases sigmoidal with the number of introduced mutations. This suggests our model to be tolerant to up to 20 mutations before a strong decrease in scores. The mark of positive predictions is crossed at about 50 mutations. For the generation of this plot GAIA was run in complete random mode introducing a new mutation ever generation until saturation. In every generation the scores were averaged over a set of 100 candidates.</DIV></DIV></DIV><DIV class="col-lg-12 col-md-12 col-xs-12"><DIV class="mdl-shadow--4dp" style="padding:20px; float:left}"><DIV class="img-caption title"><STRONG><B>
      
Figure 4: The GAIA score decreases linearly with the number of introduced mutations. 
    </B></STRONG></DIV><DIV class="img-caption subtitle">
      
The random mutagenesis of the beta-lactamase sequence, shows diminishing scores with increasing mutation numbers. The decrease in scores is sigmoidal and falls below the threshold of positive prediciton after about 50 mutations. Initially the model however tolerates up to 20 mutations before the score starts to decrease.

    </DIV></DIV></DIV><DIV class="container"><DIV class="row"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="display: inline-block; padding-bottom: 10px; padding-top:10px;"><H2>Experimental results</H2><DIV style="padding-top: 50px; padding-bottom:50px;"><DIV class="heidel-form container"><DIV class="heidel-form-header col-lg-12" style="text-align: left !important;"><A href="https://2017.igem.org/Team:Heidelberg/Validation" style="color: #000000">See the comprehensive report here</A>.
 </DIV></DIV></DIV><H3>Key Finding - GAIA enables Functionality Transfer</H3>
To assert the <I>in silico</I> evolution capabilities of GAIA in a real world application, we set out to reprogram the <I>E. coli</I> beta-glucuronidase to beta-galactosidase activity.
We initiallly evaluated the <I>in silico</I> evolution by performing <A href="https://2017.igem.org/Team:Heidelberg/Validation" style="color: #000000">equilibration molecular dynamics simulations</A> on the wildtype GUS and the GUS variant suggested by Matsumura et al. <X-REF>matsumura2001vitro</X-REF> to determine the effect of the introduced mutations on the protein fold. As no significant change in protein fold was observable we proceeded by liberately defining three mutative fragments on the GUS sequence, displayed in table 1. The limitation of mutagenesis to defined sequence regions was required to ensure the cloneability of the resulting constructs in the wet lab.<DIV class="col-lg-12 col-md-12 col-xs-12 content" style="padding-top: 20px; padding-bottom: 20px"><P class="content"><B>
                Table 1: Defined sequence patches open for mutagenesis. </B>
    
                The three defined sequence patches for the functionality transfer in beta glucuronidase. Fragments were determined after equilibration MD simulations and structure assertion in pyMOL.
            
  </P><DIV class="table-slot" style="overflow-x: auto"><TABLE><TBODY><TR><TH>Fragment</TH><TH>Positions</TH><TH>Constant Residue</TH></TR><TR><TD>A</TD><TD>351-371</TD><TD>G362</TD></TR><TR><TD>B</TD><TD>506-512</TD><TD>None</TD></TR><TR><TD>C</TD><TD>548-568</TD><TD>G559</TD></TR></TBODY></TABLE></DIV></DIV>

    Subsequently we ran GAIA on the determined fragments, with the objective to maximize the term for Galactosidase activity for up to 1000 generations. The mutation rate was thereby limited to 9 amino acid substituions per generation and reduced by one mutation every 300 generations.
    After cloning the activity of the variants was determined in <I>in vitro</I> assays. We thereby identified a GAIA predicted beta-glucuronidase variant carrying a single amino-acid (T509L) mutation with a beta-galactosidase activity comparable to the wild type.
    
<DIV class="col-lg-12 col-md-12 col-xs-12"><DIV class="mdl-shadow--4dp" style="padding:20px; float:left}"><DIV class="img-caption title"><STRONG><B>
      
            	Figure 5: Comparison Between the Wildtype Proteins and GUS_T509L
    </B></STRONG></DIV><DIV class="img-caption subtitle">
      
      Our assay demonstrated that the wildtype GUS shows no catlytic activity on a GAL substrate. The mutant predicted by GAIA however, exhibits extraordinary enzymatic activity on the GAL substrate. While the \(k_{cat}\) is lower compared to the wild type beta galactosidase the estimated \(K_M\) is approx. two-fold higher.</DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV><DIV style="background-color: white; padding-top: 20px;"><DIV class="container"><DIV class="row"><DIV class="col-lg-12 col-md-12 col-xs-12 content" style="display: inline-block;"><DIV class="row content"><DIV class="col-lg-12 col-md-12 col-xs-12" style="padding-top: 20px; padding-bottom: 50px; display: block"><DIV class="mdl-shadow--4dp" style="padding: 20px"><H3> References </H3></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV><SECTION id="footer-sec" style="background-color: #222 !important"><DIV class="container"><DIV class="row" style="padding-top: 30px;"><DIV class="col-md-3"><H4 style="text-align: center">Quote</H4><P><I>“”</I></P></DIV><DIV class="col-md-3"><H4 style="text-align: center"> Useful <STRONG>Links</STRONG></H4><P><A href="https://igem.org/Special:SpecialPages">
			Special pages
		</A></P><P><A href="https://igem.org/Main_Page">
			Main Page
		</A></P></DIV><DIV class="col-md-3"><H4 style="text-align: center"> Follow us on </H4><DIV style="text-align: center;"><SPAN style="color: grey; text-align: center;">&amp;</SPAN></DIV></DIV><DIV class="col-md-3"><H4 style="text-align: center"> Contact us </H4><P>

               iGEM-Heidelberg2017@bioquant.uni-heidelberg.de
               
		 Im Neuenheimer Feld 267
		
		69120 Heidelberg
                    </P></DIV></DIV></DIV></SECTION></DIV></DIV></DIV></DIV></BODY></HTML>