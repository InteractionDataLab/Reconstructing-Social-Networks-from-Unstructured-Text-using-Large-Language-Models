<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_TU_Darmstadt_tech_software skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:TU Darmstadt/tech/software</SPAN></H1></DIV><DIV id="HQ_page"><DIV id="bodyContent"><DIV id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><DIV id="titleBar"><SPAN class="title"><A href="https://2017.igem.org/Team:TU_Darmstadt">ChiTUcare</A></SPAN></DIV><P><TITLE>MainPage</TITLE></P><H1 id="logo"><A href="https://2017.igem.org/Team:TU_Darmstadt">ChiTUcare</A></H1><NAV id="nav"><UL><DIV class="mainmenu"><DIV class="nav-follow"><DIV class="nav-drop"><LI><A href="https://2017.igem.org/Team:TU_Darmstadt/project">Project</A></LI><LI><A href="https://2017.igem.org/Team:TU_Darmstadt/human_practices">Human Practices</A></LI></DIV></DIV><LI><A href="https://2017.igem.org/Team:TU_Darmstadt/tech" class="active">Tech</A></LI></DIV><DIV class="nav-proj-drop"><LI><A href="https://2017.igem.org/Team:TU_Darmstadt/tech/hardware">Hardware</A></LI><LI><A href="https://2017.igem.org/Team:TU_Darmstadt/tech/software" class="active">Software</A></LI></DIV><DIV class="mainmenu"><DIV class="nav-follow"><DIV class="nav-drop_b"><LI><A href="https://2017.igem.org/Team:TU_Darmstadt/team">Team</A></LI><LI><A href="https://2017.igem.org/Team:TU_Darmstadt/judging">Judging</A></LI></DIV></DIV></DIV></UL></NAV><DIV id="wrapper"><DIV id="main"><SECTION id="one"><DIV class="container"><HEADER class="major"><H2>Software HoloPyGuy</H2></HEADER><DIV class="post-it"><P>Here, we present HoloPyGuy, an universal software solution created for Digital Inline Holographic Microscopy (DIHM). HoloPyGuy is an easy-to-use hologram reconstruction suite for self-made DIHM. We employed the open-source framework <STRONG>Holo</STRONG><STRONG>P</STRONG><STRONG>y</STRONG>, extended the existing solution with a graphical user interface, which greatly ease the whole process of parameter tuning, visualization of the holograms and reconstructed images. The software also supports 3D imaging from the reconstructed stack of images, by invoking the open source software <STRONG>Fiji</STRONG>. The graphical user interface relies on the <STRONG>Qt5</STRONG> framework and is written in <STRONG>Python</STRONG>. The project is hosted on <STRONG>GitHub</STRONG> under <STRONG>MIT License</STRONG> and is also available for download. A complete user manual is provided in the following section.</P></DIV></DIV></SECTION><SECTION id="two"><DIV class="container"><H2>HoloPyGuy: User Manual</H2><P>HoloPyGuy functions simply by uploading the reference picture, the recorded sample hologram, adjusting parameters, and hit “Reconstruct”. As demonstrated in the video, we first adjusted the parameters according to our experimental setup, whereas the settings in “Point Source” tab are explained in the table below. Note that HoloPyGuy also supports collimated source calculation,  if an collimated source instead of a pinhole is used.</P><P>As HoloPy only supports square images when it comes to point source, HoloPyGuy automatically cuts the images into square images stemming from the center, with equal linear pixel size, once the images are imported. In addition, HoloPyGuy also converts the images to gray scale, this is due to the fact that for a coherent light source only a single wavelength is considered in the algorithm, thus color information is discarded for a simpler and better reconstruction.</P><TABLE style="width: 100%;"><TBODY><TR><TH>Parameters</TH><TH>Description</TH></TR><TR><TD>Spacing</TD><TD>Distance between the center of two pixels, can be arbitrarily specified in point source setup, relative to “Magnification”</TD></TR><TR><TD>Wavelength</TD><TD>Wavelength of the used light source in nm, in our case the cell phone flashlight has a wavelength of approx. 450 nm</TD></TR><TR><TD>Medium</TD><TD>Refractive index of the medium, HoloPy currently only supports index = 1 for point source setup</TD></TR><TR><TD>Magnification</TD><TD>Magnification factor from the sample object to the reconstructed wavefronts, can be arbitrarily specified, relative to “Spacing”</TD></TR><TR><TD>Distance</TD><TD>The distance between image sensor to light source in mm (don’t forget the distance from image sensor to cam!)</TD></TR><TR><TD>Z min</TD><TD>Minimum distance from the camera to the xy plane near the object for wave front reconstruction</TD></TR><TR><TD>Z max</TD><TD>Maximum distance from the camera to the xy plane near the object for wave front reconstruction</TD></TR><TR><TD>Z steps</TD><TD>Numer of wavefronts at various distance near the object to be reconstructed</TD></TR><TR><TD>Outpixel [#]</TD><TD>Size of the output square pictures, can be used to cut the center part of the reconstructed images</TD></TR></TBODY></TABLE><P>In our experiment we used cell phone flash light attached with a 5 micrometer pinhole, which makes it a point source. Unlike the collimated source, the pixel spacing at the reconstructed wavefront can be chosen arbitrarily due to the magnification of the emanating spherical wave. The “Spacing” and “Magnification” parameter are relative and reversely proportional, the higher the magnification, the smaller the pixel spacing, thus the higher the resolution in the reconstructed images. When the reconstructed image has less pixels than the specified “Outpixel[#]”, the whole images will be displayed in “Reconstructed Images”, otherwise the images will be cut from the center <A href="#[15]">[15]</A>.
Next, select “Point Source” tab, “Open Background” to import the background image, such that the recorded hologram with the sample object and the same background, would be able to subtract the background noise for a better reconstructed visualization. In addition, more than one background image can be imported, whereas the average is taken for better estimation. Then, “Load Sample” loads the recorded hologram of the sample object, then “Reconstruct” ignites the calculation, a stack of “Reconstructed Images” will be shown in the window, where you can move the slide bar through the stack, as well as zoom in by rolling your mouse.
Essentially the algorithm in HoloPy functions as a digital lens, taking pictures at different depths, or cross-section slicing images of the sample object, which contains the 3D information of the object. Next “Save holograms as”, where all reconstructed images will be named and saved in sequence in the specified folder, clicking now on “Show 3D Object”, a subprocess in python would trigger the software Fiji, passing command arguments converting images to stack, invoking the 3D Viewer plug-in, thus visualizing the stack images as one 3D object.
If the reconstructed images is not yet optimal due to parameters tuning, or when we simply want to compare different reconstructed images, we can “Set Reference Pic”, so that the current displayed image in “Reconstructed Images” window will be shown in the “Reference Reconstruction” window. Further adjustment of the parameters and the resulting updated “Reconstructed Images” will be shown for comparison.</P></DIV></SECTION><SECTION id="four"><DIV class="container"><H3>Achievements</H3><P>After taking pictures using our hardware setup, we ran HoloPyGuy software to reconstruct the sample object images. We tested three different sample objects: microscope resolution slide, bubbles, and blood cells respectively.</P><CENTER><FIGURE style="text-align: center;"><FIGCAPTION><B>Figure 1.</B> From left to right: average background image, recorded hologram with microscope resolution slide, moving through reconstructed stack images</FIGCAPTION></FIGURE></CENTER><P>According to the above figure, HoloPyGuy first takes the average of the import background images, subtracts the average background from the recorded hologram to remove noise, and then computes the reconstructed images. We can see from the reconstruction of the microscope resolution slide, that our hardware setup and HoloPyGuy software solution can resolve up to 2 micrometer resolution. However we also observe some dust within the resolution slide, which can't be cleaned and results in excessive inteference patterns in the reconstructed images. The excessive interference is also observed in the following figure, where the sample object is a bubble.</P><CENTER><FIGURE style="text-align: center;"><FIGCAPTION><B>Figure 2.</B> From left to right: average background image, recorded hologram with a bubble, moving through reconstructed stack images</FIGCAPTION></FIGURE></CENTER><P>In the following figure the sample object are blood cells, however there're too many cells in the field of view, resulting in quite noisy interference patterns in the reconstruction. </P><CENTER><FIGURE style="text-align: center;"><FIGCAPTION><B>Figure 3.</B> From left to right: average image, recorded hologram with blood cells, moving through reconstructed stack images</FIGCAPTION></FIGURE></CENTER><P>Multiple objects in the field of view and excessive interference patterns partly destroy the 3D information. Thus with out current hardware setup and alignment, 3D imaging using Fiji is not yet feasible. However, we have successfully tested the sample images from <A href="http://holopy.readthedocs.io/en/3.1.1/users/ps_recon_tutorial.html">HoloPy documentation</A> in the point source set up. The resampling is set to 1, and threshold set to 74 to remove remaining background noise. The resulting 3D object is shown below:</P><CENTER><FIGCAPTION><B>Figure 4.</B> From left to right: the recordered hologram from holopy documentation, moving through the reconstructed images, 3D object in Fiji</FIGCAPTION></CENTER></DIV></SECTION></DIV><SECTION id="five"><DIV class="container"><H3>Download and further documentation</H3><H4>Setting up your system for using HoloPyGuy</H4><P>
                                            To set it up for running, we follow the getting started section from holopy. If you use a unix based operating system, please run the following lines in command-line:
                                            <CODE>sudo apt install conda</CODE><CODE>conda install -c conda-forge holopy</CODE>
                                            This should set up the production branch of HoloPy. For Windows, the installation process is quite similar. Install Anaconda3 for your OS. Be aware that if you let the box checked in the installer, Anaconda overwirtes the default python interpreter. Then, run the following commands in the anaconda prompt:
                                            <CODE>anaconda search holopy</CODE><CODE>anaconda show ralex0/holopy</CODE><CODE>conda install -c conda-forge emcee</CODE><CODE>conda install -c conda-forge h5netcdf</CODE><CODE>conda install --channel https://conda.anaconda.org/ralex0 holopy</CODE>
                                            Install hologuy requirements (a converter from QImage to NdArray)<CODE>conda install -c conda-forge qimage2ndarray</CODE>
                                            
For 3D model support, you have to install the latest version of FiJi from their website. Follow the instructions provided. Then, you have to edit the paths in <CODE>call_fiji.py</CODE> and <CODE>testfiji.py</CODE>.
</P><H4>Get a copy of HoloPyGuy</H4><P>
                                            Download the latest version from hologuy and extract the files
                                            either from our GitHub repo or download the <A href="https://static.igem.org/mediawiki/2017/c/c9/T--TU_Darmstadt--holopyguy_software.zip">.zip</A> file.

                                            To get the latest version, it is recommended to check our git. 
                                            You can get a copy of our repository by installing git and run in a terminal:
                                            <CODE>git clone https://www.github.com/iGEMDarmstadt/holopyguy.git</CODE><CODE>python hologuy.py</CODE></P></DIV></SECTION><SECTION id="seven"><DIV class="container"><H3>Outlook: Future Development</H3><P>There's still room for improvement in our software solution, as well as in coordination with the hardware setup:
    </P><P>As we mentioned earlier in the <B>Achievements</B> section, too many objects in the field of view would introduce excessive interference patterns which can't be effectively removed after reconstruction. This can be solved with a precisely controlled hardware setup, careful selection and alignment such that there's one or only a few sample objects in the field of view.</P><LI><P>A bug in software solution: adjusting the parameter &quot;Spacing&quot; needs to be prior to importing any pictures to HoloPyGuy, otherwise the calculation would raise memory error. This is due to source code of HoloPy, as 'cam spacing&quot; is not updated in the <CODE>holopy.core.update_metadata()</CODE> function. In collimated source setup, &quot;Spacing&quot; is a parameter that doesn't need frequent update. However in point source setup, &quot;Spacing&quot;, in relation to &quot;Magnification&quot;, can be arbitrarily set for better reconstruction. Thus future improvement can be done in updating the source code for the point source setup.</P></LI><LI><P>Integrate the pi-cam webserver into the user interface of HoloPyGuy, where an end-to-end process from taking pictures upto 3D imaging can be realized.</P></LI></DIV></SECTION><SECTION id="seven"><DIV class="container"><H3>References</H3><P><TABLE class="ref"><TBODY><TR><TD id="[1]">[1]</TD><TD>Shiraki, A., Taniguchi, Y., Shimobaba, T., Masuda, N., Ito, T. (2012) Handheld and low-cost digital
                                                    holographic microscopy.
                                                <A href="http://www.arXiv.org/abs/1211.0336">arXiv:1211.0336</A></TD></TR><TR><TD id="[2]">[2]</TD><TD>Cotte, Y., Toy, F., Jourdain, P., Pavillon, N., Boss, D., Magistretti, P., Marquet, P., Depeursinge
                                                    (2013) Marker-free phase nanoscopy <I>Nature Photonics</I>, 7 (2):113
                                                <A href="https://doi.org/10.1038/nphoton.2012.329">DOI: 10.1038/nphoton.2012.329</A></TD></TR><TR><TD id="[3]">[3]</TD><TD>    Giuliano, C. B., Zhang, R., Wilson, L. G. (2014) Digital Inline Microscopy (DIHM) of Weakly-scattering
                                                Subjects <I>Journal of Visualized Experiments</I>, <A href="https://doi.org/10.3791/50488">DOI:10.3791/50488</A></TD></TR><TR><TD id="[4]">[4]</TD><TD>Molaei, M., Sheng, J. (2014) Imaging bacterial 3D motion using digital inline holographic microscopy
                                                and correlation-based de-noising algorithm <I>Optics Express</I>, <A href="https://doi.org/10.1364/OE.22.032119">DOI: 10.1364/OE.22.032119</A></TD></TR><TR><TD id="[5]">[5]</TD><TD> Braat, J., Dirksen, P., Janssen, A. J. E. M. (2003) Diffractive Read-Out of Optical Discs, <I>Optical Imaging</I>Springer Verlag</TD></TR><TR><TD id="[6]">[6]</TD><TD>Deng, Y., Chu, D., (2017) Coherence properties of different light sources and their effect on the image sharpness and
                                                    speckle of holographic displays, <I>Scientific Report</I>,
                                                <A href="https://doi.org/10.1038/s41598-017-06215-x">DOI: 10.1038/s41598-017-06215-x</A></TD></TR><TR><TD id="[7]">[7]</TD><TD>Jericho, M. H., Kreuzer, H.J., (2011), Point Source Digital In-Line Holographic Microscopy, Chapter 1, Coherent Light Microscopy, <I>Springer Series in Surface Sciences 46</I>, 46
                                                <A href="https://doi.org/10.1007/978-3-642-15813-1_1">DOI: 10.1007/978-3-642-15813-1_1</A></TD></TR><TR><TD id="[8]">[8]</TD><TD>Rostykus, M., Moser, C. (2017) Compact lensless off-axis transmission digital holographic microscope, <I>Optics Express</I>, <A href="https:/doi.org/10.1364/OE.25.016652">DOI: 10.1364/OE.25.016652</A></TD></TR><TR><TD id="[9]">[9]</TD><TD>Reichert, C. C., Herkommer, A., Claus, D. (2016) Das Smartphone als Mikroskop, <I>AT-Fachverlag GmbH</I>,
                                                <A href="http://www.biophotonik.de">www.biophotonik.de</A></TD></TR><TR><TD id="[10]">[10]</TD><TD>Moon, I., Daneshpanah, M., Anand, A., Javidi, B. (2011) Cell Identification Computational 3-D Holographic
                                                    Microscopy, <I>Optics &amp; Photonics</I>, 22 (6),
                                                </TD></TR><TR><TD id="[11]">[11]</TD><TD>Greenbaum, A., Luo, W., Su, T., Göröcs, Z., Xue, L., Isikman S., Coskun, A., Mudanyali, O., Ozcan, A. (2012) Imaging
                                                without lenses: achievments and remaining challenges of wide-field on-chip microscopy, <IT>Nature America</IT>, <A href="https://doi.org/10.1038/nmeth.2114">DOI:10.1038/nmeth.2114</A></TD></TR><TR><TD id="[12]">[12]</TD><TD>beniroquai (2017) Blog, <A href="http://beniroquai.wordpress.com/2016/01/20/holoscope-linsenloses-holographisches-mikroskop/">https://beniroquai.wordpress.com/2016/01/20/holoscope-linsenloses-holographisches-mikroskop/</A>,
                                                last visited: 10/15/2017</TD></TR><TR><TD id="[13]">[13]</TD><TD>BDan (2015) micromanipulator, Thingiverse, <A href="http://www.thingiverse.com/thing:923865/#files">https://www.thingiverse.com/thing:923865/#files</A>,
                                                last visited: 10/15/2017</TD></TR><TR><TD id="[14]">[14]</TD><TD>&quot;Do-it-yourself&quot; project for steering HD-DVD pickup homepage: <A href="http://www.diyouware.com/">http://www.diyouware.com/</A>
                                                last visited: 10/15/2017</TD></TR><TR><TD id="[15]">[15]</TD><TD>&quot;HoloPy, a python framework for analyzing digital holographs, <I> manoharan lab, Harvard<I><A href="https://github.com/manoharan-lab/holopy">https://github.com/manoharan-lab/holopy</A>
                                                last visited: 10/18/2017</I></I></TD></TR><TR><TD id="[16]">[16]</TD><TD>&quot;HoloPy, documentation, <A href="https://holopy.readthedocs.io/en/latest/users/index.html">https://holopy.readthedocs.io/en/latest/users/index.html</A>
                                                last visited: 10/18/2017</TD></TR><TR><TD id="[17]">[17]</TD><TD><A href="https://en.wikipedia.org/wiki/User:Egelberg">User:Egelberg</A>, <A href="https://commons.wikimedia.org/wiki/File:OpticalSetupDHM.jpg#filelinks">OpticalSetupDHM</A>, <A href="https://creativecommons.org/licenses/by-sa/3.0/legalcode">CC BY-SA 3.0</A></TD></TR><TR><TD id="[18]">[18]</TD><TD>Schmid B., Schindelin, J., Cardona, A. et al. (2010) A high-level 3D visualization API for Java and ImageJ, <I>BMC Bioinformatics 11(1): 1</I>, <A href="https:/doi.org/10.1038/nmeth.3392">DOI: 10.1038/nmeth.3392</A></TD></TR><TR><TD id="[19]">[19]</TD><TD>Schindelin, J., Arganda-Carreras, I., Frise, E. et al. (2012) Fiji: an open-source platform for biological-image analysis, <I>Nature methods 9(7): 676-682</I>, <A href="https:/doi.org/10.1038/nmeth.2019">DOI: 10.1038/nmeth.2019</A></TD></TR></TBODY></TABLE></P></DIV></SECTION><SECTION id="footer"><DIV class="container"><P style="text-align: center;"><A href="http://www.igem.tu-darmstadt.de/igem_2/projekt_2/index.de.jsp">iGEM Technische Universität Darmstadt</A></P><P style="text-align: center;">We thank our sponsors, instructors and the iGEM organization!</P><P style="text-align: center;">Design: <A href="http://html5up.net">HTML5 UP</A></P></DIV></SECTION></DIV></DIV></DIV></DIV></DIV></DIV></BODY></HTML>