<HTML lang="en" dir="ltr" class="client-nojs">
<style type="text/css">
A:before { content:' '; } 
A:after { content:' '; } 
SPAN:before { content:' '; } 
SPAN:after { content:' '; } 
</style>
<BODY class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Team_Cornell_Software skin-igem action-view"><DIV id="globalWrapper"><DIV id="content" class="mw-body" role="main"><DIV id="top_title"><H1 id="firstHeading" class="firstHeading"><SPAN dir="auto">Team:Cornell/Software</SPAN></H1></DIV><DIV id="HQ_page"><DIV id="bodyContent"><DIV id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><P>&lt;!DOCTYPE html&gt;<TITLE>Software</TITLE></P><DIV class="main-nav-wrapper nav-wrapper-1-creative"><NAV><DIV class="main-nav main-nav-1 creative-page nav-content-toggle"><DIV class="container"><UL class="nav-main-menu nav-content-item"><LI><A href="https://2017.igem.org/Team:Cornell">HOME</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Description">ABOUT</A></LI><LI class="mega-menu menu-5-col"><A href="#">TOOLKIT</A></LI><LI class="menu-title"><A href="#">WET LAB</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Results">FOUNDATIONS</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Demonstrate">DEMONSTRATE</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Contribution">CONTRIBUTION</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Parts">PARTS</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Basic_Part">BASIC PARTS</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Protocol">PROTOCOLS</A></LI></UL><LI class="menu-title"><A href="#">PRODUCT DEVELOPMENT</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Design">DESIGN PROCESS</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Applied_Design">APPLIED DESIGN</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Software">SOFTWARE</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Model">MODELING</A></LI><LI class="menu-title"><A href="#">DOCUMENTATION</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Notebook">NOTEBOOK</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Safety">SAFETY</A></LI><LI><A href="#">HUMAN CENTERED DESIGN</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/HP/Gold_Integrated">PRACTICES</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Policies">POLICIES</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Entrepreneurship">ENTREPRENEURSHIP</A></LI><LI><A href="#">OUTREACH</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Collaborations">COLLABORATIONS</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Engagement">PUBLIC ENGAGEMENT</A></LI><LI><A href="#">TEAM</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Team">BIOS</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Sponsors">SPONSORS</A></LI><LI><A href="https://2017.igem.org/Team:Cornell/Attributions">ATTRIBUTIONS</A></LI></DIV></DIV></NAV></DIV><MAIN><HEADER class="container-fluid banner-wrapper banner-photo-software"><DIV class="caption">
          Software
        </DIV></HEADER><DIV id="sidebar" class="container-fluid content-wrapper-font"><DIV class="row standardPageContent"><DIV class="col-xs-2 sidebar"><UL class="sidebar-wrapper"><LI><A href="#overview">Overview</A></LI><LI><A href="#detection">Detection</A></LI><LI><A href="#signal">Signal Processing</A></LI><LI><A href="#storage">Storage</A></LI></UL></DIV><DIV class="col-xs-8 standard-content"><DIV class="content-title top"><A id="overview">Overview</A></DIV><P>In the process of creating our OxyPonics system, we realized we needed to make a cheap, flexible, camera system capable of quantifying and localizing our optical signals. To keep costs low, we built our system out of a ten dollar camera and a Raspberry Pi. This allows us to properly image and track fluorescence to a reasonable degree without the need for expensive lab equipment like plate readers or spectrofluorometers. Using OpenCV, an open-source package for computer vision, we created software to track the fluorescent signal in our frame, efficiently eliminate noise, and record and send the measured intensity to a web server which tracks the readings. While our optics are designed for rxRFP, our software works for any wavelength and is capable of cheaply identifying and quantifying localized fluorescence in a wide variety of environments, providing a powerful tool for labs on a budget. Our software can be accessed on our GitHub <A class="link" href="https://github.com/Cornell-iGEM/iGEM-Detection">here.</A></P><DIV class="content-title"><A id="detection">Detection</A></DIV><P>Our fluorescence signal comes in the form of an image from our camera.  While the optical filter on the camera removes most of the stray and excitation light, there is still a noticeable background.  To account for this, we mask the image for only the color range of the fluorescent light, which blocks out background from other parts of the image.  We then find contours in this mask to locate position of the fluorescence, and integrate over this contour to find the average fluorescence intensity.  Our software automatically records measurements at various excitation intensities and records this information to a log file; a slight modification (commented) allows it to send this data to a remote web server as well. If users choose to use the full automation of the software, users only need to set the data once, freeing them to perform other tasks while still examining the data in real time.
                         </P><DIV class="content-title"><A id="signal">Signal Processing</A></DIV><P>We implemented a rudimentary Kalman filter in order to process our data.  The base code came from <A class="link" href="http://scipy-cookbook.readthedocs.io/items/KalmanFiltering.html">here</A>, but was modified to use our actual measurements and incorporate our model.  It was also generalized to work for a vector state variable.
                  </P><DIV class="content-title"><A id="storage">Storage</A></DIV><P>A simple web server implemented in Express with MongoDB allows for remote storage of data as it is collected.  Endpoints for additional data are easy to set up, following the example of the existing ones.  This is useful for when the processing power or storage on the Raspberry Pi is not enough, or when one wants a more permanent backup of the data.
                        </P></DIV></DIV></DIV></MAIN></DIV></DIV></DIV></DIV></DIV></BODY></HTML>